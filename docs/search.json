[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python for Data Analysis, 3E",
    "section": "",
    "text": "About\n本书为《Python for Data Analysis》的中文翻译版本，仅供个人学习。\n原书链接：https://wesmckinney.com/book",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "01.preliminaries.html",
    "href": "01.preliminaries.html",
    "title": "1  Preliminaries",
    "section": "",
    "text": "1.1 What Is This Book About?\n本书涉及用 Python 操作、处理、清理和处理数据的具体细节。本书的目标是提供有关 Python 编程语言及其面向数据的库生态系统和工具的指南，帮助您成为一名高效的数据分析师。虽然本书的标题是“data analysis”，但重点是 Python 编程、库和工具，而不是数据分析方法。这是数据分析所需的 Python 编程。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "02.python-basics.html",
    "href": "02.python-basics.html",
    "title": "2  Python Language Basics, IPython, and Jupyter Notebooks",
    "section": "",
    "text": "2.1 The Python Interpreter (Python 解释器)\nPython 是一种解释型（interpreted）语言。Python 解释器通过一次执行一条语句来运行程序。可以使用 python 命令在命令行上调用标准交互式 Python 解释器：\n您看到的 &gt;&gt;&gt; 是提示符，您可以在该提示符后键入代码表达式。要退出 Python 解释器，您可以键入 exit() 或按 Ctrl-D（仅适用于 Linux 和 macOS）。\n运行 Python 程序就像使用 .py 文件作为第一个参数调用 python 一样简单。假设我们使用以下内容创建了 hello_world.py：\n您可以通过执行以下命令来运行它（hello_world.py 文件必须位于您当前的工作终端目录中）：\n虽然一些 Python 程序员以这种方式执行所有 Python 代码，但进行数据分析或科学计算的程序员则使用 IPython（一种增强的 Python 解释器）或 Jupyter notebooks（最初在 IPython 项目中创建的基于 Web 的代码笔记本）。我在本章中介绍了如何使用 IPython 和 Jupyter，并在 Appendix A: Advanced NumPy 中更深入地了解了 IPython 功能。当您使用 %run 命令时，IPython 会在同一进程中执行指定文件中的代码，使您能够在完成后以交互方式探索结果：\n与标准的 &gt;&gt;&gt; 提示符相比，默认的 IPython 提示符采用编号 In [2]: 样式。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Language Basics, IPython, and Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "02.python-basics.html#the-python-interpreter-python-解释器",
    "href": "02.python-basics.html#the-python-interpreter-python-解释器",
    "title": "2  Python Language Basics, IPython, and Jupyter Notebooks",
    "section": "",
    "text": "$ python\nPython 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57)\n[GCC 10.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; a = 5\n&gt;&gt;&gt; print(a)\n5\n\n\nprint(\"Hello world\")\n\n$ python hello_world.py\nHello world\n\n$ ipython\nPython 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57)\nType 'copyright', 'credits' or 'license' for more information\nIPython 7.31.1 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: %run hello_world.py\nHello world\n\nIn [2]:",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Language Basics, IPython, and Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "02.python-basics.html#ipython-basics",
    "href": "02.python-basics.html#ipython-basics",
    "title": "2  Python Language Basics, IPython, and Jupyter Notebooks",
    "section": "2.2 IPython Basics",
    "text": "2.2 IPython Basics\n在本节中，我将帮助您启动并运行 IPython shell 和 Jupyter Notebook，并向您介绍一些基本概念。\n\n2.2.1 Running the IPython Shell\n您可以在命令行上启动 IPython shell，就像启动常规 Python 解释器一样，只不过使用 ipython 命令：\n$ ipython\nPython 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57)\nType 'copyright', 'credits' or 'license' for more information\nIPython 7.31.1 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: a = 5\n\nIn [2]: a\nOut[2]: 5\n您可以通过键入任意 Python 语句并按 Return（或 Enter）来执行它们。当您在 IPython 中键入一个变量时，它会呈现该对象的字符串表示形式：\nIn [5]: import numpy as np\n\nIn [6]: data = [np.random.standard_normal() for i in range(7)]\n\nIn [7]: data\nOut[7]: \n[-0.20470765948471295,\n 0.47894333805754824,\n -0.5194387150567381,\n -0.55573030434749,\n 1.9657805725027142,\n 1.3934058329729904,\n 0.09290787674371767]\n前两行是 Python 代码语句；第二条语句创建一个名为 data 的变量，该变量引用新创建的列表。最后一行在控制台中打印 data 的值。\n许多类型的 Python 对象都被格式化为更具可读性或打印更美观，这与普通的 print 打印不同。如果你在标准 Python 解释器中打印上面的 data 变量，它的可读性会低得多：\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; data = [np.random.standard_normal() for i in range(7)]\n&gt;&gt;&gt; print(data)\n&gt;&gt;&gt; data\n[-0.5767699931966723, -0.1010317773535111, -1.7841005313329152,\n-1.524392126408841, 0.22191374220117385, -1.9835710588082562,\n-1.6081963964963528]\nIPython 还提供了执行任意代码块（通过某种美化的复制粘贴方法）和整个 Python 脚本的工具。您还可以使用 Jupyter notebook 来处理更大的代码块，我们很快就会看到。\n\n\n2.2.2 Running the Jupyter Notebook\nJupyter 项目的主要组件之一是 notebook，一种用于代码、文本（包括 Markdown）、数据可视化和其他输出的交互式文档。Jupyter notebook 与 kernels 交互，kernels 是特定于不同编程语言的 Jupyter 交互式计算协议的实现。Python Jupyter kernel 使用 IPython 系统来实现其底层行为。\n要启动 Jupyter，请在终端中运行命令 jupyter notebook：\n$ jupyter notebook\n[I 15:20:52.739 NotebookApp] Serving notebooks from local directory:\n/home/wesm/code/pydata-book\n[I 15:20:52.739 NotebookApp] 0 active kernels\n[I 15:20:52.739 NotebookApp] The Jupyter Notebook is running at:\nhttp://localhost:8888/?token=0a77b52fefe52ab83e3c35dff8de121e4bb443a63f2d...\n[I 15:20:52.740 NotebookApp] Use Control-C to stop this server and shut down\nall kernels (twice to skip confirmation).\nCreated new window in existing browser session.\n    To access the notebook, open this file in a browser:\n        file:///home/wesm/.local/share/jupyter/runtime/nbserver-185259-open.html\n    Or copy and paste one of these URLs:\n        http://localhost:8888/?token=0a77b52fefe52ab83e3c35dff8de121e4...\n     or http://127.0.0.1:8888/?token=0a77b52fefe52ab83e3c35dff8de121e4...\n在许多平台上，Jupyter 将自动在您的默认 Web 浏览器中打开（除非您使用 --no-browser 启动它）。否则，您可以导航到启动笔记本时打印的 HTTP 地址，此处为 http://localhost:8888/?token=0a77b52fefe52ab83e3c35dff8de121e4bb443a63f2d3055。请参阅 Figure 2.1 了解 Google Chrome 中的情况。\n\n\n\n\n\n\nNote\n\n\n\n很多人使用 Jupyter 作为本地计算环境，但它也可以部署在服务器上并远程访问。我不会在这里介绍这些细节，但我鼓励您在互联网上探索这个主题（如果它与您的需求相关）。\n\n\n\n\n\nFigure 2.1: Jupyter notebook landing page\n\n\n要创建新的笔记本，请单击“新建”按钮并选择“Python 3”选项。您应该看到如 Figure 2.2 所示的内容。如果这是您第一次，请尝试单击空代码“单元格”并输入一行 Python 代码。然后按 Shift-Enter 执行它。\n\n\n\nFigure 2.2: Jupyter new notebook view\n\n\n保存笔记本时（see “Save and Checkpoint” under the notebook File menu），它会创建一个扩展名为 .ipynb 的文件。这是一种独立的文件格式，包含当前笔记本中的所有内容（包括任何评估的代码输出）。其他 Jupyter 用户可以加载和编辑它们。\n要重命名打开的笔记本，请单击页面顶部的笔记本标题并键入新标题，完成后按 Enter。\n要加载现有笔记本，请将文件放在启动笔记本进程的同一目录中（或其中的子文件夹中），然后单击登录页面中的名称。您可以使用我在 GitHub 上的 wesm/pydata-book 存储库中的笔记本进行尝试。参见 Figure 2.3。\n当您想要关闭笔记本时，请单击 File 菜单并选择 “Close and Halt”。如果您只是关闭浏览器选项卡，与笔记本关联的 Python 进程将继续在后台运行。\n虽然 Jupyter Notebook 可能给人一种与 IPython shell 截然不同的体验，但本章中的几乎所有命令和工具都可以在任一环境中使用。\n\n\n\nFigure 2.3: Jupyter example view for an existing notebook\n\n\n\n\n2.2.3 Tab Completion\n从表面上看，IPython shell 看起来像是标准终端 Python 解释器（使用 python 调用）的一个外观上不同的版本。相对于标准 Python shell 的主要改进之一是制表符补全，在许多 IDEs 或其他交互式计算分析环境中都可以找到。在 shell 中输入表达式时，按 Tab 键将在命名空间中搜索与您目前键入的字符相匹配的任何变量（对象、函数等），并在方便的下拉菜单中显示结果：\nIn [1]: an_apple = 27\n\nIn [2]: an_example = 42\n\nIn [3]: an&lt;Tab&gt;\nan_apple   an_example  any\n在此示例中，请注意 IPython 显示了我定义的两个变量以及内置函数 any。此外，您还可以在输入句点后完成任何对象的方法和属性：\nIn [3]: b = [1, 2, 3]\n\nIn [4]: b.&lt;Tab&gt;\nappend()  count()   insert()  reverse()\nclear()   extend()  pop()     sort()\ncopy()    index()   remove()\n对于模块也是如此：\nIn [1]: import datetime\n\nIn [2]: datetime.&lt;Tab&gt;\ndate          MAXYEAR       timedelta\ndatetime      MINYEAR       timezone\ndatetime_CAPI time          tzinfo\n\n\n\n\n\n\nNote\n\n\n\n请注意，IPython 默认隐藏以下划线开头的方法和属性，例如 magic 方法和内部“私有（private）”方法和属性，以避免显示混乱（并使新手用户感到困惑！）。这些也可以通过制表符完成，但您必须首先键入下划线才能看到它们。如果您希望始终在制表符补全中看到此类方法，则可以在 IPython 配置中更改此设置。请参阅 IPython documentation 以了解如何执行此操作。\n\n\n除了搜索交互式命名空间和完成对象或模块属性之外，选项卡补全还可以在许多上下文中使用。当输入任何看起来像文件路径的内容时（即使是 Python 字符串），按 Tab 键将完成计算机文件系统上与您输入的内容匹配的任何内容。\n与 %run 命令（请参阅 Appendix B.2.1: The %run Command）结合使用，此功能可以节省您许多击键次数。\n制表符补全可以节省时间的另一个方面是函数关键字参数的补全（包括 = 符号！）。参见 Figure 2.4。\n\n\n\nFigure 2.4: Autocomplete function keywords in a Jupyter notebook\n\n\n稍后我们将更仔细地了解函数。\n\n\n2.2.4 Introspection\n在变量之前或之后使用问号 (?) 将显示有关该对象的一些常规信息：\nIn [1]: b = [1, 2, 3]\n\nIn [2]: b?\nType:        list\nString form: [1, 2, 3]\nLength:      3\nDocstring:\nBuilt-in mutable sequence.\n\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\n\nIn [3]: print?\nDocstring:\nprint(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n\nPrints the values to a stream, or to sys.stdout by default.\nOptional keyword arguments:\nfile:  a file-like object (stream); defaults to the current sys.stdout.\nsep:   string inserted between values, default a space.\nend:   string appended after the last value, default a newline.\nflush: whether to forcibly flush the stream.\nType:      builtin_function_or_method\n这称为对象自省（introspection）。如果对象是函数或实例方法，则还将显示文档字符串（如果已定义）。假设我们编写了以下函数（您可以在 IPython 或 Jupyter 中重现）：\ndef add_numbers(a, b):\n    \"\"\"\n    Add two numbers together\n\n    Returns\n    -------\n    the_sum : type of arguments\n    \"\"\"\n    return a + b\n然后使用 ? 向我们展示了文档字符串：\nIn [6]: add_numbers?\nSignature: add_numbers(a, b)\nDocstring:\nAdd two numbers together\nReturns\n-------\nthe_sum : type of arguments\nFile:      &lt;ipython-input-9-6a548a216e27&gt;\nType:      function\n?还有最后一个用途，即以类似于标准 Unix 或 Windows 命令行的方式搜索 IPython 命名空间。多个字符与通配符 (*) 组合将显示与通配符表达式匹配的所有名称。例如，我们可以获得顶级 NumPy 命名空间中包含 load 的所有函数的列表：\nIn [9]: import numpy as np\n\nIn [10]: np.*load*?\nnp.__loader__\nnp.load\nnp.loads\nnp.loadtxt",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Language Basics, IPython, and Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "02.python-basics.html#python-language-basics",
    "href": "02.python-basics.html#python-language-basics",
    "title": "2  Python Language Basics, IPython, and Jupyter Notebooks",
    "section": "2.3 Python Language Basics",
    "text": "2.3 Python Language Basics\n在本节中，我将概述基本的 Python 编程概念和语言机制。在下一章中，我将更详细地介绍 Python 数据结构、函数和其他内置工具。\n\n2.3.1 Language Semantics\nPython 语言设计的特点是强调可读性、简单性和明确性。有些人甚至将其比作“可执行伪代码（executable pseudocode）”。\nIndentation, not braces（缩进，而不是大括号）\nPython 使用空格（制表符或空格）来构建代码，而不是像 R、C++、Java 和 Perl 等许多其他语言那样使用大括号。考虑排序算法中的 for 循环：\nfor x in array:\n    if x &lt; pivot:\n        less.append(x)\n    else:\n        greater.append(x)\n冒号表示缩进代码块的开始，之后所有代码都必须缩进相同的量，直到块的末尾。\n不管你喜欢还是讨厌，重要的空格对于 Python 程序员来说都是一个事实。虽然一开始它可能看起来很陌生，但希望您很快就会习惯它。\n\n\n\n\n\n\nNote\n\n\n\n我强烈建议使用四个空格作为默认缩进，并将制表符替换为四个空格。许多文本编辑器都有一个设置，可以自动用空格替换制表位（这样做！）。IPython 和 Jupyter notebooks 将自动在冒号后面的新行中插入四个空格，并将制表符替换为四个空格。\n\n\n正如您现在所看到的，Python 语句也不需要以分号终止。但是，可以使用分号来分隔一行上的多个语句：\na = 5; b = 6; c = 7\n在 Python 中通常不鼓励将多个语句放在一行上，因为这会降低代码的可读性。\nEverything is an object（一切皆对象）\nPython 语言的一个重要特性是其对象模型的一致性。每个数字、字符串、数据结构、函数、类、模块等都存在于 Python 解释器中自己的“盒子”中，称为 Python object。每个对象都有一个关联的类型（例如整数、字符串或函数）和内部数据。实际上，这使得该语言非常灵活，因为甚至函数也可以像任何其他对象一样对待。\nComments（注释）\nPython 解释器会忽略任何以井号 # 开头的文本。这通常用于向代码添加注释。有时您可能还想排除某些代码块而不删除它们。一种解决方案是注释掉代码：\nresults = []\nfor line in file_handle:\n    # keep the empty lines for now\n    # if len(line) == 0:\n    #   continue\n    results.append(line.replace(\"foo\", \"bar\"))\n注释也可以出现在执行代码行之后。虽然有些程序员喜欢将注释放在特定代码行的前面，但这有时很有用：\nprint(\"Reached this line\")  # Simple status report\nFunction and object method calls（函数和对象方法调用）\n您可以使用括号并传递零个或多个参数来调用函数，还可以选择将返回值分配给变量：\nresult = f(x, y, z)\ng()\nPython 中几乎每个对象都具有附加函数（称为方法），可以访问对象的内部内容。您可以使用以下语法来调用它们：\nobj.some_method(x, y, z)\n函数可以同时采用位置参数和关键字参数：\nresult = f(a, b, c, d=5, e=\"foo\")\n稍后我们将更详细地讨论这一点。\nVariables and argument passing（变量和参数传递）\n在 Python 中分配变量（或名称）时，您正在创建对等号右侧显示的对象的引用。实际上，考虑一个整数列表：\nIn [8]: a = [1, 2, 3]\n假设我们将 a 赋给一个新变量 b：\nIn [9]: b = a\n\nIn [10]: b\nOut[10]: [1, 2, 3]\n在某些语言中，如果 b 的赋值会导致数据 [1, 2, 3] 被复制。在 Python 中，a 和 b 现在实际上指的是同一个对象，即原始列表 [1, 2, 3]（参见 Figure 2.5 的模型）。您可以通过将一个元素附加到 a 然后检查 b 来向自己证明这一点：\nIn [11]: a.append(4)\n\nIn [12]: b\nOut[12]: [1, 2, 3, 4]\n\n\n\nFigure 2.5: Two references for the same object\n\n\n当您在 Python 中处理较大的数据集时，了解 Python 中引用的语义以及复制数据的时间、方式和原因尤其重要。\n\n\n\n\n\n\nNote\n\n\n\n赋值（Assignment）也称为绑定（binding），因为我们将名称绑定到对象。已分配的变量名称有时可能称为绑定变量。\n\n\n当您将对象作为参数传递给函数时，将创建引用原始对象的新局部变量，而不进行任何复制。如果将新对象绑定到函数内部的变量，则不会覆盖函数外部“范围(scope)”（“父范围(parent scope)”）中的同名变量。因此，可以改变可变参数的内部结构。假设我们有以下函数：\nIn [13]: def append_element(some_list, element):\n   ....:     some_list.append(element)\n然后我们有：\nIn [14]: data = [1, 2, 3]\n\nIn [15]: append_element(data, 4)\n\nIn [16]: data\nOut[16]: [1, 2, 3, 4]\nDynamic references, strong types（动态引用、强类型）\nPython 中的变量没有与其关联的固有类型；只需进行赋值，变量就可以引用不同类型的对象。以下情况是没有问题的：\nIn [17]: a = 5\n\nIn [18]: type(a)\nOut[18]: int\n\nIn [19]: a = \"foo\"\n\nIn [20]: type(a)\nOut[20]: str\n变量是特定命名空间中对象的名称；类型信息存储在对象本身中。一些观察者可能会仓促得出结论：Python 不是一种“类型化语言”。这不是真的；考虑这个例子：\nIn [21]: \"5\" + 5\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-21-7fe5aa79f268&gt; in &lt;module&gt;\n----&gt; 1 \"5\" + 5\nTypeError: can only concatenate str (not \"int\") to str\n在某些语言中，字符串 '5' 可能会隐式转换为整数，从而生成 10。在其他语言中，整数 5 可能会转换为字符串，生成连接字符串 '55'。在 Python 中，不允许这种隐式转换。就此而言，我们说 Python 是一种强类型（strongly typed）语言，这意味着每个对象都有特定的类型（或类），并且只有在某些允许的情况下才会发生隐式转换，例如：\nIn [22]: a = 4.5\n\nIn [23]: b = 2\n\n# String formatting, to be visited later\nIn [24]: print(f\"a is {type(a)}, b is {type(b)}\")\na is &lt;class 'float'&gt;, b is &lt;class 'int'&gt;\n\nIn [25]: a / b\nOut[25]: 2.25\n这里，即使 b 是整数，它也会被隐式转换为浮点数以进行除法运算。\n了解对象的类型很重要，并且能够编写可以处理多种不同类型输入的函数非常有用。您可以使用 isinstance 函数检查对象是否是特定类型的实例：\nIn [26]: a = 5\n\nIn [27]: isinstance(a, int)\nOut[27]: True\n如果您想检查对象的类型是否属于元组中存在的类型，则 isinstance 可以接受类型元组：\nIn [28]: a = 5; b = 4.5\n\nIn [29]: isinstance(a, (int, float))\nOut[29]: True\n\nIn [30]: isinstance(b, (int, float))\nOut[30]: True\nAttributes and methods（属性和方法）\nPython 中的对象通常具有属性（存储在对象“内部”的其他 Python 对象）和方法（与对象关联的可以访问对象内部数据的函数）。它们都可以通过语法 &lt;obj.attribute_name&gt; 访问：\nIn [1]: a = \"foo\"\n\nIn [2]: a.&lt;Press Tab&gt;\ncapitalize() index()        isspace()      removesuffix()  startswith()\ncasefold()   isprintable()  istitle()      replace()       strip()\ncenter()     isalnum()      isupper()      rfind()         swapcase()\ncount()      isalpha()      join()         rindex()        title()\nencode()     isascii()      ljust()        rjust()         translate()\nendswith()   isdecimal()    lower()        rpartition()\nexpandtabs() isdigit()      lstrip()       rsplit()\nfind()       isidentifier() maketrans()    rstrip()\nformat()     islower()      partition()    split()\nformat_map() isnumeric()    removeprefix() splitlines()\n属性和方法也可以通过 getattr 函数按名称访问：\nIn [32]: getattr(a, \"split\")\nOut[32]: &lt;function str.split(sep=None, maxsplit=-1)&gt;\n虽然我们不会在本书中广泛使用函数 getattr 以及相关函数 hasattr 和 setattr，但它们可以非常有效地用于编写通用的、可重用的代码。\nDuck typing（鸭子类型）\n通常，您可能不关心对象的类型，而只关心它是否具有某些方法或行为。这有时被称为鸭子类型，俗话说“如果它像鸭子一样行走并且像鸭子一样嘎嘎叫，那么它就是一只鸭子”。例如，如果一个对象实现了迭代器协议（iterator protocol），您可以验证该对象是否可迭代。对于许多对象来说，这意味着它有一个 __iter__ “魔术方法（magic method）”，尽管另一种更好的检查方法是尝试使用 iter 函数：\nIn [33]: def isiterable(obj):\n   ....:     try:\n   ....:         iter(obj)\n   ....:         return True\n   ....:     except TypeError: # not iterable\n   ....:         return False\n对于字符串以及大多数 Python 集合类型，此函数将返回 True：\nIn [34]: isiterable(\"a string\")\nOut[34]: True\n\nIn [35]: isiterable([1, 2, 3])\nOut[35]: True\n\nIn [36]: isiterable(5)\nOut[36]: False\nImports\n在 Python 中，模块只是一个包含 Python 代码、扩展名为 .py 的文件。假设我们有以下模块：\n# some_module.py\nPI = 3.14159\n\ndef f(x):\n    return x + 2\n\ndef g(a, b):\n    return a + b\n如果我们想从同一目录中的另一个文件访问 some_module.py 中定义的变量和函数，我们可以这样做：\nimport some_module\nresult = some_module.f(5)\npi = some_module.PI\n或者：\nfrom some_module import g, PI\nresult = g(5, PI)\n通过使用 as 关键字，您可以为导入指定不同的变量名称：\nimport some_module as sm\nfrom some_module import PI as pi, g as gf\n\nr1 = sm.f(pi)\nr2 = gf(6, pi)\nBinary operators and comparisons（二元运算符和比较）\n大多数二元数学运算和比较都使用其他编程语言中使用的熟悉的数学语法：\nIn [37]: 5 - 7\nOut[37]: -2\n\nIn [38]: 12 + 21.5\nOut[38]: 33.5\n\nIn [39]: 5 &lt;= 2\nOut[39]: False\n有关所有可用的二元运算符，请参阅 Table 2.1。\n\nTable 2.1: Binary operators\n\n\n\n\n\n\nOperation\nDescription\n\n\n\n\na + b\na 加 b\n\n\na - b\na 减 b\n\n\na * b\na 乘 b\n\n\na / b\na 除 b\n\n\na // b\na 除 b 后取整\n\n\na ** b\na 的 b 次方\n\n\na & b\n如果 a 和 b 都为 True，则为 True；对于整数，采用按位 AND\n\n\na | b\n如果 a 或 b 为 True，则为 True；对于整数，采用按位 OR\n\n\na ^ b\n对于布尔值，如果 a 或 b 为 True，但不是两者都为 True，则为 True；对于整数，采用按位 EXCLUSIVE-OR\n\n\na == b\n如果 a 等于 b，则为 True\n\n\na != b\n如果 a 不等于 b，则为 True\n\n\na &lt; b, a &lt;= b\n如果 a 小于（小于或等于）b，则为 True\n\n\na &gt; b, a &gt;= b\n如果 a 大于（大于或等于）b，则为 True\n\n\na is b\n如果 a 和 b 引用同一个 Python 对象，则为 True\n\n\na is not b\n如果 a 和 b 引用不同的 Python 对象，则为 True\n\n\n\n要检查两个变量是否引用同一个对象，请使用 is 关键字。使用 is not 检查两个对象是否不相同：\nIn [40]: a = [1, 2, 3]\n\nIn [41]: b = a\n\nIn [42]: c = list(a)\n\nIn [43]: a is b\nOut[43]: True\n\nIn [44]: a is not c\nOut[44]: True\n由于 list 函数总是创建一个新的 Python 列表（即副本），因此我们可以确定 c 与 a 不同。使用 is 进行比较与 == 运算符不同，因为在这种情况下我们有：\nIn [45]: a == c\nOut[45]: True\nis 和 is not 的一种常见用途是检查变量是否为 None，因为 None 仅有一个实例：\nIn [46]: a = None\n\nIn [47]: a is None\nOut[47]: True\nMutable and immutable objects（可变和不可变对象）\nPython 中的许多对象，例如列表、字典、NumPy 数组和大多数用户定义的类型（类），都是可变的。这意味着可以修改它们包含的对象或值：\nIn [48]: a_list = [\"foo\", 2, [4, 5]]\n\nIn [49]: a_list[2] = (3, 4)\n\nIn [50]: a_list\nOut[50]: ['foo', 2, (3, 4)]\n其他的，如字符串和元组，是不可变的，这意味着它们的内部数据不能更改：\nIn [51]: a_tuple = (3, 5, (4, 5))\n\nIn [52]: a_tuple[1] = \"four\"\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-52-cd2a018a7529&gt; in &lt;module&gt;\n----&gt; 1 a_tuple[1] = \"four\"\nTypeError: 'tuple' object does not support item assignment\n请记住，仅仅因为您可以改变对象并不意味着您总是应该这样做。此类行为称为副作用。例如，在编写函数时，应在函数的文档或注释中明确向用户传达任何副作用。如果可能的话，我建议尝试避免副作用并支持不变性，即使可能涉及可变对象。\n\n\n2.3.2 Scalar Types\nPython 有一小部分内置类型用于处理数值数据、字符串、布尔值（True 或 False）以及日期和时间。这些“单值（single value）”类型有时称为标量类型（scalar types），我们在本书中将它们称为标量（scalars）。有关主要标量类型的列表，请参阅 Table 2.2。日期和时间处理将单独讨论，因为它们是由标准库中的 datetime 模块提供的。\n\nTable 2.2: Standard Python scalar types\n\n\nType\nDescription\n\n\n\n\nNone\nPython “null” 值（None 对象仅存在一个实例）\n\n\nstr\n字符串类型；保存 Unicode 字符串\n\n\nbytes\n原始二进制数据\n\n\nfloat\n双精度浮点数（注意没有单独的 double 类型）\n\n\nbool\n布尔 True 或 False 值\n\n\nint\n任意精度整数\n\n\n\nNumeric types\nPython 中数字的主要类型是 int 和 float。int 可以存储任意大的数字：\nIn [53]: ival = 17239871\n\nIn [54]: ival ** 6\nOut[54]: 26254519291092456596965462913230729701102721\n浮点数用 Python float 类型表示。在底层，每一个都是一个双精度值。它们也可以用科学计数法来表示：\nIn [55]: fval = 7.243\n\nIn [56]: fval2 = 6.78e-5\n不产生整数的整数除法将始终产生浮点数：\nIn [57]: 3 / 2\nOut[57]: 1.5\n要获得 C-style 的整数除法（如果结果不是整数，则舍去小数部分），请使用向下取整除法运算符 //：\nIn [58]: 3 // 2\nOut[58]: 1\nStrings\n许多人使用 Python 是因为它内置的字符串处理功能。您可以使用单引号 ' 或双引号 \" 编写字符串文字（通常首选双引号）：\na = 'one way of writing a string'\nb = \"another way\"\nPython 的字符串类型是 str。\n对于带有换行符的多行字符串，您可以使用三引号，即 ''' 或 \"\"\"：\nc = \"\"\"\nThis is a longer string that\nspans multiple lines\n\"\"\"\n您可能会惊讶这个字符串 c 实际上包含四行文本； \"\"\" 之后的换行符和 lines 之后都包含在字符串中。我们可以使用 c 上的 count 方法来计算新行字符：\nIn [60]: c.count(\"\\n\")\nOut[60]: 3\nPython 字符串是不可变的；你不能修改字符串：\nIn [61]: a = \"this is a string\"\n\nIn [62]: a[10] = \"f\"\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-62-3b2d95f10db4&gt; in &lt;module&gt;\n----&gt; 1 a[10] = \"f\"\nTypeError: 'str' object does not support item assignment\n要解释此错误消息，请从下往上阅读。我们尝试将位置 10 处的字符（“item”）替换为字母\"f\"，但这对于字符串对象是不允许的。如果我们需要修改字符串，我们必须使用创建新字符串的函数或方法，例如字符串 replace 方法：\nIn [63]: b = a.replace(\"string\", \"longer string\")\n\nIn [64]: b\nOut[64]: 'this is a longer string'\n执行此操作后，变量 a 未修改：\nIn [65]: a\nOut[65]: 'this is a string'\n许多 Python 对象可以使用 str 函数转换为字符串：\nIn [66]: a = 5.6\n\nIn [67]: s = str(a)\n\nIn [68]: print(s)\n5.6\n字符串是 Unicode 字符序列，因此可以像其他序列（例如列表和元组）一样对待：\nIn [69]: s = \"python\"\n\nIn [70]: list(s)\nOut[70]: ['p', 'y', 't', 'h', 'o', 'n']\n\nIn [71]: s[:3]\nOut[71]: 'pyt'\n语法 s[:3] 称为切片（slicing），并为多种 Python 序列实现。稍后将对此进行更详细的解释，因为它在本书中被广泛使用。\n反斜杠字符 \\ 是转义字符，这意味着它用于指定特殊字符，例如换行符 \\n 或 Unicode 字符。要编写带有反斜杠的字符串文字，您需要对它们进行转义：\nIn [72]: s = \"12\\\\34\"\n\nIn [73]: print(s)\n12\\34\n如果您的字符串包含很多反斜杠并且没有特殊字符，您可能会发现这有点烦人。幸运的是，您可以在字符串的前导引号前添加 r，这意味着字符应按原样解释：\nIn [74]: s = r\"this\\has\\no\\special\\characters\"\n\nIn [75]: s\nOut[75]: 'this\\\\has\\\\no\\\\special\\\\characters'\nr 代表原始（raw）。\n将两个字符串相加会将它们连接起来并生成一个新字符串：\nIn [76]: a = \"this is the first half \"\n\nIn [77]: b = \"and this is the second half\"\n\nIn [78]: a + b\nOut[78]: 'this is the first half and this is the second half'\n字符串模板或格式化是另一个重要主题。随着 Python 3 的出现，实现此目的的方法数量不断增加，在这里我将简要描述其中一个主要接口的机制。字符串对象有一个 format 方法，可用于将格式化参数替换为字符串，生成一个新字符串：\nIn [79]: template = \"{0:.2f} {1:s} are worth US${2:d}\"\n在这个字符串中：\n\n{0:.2f} 表示将第一个参数格式化为具有两位小数的浮点数。\n{1:s} 表示将第二个参数格式化为字符串。\n{2:d} 表示将第三个参数格式化为精确整数。\n\n为了替换这些格式参数的参数，我们将一系列参数传递给 format 方法：\nIn [80]: template.format(88.46, \"Argentine Pesos\", 1)\nOut[80]: '88.46 Argentine Pesos are worth US$1'\nPython 3.6 引入了一个名为 f-strings（格式化字符串文字的缩写）的新功能，它可以使创建格式化字符串变得更加方便。要创建 f-strings，请在字符串文字前面写入字符 f。在字符串中，将 Python 表达式括在大括号中，以将表达式的值替换为格式化字符串：\nIn [81]: amount = 10\n\nIn [82]: rate = 88.46\n\nIn [83]: currency = \"Pesos\"\n\nIn [84]: result = f\"{amount} {currency} is worth US${amount / rate}\"\n可以使用与上面的字符串模板相同的语法在每个表达式之后添加格式说明符：\nIn [85]: f\"{amount} {currency} is worth US${amount / rate:.2f}\"\nOut[85]: '10 Pesos is worth US$0.11'\n字符串格式化是一个深奥的话题；有多种方法和大量选项和调整可用于控制结果字符串中值的格式。要了解更多信息，请查阅 official Python documentation。\nBytes and Unicode\n在现代 Python（即 Python 3.0 及更高版本）中，Unicode 已成为一流的字符串类型，可以更一致地处理 ASCII 和 non-ASCII 文本。在旧版本的 Python 中，字符串都是字节，没有任何显式的 Unicode 编码。假设您知道字符编码，则可以转换为 Unicode。下面是一个包含非 ASCII 字符的 Unicode 字符串示例：\nIn [86]: val = \"español\"\n\nIn [87]: val\nOut[87]: 'español'\n我们可以使用 encode 方法将此 Unicode 字符串转换为其 UTF-8 字节表示形式：\nIn [88]: val_utf8 = val.encode(\"utf-8\")\n\nIn [89]: val_utf8\nOut[89]: b'espa\\xc3\\xb1ol'\n\nIn [90]: type(val_utf8)\nOut[90]: bytes\n假设您知道 bytes 对象的 Unicode 编码，您可以使用 decode 方法返回：\nIn [91]: val_utf8.decode(\"utf-8\")\nOut[91]: 'español'\n虽然现在最好对任何编码使用 UTF-8，但由于历史原因，您可能会遇到多种不同编码的数据：\nIn [92]: val.encode(\"latin1\")\nOut[92]: b'espa\\xf1ol'\n\nIn [93]: val.encode(\"utf-16\")\nOut[93]: b'\\xff\\xfee\\x00s\\x00p\\x00a\\x00\\xf1\\x00o\\x00l\\x00'\n\nIn [94]: val.encode(\"utf-16le\")\nOut[94]: b'e\\x00s\\x00p\\x00a\\x00\\xf1\\x00o\\x00l\\x00'\n在处理文件的上下文中最常见的是遇到 bytes 对象，其中可能不需要将所有数据隐式解码为 Unicode 字符串。\nBooleans\nPython 中的两个布尔值分别写为 True 和 False。比较和其他条件表达式的计算结果为 True 或 False。布尔值与 and 和 or 关键字组合：\nIn [95]: True and True\nOut[95]: True\n\nIn [96]: False or True\nOut[96]: True\n转换为数字时，False 变为 0，True 变为 1：\nIn [97]: int(False)\nOut[97]: 0\n\nIn [98]: int(True)\nOut[98]: 1\n该关键字 not 会将布尔值从 True 翻转为 False，反之亦然：\nIn [99]: a = True\n\nIn [100]: b = False\n\nIn [101]: not a\nOut[101]: False\n\nIn [102]: not b\nOut[102]: True\nType casting\nstr、bool、int 和 float 类型也是可用于将值转换为这些类型的函数：\nIn [103]: s = \"3.14159\"\n\nIn [104]: fval = float(s)\n\nIn [105]: type(fval)\nOut[105]: float\n\nIn [106]: int(fval)\nOut[106]: 3\n\nIn [107]: bool(fval)\nOut[107]: True\n\nIn [108]: bool(0)\nOut[108]: False\n请注意，大多数非零值在转换为 bool 时会变为 True。\nNone\nNone 是 Python 空值类型：\nIn [109]: a = None\n\nIn [110]: a is None\nOut[110]: True\n\nIn [111]: b = 5\n\nIn [112]: b is not None\nOut[112]: True\nNone 也是函数参数的常见默认值：\ndef add_and_maybe_multiply(a, b, c=None):\n    result = a + b\n\n    if c is not None:\n        result = result * c\n\n    return result\nDates and times\n内置的 Python datetime 模块提供了 datetime、date 和 time 类型。datetime 类型结合了 date 和 time 存储的信息，最常用：\nIn [113]: from datetime import datetime, date, time\n\nIn [114]: dt = datetime(2011, 10, 29, 20, 30, 21)\n\nIn [115]: dt.day\nOut[115]: 29\n\nIn [116]: dt.minute\nOut[116]: 30\n给定一个 datetime 实例，您可以通过调用 datetime 上同名的方法来提取等效的 date 和 time 对象：\nIn [117]: dt.date()\nOut[117]: datetime.date(2011, 10, 29)\n\nIn [118]: dt.time()\nOut[118]: datetime.time(20, 30, 21)\nstrftime 方法将 datetime 格式化为字符串：\nIn [119]: dt.strftime(\"%Y-%m-%d %H:%M\")\nOut[119]: '2011-10-29 20:30'\n有关格式规范的完整列表，请参阅 Table 11.2。\n当您聚合或以其他方式对时间序列数据进行分组时，替换一系列日期时间的 datetime 字段有时会很有用，例如，将 minute 和 second 字段替换为零：\nIn [121]: dt_hour = dt.replace(minute=0, second=0)\n\nIn [122]: dt_hour\nOut[122]: datetime.datetime(2011, 10, 29, 20, 0)\n由于 datetime.datetime 是不可变类型，因此此类方法总是会生成新对象。所以在前面的例子中，dt 并没有被 replace 修改：\nIn [123]: dt\nOut[123]: datetime.datetime(2011, 10, 29, 20, 30, 21)\n两个 datetime 对象的差异产生 datetime.timedelta 类型：\nIn [124]: dt2 = datetime(2011, 11, 15, 22, 30)\n\nIn [125]: delta = dt2 - dt\n\nIn [126]: delta\nOut[126]: datetime.timedelta(days=17, seconds=7179)\n\nIn [127]: type(delta)\nOut[127]: datetime.timedelta\n输出 timedelta(17, 7179) 表示 timedelta 编码了 17 天 7,179 秒的偏移量。\n将 timedelta 添加到 datetime 会产生新的移位日期时间：\nIn [128]: dt\nOut[128]: datetime.datetime(2011, 10, 29, 20, 30, 21)\n\nIn [129]: dt + delta\nOut[129]: datetime.datetime(2011, 11, 15, 22, 30)\n\n\n2.3.3 Control Flow\nPython 有几个内置关键字，用于条件逻辑、循环和其他编程语言中的其他标准控制流概念。\nif, elif, and else\nif 语句是最著名的控制流语句类型之一。它检查一个条件，如果为 True，则评估后面块中的代码：\nx = -5\nif x &lt; 0:\n    print(\"It's negative\")\n如果所有条件都为 False，则 if 语句后面可以选择跟随一个或多个 elif 块以及一个包罗万象的 else 块：\nif x &lt; 0:\n    print(\"It's negative\")\nelif x == 0:\n    print(\"Equal to zero\")\nelif 0 &lt; x &lt; 5:\n    print(\"Positive but smaller than 5\")\nelse:\n    print(\"Positive and larger than or equal to 5\")\n如果任何条件为 True，则不会再到达 elif 或 else 块。对于使用 and 或 or 的复合条件，条件从左到右计算并且会短路：\nIn [130]: a = 5; b = 7\n\nIn [131]: c = 8; d = 4\n\nIn [132]: if a &lt; b or c &gt; d:\n   .....:     print(\"Made it\")\nMade it\n在此示例中，比较 c &gt; d 永远不会被计算，因为第一个比较为 True。\n也可以进行链式比较：\nIn [133]: 4 &gt; 3 &gt; 2 &gt; 1\nOut[133]: True\nfor loops\nfor 循环用于迭代集合（如列表或元组）或迭代器。for 循环的标准语法是：\nfor value in collection:\n    # do something with value\n您可以使用 continue 关键字将 for 循环推进到下一次迭代，跳过块的其余部分。考虑以下代码，它将列表中的整数相加并跳过 None 值：\nsequence = [1, 2, None, 4, None, 5]\ntotal = 0\nfor value in sequence:\n    if value is None:\n        continue\n    total += value\n可以使用 break 关键字一起退出 for 循环。此代码对列表中的元素求和，直到达到 5：\nsequence = [1, 2, 0, 4, 6, 5, 2, 1]\ntotal_until_5 = 0\nfor value in sequence:\n    if value == 5:\n        break\n    total_until_5 += value\nbreak 关键字仅终止最内层的 for 循环；任何外部 for 循环将继续运行：\nIn [134]: for i in range(4):\n   .....:     for j in range(4):\n   .....:         if j &gt; i:\n   .....:             break\n   .....:         print((i, j))\n   .....:\n(0, 0)\n(1, 0)\n(1, 1)\n(2, 0)\n(2, 1)\n(2, 2)\n(3, 0)\n(3, 1)\n(3, 2)\n(3, 3)\n正如我们将更详细地看到的，如果集合或迭代器中的元素是序列（例如元组或列表），则可以方便地将它们解包到 for 循环语句中的变量中：\nfor a, b, c in iterator:\n    # do something\nwhile loops\nwhile 循环指定一个条件和一个要执行的代码块，直到条件计算结果为 False 或循环以 break 显式结束：\nx = 256\ntotal = 0\nwhile x &gt; 0:\n    if total &gt; 500:\n        break\n    total += x\n    x = x // 2\npass\npass 是 Python 中的“no-op”（或“不执行任何操作”）语句。它可以用在不采取任何操作的块中（或者作为尚未实现的代码的占位符）；它是必需的，只是因为 Python 使用空格来分隔块：\nif x &lt; 0:\n    print(\"negative!\")\nelif x == 0:\n    # TODO: put something smart here\n    pass\nelse:\n    print(\"positive!\")\nrange\nrange 函数生成均匀间隔的整数序列：\nIn [135]: range(10)\nOut[135]: range(0, 10)\n\nIn [136]: list(range(10))\nOut[136]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n可以给出开始、结束和步骤（可能是负数）：\nIn [137]: list(range(0, 20, 2))\nOut[137]: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\nIn [138]: list(range(5, 0, -1))\nOut[138]: [5, 4, 3, 2, 1]\n正如您所看到的，range 生成直到但不包括端点的整数。range 的常见用途是按索引迭代序列：\nIn [139]: seq = [1, 2, 3, 4]\n\nIn [140]: for i in range(len(seq)):\n   .....:     print(f\"element {i}: {seq[i]}\")\nelement 0: 1\nelement 1: 2\nelement 2: 3\nelement 3: 4\n虽然您可以使用 list 等函数将 range 生成的所有整数存储在其他数据结构中，但通常默认的迭代器形式就是您想要的。此代码片段将 0 到 99,999 之间所有 3 或 5 的倍数的数字相加：\nIn [141]: total = 0\n\nIn [142]: for i in range(100_000):\n   .....:     # % is the modulo operator\n   .....:     if i % 3 == 0 or i % 5 == 0:\n   .....:         total += i\n\nIn [143]: print(total)\n2333316668\n虽然生成的范围可以任意大，但任何给定时间的内存使用量可能非常小。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Language Basics, IPython, and Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "02.python-basics.html#conclusion",
    "href": "02.python-basics.html#conclusion",
    "title": "2  Python Language Basics, IPython, and Jupyter Notebooks",
    "section": "2.4 Conclusion",
    "text": "2.4 Conclusion\n本章简要介绍了一些基本的 Python 语言概念以及 IPython 和 Jupyter 编程环境。在下一章中，我将讨论许多内置数据类型、函数和输入输出实用程序，这些内容将在本书的其余部分中不断使用。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Language Basics, IPython, and Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "03.python-builtin.html",
    "href": "03.python-builtin.html",
    "title": "3  Built-In Data Structures, Functions, and Files",
    "section": "",
    "text": "3.1 Data Structures and Sequences\nPython 的数据结构简单但功能强大。掌握它们的使用是成为熟练的 Python 程序员的关键部分。我们从元组、列表和字典开始，它们是一些最常用的序列类型。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Built-In Data Structures, Functions, and Files</span>"
    ]
  },
  {
    "objectID": "03.python-builtin.html#data-structures-and-sequences",
    "href": "03.python-builtin.html#data-structures-and-sequences",
    "title": "3  Built-In Data Structures, Functions, and Files",
    "section": "",
    "text": "3.1.1 Tuple\n元组（tuples）是固定长度、不可变的 Python 对象序列，一旦分配就无法更改。创建一个最简单的方法是使用括号中的逗号分隔值序列：\nIn [2]: tup = (4, 5, 6)\n\nIn [3]: tup\nOut[3]: (4, 5, 6)\n在许多情况下，括号可以省略，所以这里我们也可以写成：\nIn [4]: tup = 4, 5, 6\n\nIn [5]: tup\nOut[5]: (4, 5, 6)\n您可以通过调用 tuple 将任何序列或迭代器转换为元组：\nIn [6]: tuple([4, 0, 2])\nOut[6]: (4, 0, 2)\n\nIn [7]: tup = tuple('string')\n\nIn [8]: tup\nOut[8]: ('s', 't', 'r', 'i', 'n', 'g')\n与大多数其他序列类型一样，可以使用方括号 [] 访问元素。与 C、C++、Java 和许多其他语言一样，序列在 Python 中是从 0 索引的：\nIn [9]: tup[0]\nOut[9]: 's'\n当您在更复杂的表达式中定义元组时，通常需要将值括在括号中，如创建元组的元组的示例所示：\nIn [10]: nested_tup = (4, 5, 6), (7, 8)\n\nIn [11]: nested_tup\nOut[11]: ((4, 5, 6), (7, 8))\n\nIn [12]: nested_tup[0]\nOut[12]: (4, 5, 6)\n\nIn [13]: nested_tup[1]\nOut[13]: (7, 8)\n虽然存储在元组中的对象本身可能是可变的，但一旦创建元组，就无法修改每个槽中存储的对象：\nIn [14]: tup = tuple(['foo', [1, 2], True])\n\nIn [15]: tup[2] = False\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-15-b89d0c4ae599&gt; in &lt;module&gt;\n----&gt; 1 tup[2] = False\nTypeError: 'tuple' object does not support item assignment\n如果元组内的对象是可变的，例如列表，您可以就地修改它：\nIn [16]: tup[1].append(3)\n\nIn [17]: tup\nOut[17]: ('foo', [1, 2, 3], True)\n您可以使用 + 运算符连接元组以生成更长的元组：\nIn [18]: (4, None, 'foo') + (6, 0) + ('bar',)\nOut[18]: (4, None, 'foo', 6, 0, 'bar')\n与列表一样，将元组乘以整数会产生连接元组的多个副本的效果：\nIn [19]: ('foo', 'bar') * 4\nOut[19]: ('foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'bar')\n请注意，对象本身不会被复制，只会复制对它们的引用。\nUnpacking tuples（元组拆包）\n如果您尝试分配给类似元组的变量表达式，Python 将尝试拆包（unpack）等号右侧的值：\nIn [20]: tup = (4, 5, 6)\n\nIn [21]: a, b, c = tup\n\nIn [22]: b\nOut[22]: 5\n即使是带有嵌套元组的序列也可以被拆包：\nIn [23]: tup = 4, 5, (6, 7)\n\nIn [24]: a, b, (c, d) = tup\n\nIn [25]: d\nOut[25]: 7\n使用此功能，您可以轻松交换变量名称，这项任务在许多语言中可能如下所示：\ntmp = a\na = b\nb = tmp\n但是，在 Python 中，交换可以这样完成：\nIn [26]: a, b = 1, 2\n\nIn [27]: a\nOut[27]: 1\n\nIn [28]: b\nOut[28]: 2\n\nIn [29]: b, a = a, b\n\nIn [30]: a\nOut[30]: 2\n\nIn [31]: b\nOut[31]: 1\n变量拆包的常见用途是迭代元组或列表的序列：\nIn [32]: seq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n\nIn [33]: for a, b, c in seq:\n   ....:     print(f'a={a}, b={b}, c={c}')\na=1, b=2, c=3\na=4, b=5, c=6\na=7, b=8, c=9\n另一个常见用途是从函数返回多个值。稍后我将更详细地介绍这一点。\n在某些情况下，您可能希望从元组的开头“提取”一些元素。有一种特殊的语法可以做到这一点，*rest，它也用在函数签名中来捕获任意长的位置参数列表：\nIn [34]: values = 1, 2, 3, 4, 5\n\nIn [35]: a, b, *rest = values\n\nIn [36]: a\nOut[36]: 1\n\nIn [37]: b\nOut[37]: 2\n\nIn [38]: rest\nOut[38]: [3, 4, 5]\n这个 rest 部分有时是你想要丢弃的东西；rest 名称没有什么特别的。按照惯例，许多 Python 程序员会使用下划线 (_) 来表示不需要的变量：\nIn [39]: a, b, *_ = values\nTuple methods\n由于元组的大小和内容无法修改，因此实例方法非常简单。一个特别有用的方法（也可用于列表）是 count，它计算某个值出现的次数：\nIn [40]: a = (1, 2, 2, 2, 3, 4, 2)\n\nIn [41]: a.count(2)\nOut[41]: 4\n\n\n3.1.2 List\n与元组相比，列表（lists）是可变长度的，并且可以就地修改其内容。列表是可变的。您可以使用方括号 [] 或使用 list 类型函数来定义它们：\nIn [42]: a_list = [2, 3, 7, None]\n\nIn [43]: tup = (\"foo\", \"bar\", \"baz\")\n\nIn [44]: b_list = list(tup)\n\nIn [45]: b_list\nOut[45]: ['foo', 'bar', 'baz']\n\nIn [46]: b_list[1] = \"peekaboo\"\n\nIn [47]: b_list\nOut[47]: ['foo', 'peekaboo', 'baz']\n列表和元组在语义上相似（尽管元组不能修改）并且可以在许多函数中互换使用。\nlist 内置函数在数据处理中经常使用，作为具体化迭代器或生成器表达式的一种方式：\nIn [48]: gen = range(10)\n\nIn [49]: gen\nOut[49]: range(0, 10)\n\nIn [50]: list(gen)\nOut[50]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nAdding and removing elements（添加和删​​除元素）\n可以使用 append 方法将元素追加到列表的末尾：\nIn [51]: b_list.append(\"dwarf\")\n\nIn [52]: b_list\nOut[52]: ['foo', 'peekaboo', 'baz', 'dwarf']\n使用 insert 可以在列表中的特定位置插入元素：\nIn [53]: b_list.insert(1, \"red\")\n\nIn [54]: b_list\nOut[54]: ['foo', 'red', 'peekaboo', 'baz', 'dwarf']\n插入索引必须介于 0 和列表长度（含）之间。\n\n\n\n\n\n\nWarning\n\n\n\n与 append 相比，insert 的计算成本较高，因为必须在内部移动对后续元素的引用，以便为新元素腾出空间。如果您需要在序列的开头和结尾插入元素，您可能希望探索 collections.deque，这是一个双端队列，它为此目的进行了优化，可以在 Python 标准库中找到。\n\n\ninsert 的逆操作是 pop，它删除并返回特定索引处的元素：\nIn [55]: b_list.pop(2)\nOut[55]: 'peekaboo'\n\nIn [56]: b_list\nOut[56]: ['foo', 'red', 'baz', 'dwarf']\n可以使用 remove 按值删除元素，它找到第一个这样的值并将其从列表中删除：\nIn [57]: b_list.append(\"foo\")\n\nIn [58]: b_list\nOut[58]: ['foo', 'red', 'baz', 'dwarf', 'foo']\n\nIn [59]: b_list.remove(\"foo\")\n\nIn [60]: b_list\nOut[60]: ['red', 'baz', 'dwarf', 'foo']\n如果性能不是问题，通过使用 append 和 remove，您可以使用 Python 列表作为类似集合的数据结构（尽管 Python 有实际的集合对象，稍后讨论）。\n使用 in 关键字检查列表是否包含值：\nIn [61]: \"dwarf\" in b_list\nOut[61]: True\n关键字 not 可用于否定 in：\nIn [62]: \"dwarf\" not in b_list\nOut[62]: False\n检查列表是否包含值比使用字典和集合（稍后介绍）慢很多，因为 Python 对列表的值进行线性扫描，而它可以检查其他值（基于哈希表）在恒定的时间内。\nConcatenating and combining lists（连接和组合列表）\n与元组类似，使用 + 将两个列表添加在一起将它们连接起来：\nIn [63]: [4, None, \"foo\"] + [7, 8, (2, 3)]\nOut[63]: [4, None, 'foo', 7, 8, (2, 3)]\n如果您已经定义了一个列表，则可以使用 extend 方法向其附加多个元素：\nIn [64]: x = [4, None, \"foo\"]\n\nIn [65]: x.extend([7, 8, (2, 3)])\n\nIn [66]: x\nOut[66]: [4, None, 'foo', 7, 8, (2, 3)]\n请注意，通过加法进行列表串联是一项相对昂贵的操作，因为必须创建新列表并复制对象。使用 extend 将元素追加到现有列表中，尤其是在构建大型列表时，通常更可取。因此：\neverything = []\nfor chunk in list_of_lists:\n    everything.extend(chunk)\n比串联替代方案更快：\neverything = []\nfor chunk in list_of_lists:\n    everything = everything + chunk\nSorting（排序）\n您可以通过调用其 sort 函数对列表进行就地排序（无需创建新对象）：\nIn [67]: a = [7, 2, 5, 1, 3]\n\nIn [68]: a.sort()\n\nIn [69]: a\nOut[69]: [1, 2, 3, 5, 7]\nsort 有一些偶尔会派上用场的选项。一是能够传递辅助排序键，即生成用于对对象进行排序的值的函数。例如，我们可以按字符串的长度对字符串集合进行排序：\nIn [70]: b = [\"saw\", \"small\", \"He\", \"foxes\", \"six\"]\n\nIn [71]: b.sort(key=len)\n\nIn [72]: b\nOut[72]: ['He', 'saw', 'six', 'small', 'foxes']\n很快，我们将看到 sorted 函数，它可以生成一般序列的排序副本。\nSlicing（切片）\n您可以使用切片表示法来选择大多数序列类型的部分，其基本形式由传递给索引运算符 [] 的 start:stop 组成：\nIn [73]: seq = [7, 2, 3, 7, 5, 6, 0, 1]\n\nIn [74]: seq[1:5]\nOut[74]: [2, 3, 7, 5]\n切片也可以分配一个序列：\nIn [75]: seq[3:5] = [6, 3]\n\nIn [76]: seq\nOut[76]: [7, 2, 3, 6, 3, 6, 0, 1]\n虽然包含 start 索引处的元素，但不包含 stop 索引处的元素，因此结果中的元素数量为 stop - start。\nstart 或 stop 都可以省略，在这种情况下，它们分别默认为序列的开始和序列的结束：\nIn [77]: seq[:5]\nOut[77]: [7, 2, 3, 6, 3]\n\nIn [78]: seq[3:]\nOut[78]: [6, 3, 6, 0, 1]\n负索引相对于末尾对序列进行切片：\nIn [79]: seq[-4:]\nOut[79]: [3, 6, 0, 1]\n\nIn [80]: seq[-6:-2]\nOut[80]: [3, 6, 3, 6]\n切片语义需要一些时间来适应，特别是如果您来自 R 或 MATLAB。请参阅 Figure 3.1，了解使用正整数和负整数进行切片的有用说明。在图中，索引显示在“bin 边缘”，以帮助显示使用正索引或负索引开始和停止切片选择的位置。\n\n\n\nFigure 3.1: Illustration of Python slicing conventions\n\n\n还可以在第二个冒号之后使用步骤来获取所有其他元素：\nIn [81]: seq[::2]\nOut[81]: [7, 3, 3, 0]\n一个巧妙的用法是传递 -1，它具有反转列表或元组的有用效果：\nIn [82]: seq[::-1]\nOut[82]: [1, 0, 6, 3, 6, 3, 2, 7]\n\n\n3.1.3 Dictionary\n字典或 dict 可能是最重要的内置 Python 数据结构。在其他编程语言中，字典有时称为哈希映射或关联数组。字典存储键值对的集合，其中键和值是 Python 对象。每个键都与一个值相关联，以便在给定特定键的情况下可以方便地检索、插入、修改或删除值。创建字典的一种方法是使用大括号 {} 和冒号来分隔键和值：\nIn [83]: empty_dict = {}\n\nIn [84]: d1 = {\"a\": \"some value\", \"b\": [1, 2, 3, 4]}\n\nIn [85]: d1\nOut[85]: {'a': 'some value', 'b': [1, 2, 3, 4]}\n您可以使用与访问列表或元组元素相同的语法来访问、插入或设置元素：\nIn [86]: d1[7] = \"an integer\"\n\nIn [87]: d1\nOut[87]: {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}\n\nIn [88]: d1[\"b\"]\nOut[88]: [1, 2, 3, 4]\n您可以使用与检查列表或元组是否包含值相同的语法来检查字典是否包含键：\nIn [89]: \"b\" in d1\nOut[89]: True\n您可以使用 del 关键字或 pop 方法（同时返回值并删除键）来删除值：\nIn [90]: d1[5] = \"some value\"\n\nIn [91]: d1\nOut[91]: \n{'a': 'some value',\n 'b': [1, 2, 3, 4],\n 7: 'an integer',\n 5: 'some value'}\n\nIn [92]: d1[\"dummy\"] = \"another value\"\n\nIn [93]: d1\nOut[93]: \n{'a': 'some value',\n 'b': [1, 2, 3, 4],\n 7: 'an integer',\n 5: 'some value',\n 'dummy': 'another value'}\n\nIn [94]: del d1[5]\n\nIn [95]: d1\nOut[95]: \n{'a': 'some value',\n 'b': [1, 2, 3, 4],\n 7: 'an integer',\n 'dummy': 'another value'}\n\nIn [96]: ret = d1.pop(\"dummy\")\n\nIn [97]: ret\nOut[97]: 'another value'\n\nIn [98]: d1\nOut[98]: {'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}\nkeys 和 values 方法分别为您提供字典的键和值的迭代器。键的顺序取决于它们的插入顺序，这些函数以相同的顺序输出键和值：\nIn [99]: list(d1.keys())\nOut[99]: ['a', 'b', 7]\n\nIn [100]: list(d1.values())\nOut[100]: ['some value', [1, 2, 3, 4], 'an integer']\n如果需要迭代键和值，可以使用 items 方法将键和值作为 2-元组进行迭代：\nIn [101]: list(d1.items())\nOut[101]: [('a', 'some value'), ('b', [1, 2, 3, 4]), (7, 'an integer')]\n您可以使用 update 方法将一个字典合并到另一个字典中：\nIn [102]: d1.update({\"b\": \"foo\", \"c\": 12})\n\nIn [103]: d1\nOut[103]: {'a': 'some value', 'b': 'foo', 7: 'an integer', 'c': 12}\nupdate 方法会就地更改字典，因此传递给 update 的数据中的任何现有键都将丢弃其旧值。\nCreating dictionaries from sequences（从序列创建字典）\n偶尔会出现想要在字典中按元素配对的两个序列，这是很常见的。作为第一步，您可能会编写如下代码：\nmapping = {}\nfor key, value in zip(key_list, value_list):\n    mapping[key] = value\n由于字典本质上是 2-元组的集合，因此 dict 函数接受 2-元组列表：\nIn [104]: tuples = zip(range(5), reversed(range(5)))\n\nIn [105]: tuples\nOut[105]: &lt;zip at 0x17d604d00&gt;\n\nIn [106]: mapping = dict(tuples)\n\nIn [107]: mapping\nOut[107]: {0: 4, 1: 3, 2: 2, 3: 1, 4: 0}\n稍后我们将讨论字典推导式，这是构建字典的另一种方式。\nDefault values\n常见的逻辑如下：\nif key in some_dict:\n    value = some_dict[key]\nelse:\n    value = default_value\n因此，字典方法 get 和 pop 可以返回一个默认值，这样上面的 if-else 块就可以简单地写成：\nvalue = some_dict.get(key, default_value)\n如果键不存在，get 默认情况下将返回 None，而 pop 将引发异常。通过设置值，字典中的值可能是另一种集合，例如列表。例如，您可以想象将单词列表按其首字母分类为列表字典：\nIn [108]: words = [\"apple\", \"bat\", \"bar\", \"atom\", \"book\"]\n\nIn [109]: by_letter = {}\n\nIn [110]: for word in words:\n   .....:     letter = word[0]\n   .....:     if letter not in by_letter:\n   .....:         by_letter[letter] = [word]\n   .....:     else:\n   .....:         by_letter[letter].append(word)\n   .....:\n\nIn [111]: by_letter\nOut[111]: {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}\nsetdefault 字典方法可用于简化此工作流程。前面的 for 循环可以重写为：\nIn [112]: by_letter = {}\n\nIn [113]: for word in words:\n   .....:     letter = word[0]\n   .....:     by_letter.setdefault(letter, []).append(word)\n   .....:\n\nIn [114]: by_letter\nOut[114]: {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}\n内置的 collections 模块有一个有用的类 defaultdict，这使得这变得更加容易。要创建一个，您可以传递一个类型或函数来为字典中的每个槽生成默认值：\nIn [115]: from collections import defaultdict\n\nIn [116]: by_letter = defaultdict(list)\n\nIn [117]: for word in words:\n   .....:     by_letter[word[0]].append(word)\nValid dictionary key types（有效的字典键类型）\n虽然字典的值可以是任何 Python 对象，但键通常必须是不可变对象，例如标量类型（int、float、string）或元组（元组中的所有对象也必须是不可变的）。这里的技术术语是可哈希性（hashability）。您可以使用 hash 函数检查对象是否可哈希（可以用作字典中的键）：\nIn [118]: hash(\"string\")\nOut[118]: 4022908869268713487\n\nIn [119]: hash((1, 2, (2, 3)))\nOut[119]: -9209053662355515447\n\nIn [120]: hash((1, 2, [2, 3])) # fails because lists are mutable\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-120-473c35a62c0b&gt; in &lt;module&gt;\n----&gt; 1 hash((1, 2, [2, 3])) # fails because lists are mutable\nTypeError: unhashable type: 'list'\n通常，您在使用 hash 函数时看到的哈希值取决于您所使用的 Python 版本。\n要使用列表作为键，一种选择是将其转换为元组，只要它的元素也可以是，就可以对其进行哈希处理：\nIn [121]: d = {}\n\nIn [122]: d[tuple([1, 2, 3])] = 5\n\nIn [123]: d\nOut[123]: {(1, 2, 3): 5}\n\n\n3.1.4 Set\n集合（set）是唯一元素的无序集合。可以通过两种方式创建集合：通过 set 函数或通过带花括号的集合文字：\nIn [124]: set([2, 2, 2, 1, 3, 3])\nOut[124]: {1, 2, 3}\n\nIn [125]: {2, 2, 2, 1, 3, 3}\nOut[125]: {1, 2, 3}\n集合支持数学集合运算，例如并集、交集、差值和对称差值。考虑这两个示例集：\nIn [126]: a = {1, 2, 3, 4, 5}\n\nIn [127]: b = {3, 4, 5, 6, 7, 8}\n这两个集合的并集是任一集合中出现的不同元素的集合。这可以使用 union 方法或 | 二元运算符来计算：\nIn [128]: a.union(b)\nOut[128]: {1, 2, 3, 4, 5, 6, 7, 8}\n\nIn [129]: a | b\nOut[129]: {1, 2, 3, 4, 5, 6, 7, 8}\n交集包含两个集合中出现的元素。可以使用 & 运算符或 intersection 方法：\nIn [130]: a.intersection(b)\nOut[130]: {3, 4, 5}\n\nIn [131]: a & b\nOut[131]: {3, 4, 5}\n有关常用设置方法的列表，请参阅 Table 3.1。\n\nTable 3.1: Python set operations\n\n\n\n\n\n\n\nFunction\nAlternative syntax\nDescription\n\n\n\n\na.add(x)\nN/A\n添加元素 x 到集合 a\n\n\na.clear()\nN/A\n重新设置 a 为空状态，丢弃其所有元素\n\n\na.remove(x)\nN/A\n从集合 a 中删除元素 x\n\n\na.pop()\nN/A\n从集合 a 中删除任意元素，如果集合为空则引发 KeyError\n\n\na.union(b)\na | b\na 和 b 的并集\n\n\na.update(b)\na |= b\n将 a 的内容设置为 a 和 b 的并集\n\n\na.intersection(b)\na & b\na 和 b 的交集\n\n\na.intersection_update(b)\na &= b\n将 a 的内容设置为 a 和 b 的交集\n\n\na.difference(b)\na - b\na 中有 b 中没有的元素\n\n\na.difference_update(b)\na -= b\n将 a 设置为 a 中有 b 中没有的元素\n\n\na.symmetric_difference(b)\na ^ b\na 或 b 中有，但不能同时存在的元素\n\n\na.symmetric_difference_update(b)\na ^= b\n将 a 设置为 a 或 b 中有，但不能同时存在的元素\n\n\na.issubset(b)\n&lt;=\n如果 a 的元素全部包含在 b 中，则为 True\n\n\na.issuperset(b)\n&gt;=\n如果 b 的元素全部包含在 a 中，则为 True\n\n\na.isdisjoint(b)\nN/A\n如果 a 和 b 没有共同元素，则为 True\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n如果将不是集合的输入传递给 union 和 intersection 等方法，Python 会在执行操作之前将输入转换为集合。使用二元运算符时，两个对象都必须已设置。\n\n\n所有逻辑集合操作都有就地对应项，这使您能够用结果替换操作左侧的集合内容。对于非常大的集合，这可能更有效：\nIn [132]: c = a.copy()\n\nIn [133]: c |= b\n\nIn [134]: c\nOut[134]: {1, 2, 3, 4, 5, 6, 7, 8}\n\nIn [135]: d = a.copy()\n\nIn [136]: d &= b\n\nIn [137]: d\nOut[137]: {3, 4, 5}\n与字典键一样，集合元素通常必须是不可变的，并且它们必须是可哈希的（hashable）（这意味着对值调用 hash 不会引发异常）。为了在集合中存储类似列表的元素（或其他可变序列），您可以将它们转换为元组：\nIn [138]: my_data = [1, 2, 3, 4]\n\nIn [139]: my_set = {tuple(my_data)}\n\nIn [140]: my_set\nOut[140]: {(1, 2, 3, 4)}\n您还可以检查一个集合是否是另一个集合的子集（包含在其中）或超集（包含其所有元素）：\nIn [141]: a_set = {1, 2, 3, 4, 5}\n\nIn [142]: {1, 2, 3}.issubset(a_set)\nOut[142]: True\n\nIn [143]: a_set.issuperset({1, 2, 3})\nOut[143]: True\n集合相等当且仅当它们的内容相等：\nIn [144]: {1, 2, 3} == {3, 2, 1}\nOut[144]: True\n\n\n3.1.5 Built-In Sequence Functions\nPython 有一些有用的序列函数，您应该熟悉它们并在任何机会使用它们。\nenumerate（枚举）\n在迭代序列时，通常希望跟踪当前项的索引。自己动手的方法如下所示：\nindex = 0\nfor value in collection:\n   # do something with value\n   index += 1\n由于这种情况很常见，Python 有一个内置函数 enumerate，它返回 (i, value) 元组序列：\nfor index, value in enumerate(collection):\n   # do something with value\nsorted（排序）\nsorted 函数从任何序列的元素中返回一个新的排序列表：\nIn [145]: sorted([7, 1, 2, 6, 0, 3, 2])\nOut[145]: [0, 1, 2, 2, 3, 6, 7]\n\nIn [146]: sorted(\"horse race\")\nOut[146]: [' ', 'a', 'c', 'e', 'e', 'h', 'o', 'r', 'r', 's']\nsorted 函数接受与列表 sort 方法相同的参数。\nzip\nzip 将多个列表、元组或其他序列的元素“配对”以创建元组列表：\nIn [147]: seq1 = [\"foo\", \"bar\", \"baz\"]\n\nIn [148]: seq2 = [\"one\", \"two\", \"three\"]\n\nIn [149]: zipped = zip(seq1, seq2)\n\nIn [150]: list(zipped)\nOut[150]: [('foo', 'one'), ('bar', 'two'), ('baz', 'three')]\nzip 可以采用任意数量的序列，它产生的元素数量由最短序列决定：\nIn [151]: seq3 = [False, True]\n\nIn [152]: list(zip(seq1, seq2, seq3))\nOut[152]: [('foo', 'one', False), ('bar', 'two', True)]\nzip 的常见用法是同时迭代多个序列，也可能与 enumerate 结合使用：\nIn [153]: for index, (a, b) in enumerate(zip(seq1, seq2)):\n   .....:     print(f\"{index}: {a}, {b}\")\n   .....:\n0: foo, one\n1: bar, two\n2: baz, three\nreversed（倒序）\nreversed 以相反的顺序迭代序列的元素：\nIn [154]: list(reversed(range(10)))\nOut[154]: [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n请记住，reverse 是一个生成器（稍后将更详细地讨论），因此它不会创建反转序列，直到具体化（例如，使用 list 或 for 循环）。\n\n\n3.1.6 List, Set, and Dictionary Comprehensions\n列表推导式是一种方便且广泛使用的 Python 语言功能。它们允许您通过过滤集合的元素、将通过过滤器的元素转换为一个简洁的表达式来简洁地形成一个新列表。它们采用基本形式：\n[expr for value in collection if condition]\n这相当于以下 for 循环：\nresult = []\nfor value in collection:\n    if condition:\n        result.append(expr)\n过滤条件可以省略，只留下表达式。例如，给定一个字符串列表，我们可以过滤掉长度为 2 或更小的字符串，并将它们转换为大写，如下所示：\nIn [155]: strings = [\"a\", \"as\", \"bat\", \"car\", \"dove\", \"python\"]\n\nIn [156]: [x.upper() for x in strings if len(x) &gt; 2]\nOut[156]: ['BAT', 'CAR', 'DOVE', 'PYTHON']\n集合和字典推导式是一种自然的扩展，以惯用的类似方式而不是列表生成集合和字典。\n字典推导式如下所示：\ndict_comp = {key-expr: value-expr for value in collection\n             if condition}\n集合推导式看起来与等效的列表推导式相似，只是使用大括号而不是方括号：\nset_comp = {expr for value in collection if condition}\n与列表推导式一样，集合推导式和字典推导式大多都很方便，但它们同样可以使代码更易于编写和阅读。考虑之前的字符串列表。假设我们想要一个仅包含集合中字符串长度的集合；我们可以使用集合推导式轻松计算：\nIn [157]: unique_lengths = {len(x) for x in strings}\n\nIn [158]: unique_lengths\nOut[158]: {1, 2, 3, 4, 6}\n我们还可以使用稍后介绍的 map 函数来更功能地表达这一点：\nIn [159]: set(map(len, strings))\nOut[159]: {1, 2, 3, 4, 6}\n作为一个简单的字典推导式示例，我们可以创建这些字符串的查找映射以查找它们在列表中的位置：\nIn [160]: loc_mapping = {value: index for index, value in enumerate(strings)}\n\nIn [161]: loc_mapping\nOut[161]: {'a': 0, 'as': 1, 'bat': 2, 'car': 3, 'dove': 4, 'python': 5}\nNested list comprehensions（嵌套列表推导式）\n假设我们有一个包含一些英语和西班牙语名称的列表列表：\nIn [162]: all_data = [[\"John\", \"Emily\", \"Michael\", \"Mary\", \"Steven\"],\n   .....:             [\"Maria\", \"Juan\", \"Javier\", \"Natalia\", \"Pilar\"]]\n假设我们想要获取一个包含所有带有两个或多个 a 的名称的列表。我们当然可以通过一个简单的 for 循环来做到这一点：\nIn [163]: names_of_interest = []\n\nIn [164]: for names in all_data:\n   .....:     enough_as = [name for name in names if name.count(\"a\") &gt;= 2]\n   .....:     names_of_interest.extend(enough_as)\n   .....:\n\nIn [165]: names_of_interest\nOut[165]: ['Maria', 'Natalia']\n实际上，您可以将整个操作包装在单个嵌套列表推导式中，如下所示：\nIn [166]: result = [name for names in all_data for name in names\n   .....:           if name.count(\"a\") &gt;= 2]\n\nIn [167]: result\nOut[167]: ['Maria', 'Natalia']\n一开始，嵌套列表推导式有点难以理解。列表推导式的 for 部分按照嵌套顺序排列，任何过滤条件都像以前一样放在最后。这是另一个例子，我们将整数元组列表“展平（flatten）”为简单的整数列表：\nIn [168]: some_tuples = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n\nIn [169]: flattened = [x for tup in some_tuples for x in tup]\n\nIn [170]: flattened\nOut[170]: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n请记住，如果您编写嵌套的 for 循环而不是列表推导式，则 for 表达式的顺序将是相同的：\nflattened = []\n\nfor tup in some_tuples:\n    for x in tup:\n        flattened.append(x)\n您可以有任意多个嵌套级别，但如果您有超过两层或三层嵌套，您可能应该开始质疑从代码可读性的角度来看这是否有意义。区分刚刚显示的语法和列表推导式中的列表推导式非常重要，这也是完全有效的：\nIn [172]: [[x for x in tup] for tup in some_tuples]\nOut[172]: [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n这会生成一个列表的列表，而不是所有内部元素的扁平列表。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Built-In Data Structures, Functions, and Files</span>"
    ]
  },
  {
    "objectID": "03.python-builtin.html#functions",
    "href": "03.python-builtin.html#functions",
    "title": "3  Built-In Data Structures, Functions, and Files",
    "section": "3.2 Functions",
    "text": "3.2 Functions\n函数是 Python 中代码组织和重用的主要也是最重要的方法。根据经验，如果您预计需要多次重复相同或非常相似的代码，那么编写可重用函数可能是值得的。函数还可以通过为一组 Python 语句命名来帮助提高代码的可读性。\n函数是用 def 关键字声明的。函数包含一个可以选择使用 return 关键字的代码块：\nIn [173]: def my_function(x, y):\n   .....:     return x + y\n当到达带有 return 的行时，return 后的值或表达式将被发送到调用该函数的上下文，例如：\nIn [174]: my_function(1, 2)\nOut[174]: 3\n\nIn [175]: result = my_function(1, 2)\n\nIn [176]: result\nOut[176]: 3\n有多个 return 语句没有问题。如果 Python 到达函数末尾而没有遇到 return 语句，则自动返回 None。例如：\nIn [177]: def function_without_return(x):\n   .....:     print(x)\n\nIn [178]: result = function_without_return(\"hello!\")\nhello!\n\nIn [179]: print(result)\nNone\n每个函数都可以有位置参数和关键字参数。关键字参数最常用于指定默认值或可选参数。这里我们将定义一个带有可选 z 参数的函数，默认值为 1.5：\ndef my_function2(x, y, z=1.5):\n    if z &gt; 1:\n        return z * (x + y)\n    else:\n        return z / (x + y)\n虽然关键字参数是可选的，但在调用函数时必须指定所有位置参数。\n您可以将值传递给 z 参数，无论是否提供关键字，但鼓励使用关键字：\nIn [181]: my_function2(5, 6, z=0.7)\nOut[181]: 0.06363636363636363\n\nIn [182]: my_function2(3.14, 7, 3.5)\nOut[182]: 35.49\n\nIn [183]: my_function2(10, 20)\nOut[183]: 45.0\n对函数参数的主要限制是关键字参数必须位于位置参数（如果有）之后。您可以按任意顺序指定关键字参数。这使您不必记住指定函数参数的顺序。您只需记住他们的名字即可。\n\n3.2.1 Namespaces, Scope, and Local Functions\n函数可以访问在函数内部创建的变量以及在更高（甚至全局）范围内的函数外部创建的变量。在 Python 中描述变量作用域的另一个更具描述性的名称是命名空间(namespace)。默认情况下，在函数内分配的任何变量都会分配给本地命名空间。本地命名空间是在调用函数时创建的，并立即由函数的参数填充。函数完成后，本地名称空间将被销毁（有一些例外情况超出了本章的范围）。考虑以下函数：\ndef func():\n    a = []\n    for i in range(5):\n        a.append(i)\n当调用 func() 时，会创建空列表 a，添加五个元素，然后在函数退出时销毁 a。假设我们声明了 a 如下：\nIn [184]: a = []\n\nIn [185]: def func():\n   .....:     for i in range(5):\n   .....:         a.append(i)\n每次调用 func 都会修改列表 a：\nIn [186]: func()\n\nIn [187]: a\nOut[187]: [0, 1, 2, 3, 4]\n\nIn [188]: func()\n\nIn [189]: a\nOut[189]: [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]\n可以在函数范围之外分配变量，但必须使用 global 或 nonlocal 关键字显式声明这些变量：\nIn [190]: a = None\n\nIn [191]: def bind_a_variable():\n   .....:     global a\n   .....:     a = []\n   .....: bind_a_variable()\n   .....:\n\nIn [192]: print(a)\n[]\nnonlocal 允许函数修改在非全局的更高级别范围中定义的变量。由于它的使用有些深奥（我在本书中从未使用过它），因此我建议您参阅 Python 文档以了解更多信息。\n\n\n\n\n\n\nCaution\n\n\n\n我通常不鼓励使用 global 关键字。通常，全局变量用于存储系统中的某种状态。如果您发现自己使用了很多它们，则可能表明需要面向对象编程（使用类）。\n\n\n\n\n3.2.2 Returning Multiple Values\n当我在使用 Java 和 C++ 编程后第一次使用 Python 编程时，我最喜欢的功能之一是能够使用简单的语法从函数返回多个值。这是一个例子：\ndef f():\n    a = 5\n    b = 6\n    c = 7\n    return a, b, c\n\na, b, c = f()\n在数据分析和其他科学应用中，您可能会发现自己经常这样做。这里发生的情况是，该函数实际上只是返回一个对象，一个元组，然后将其解压缩到结果变量中。在前面的示例中，我们可以这样做：\nreturn_value = f()\n在这种情况下，return_value 将是一个包含三个返回变量的三元组。像以前一样返回多个值的一个潜在有吸引力的替代方案可能是返回一个字典：\ndef f():\n    a = 5\n    b = 6\n    c = 7\n    return {\"a\" : a, \"b\" : b, \"c\" : c}\n这种替代技术可能会很有用，具体取决于您想要做什么。\n\n\n3.2.3 Functions Are Objects\n由于 Python 函数是对象，因此可以轻松表达许多在其他语言中难以做到的结构。假设我们正在进行一些数据清理，并且需要对以下字符串列表应用一系列转换：\nIn [193]: states = [\"   Alabama \", \"Georgia!\", \"Georgia\", \"georgia\", \"FlOrIda\",\n   .....:           \"south   carolina##\", \"West virginia?\"]\n任何曾经处理过用户提交的调查数据的人都见过这样混乱的结果。为了使这个字符串列表统一并准备好进行分析，需要做很多事情：去除空格、删除标点符号以及标准化正确的大写。一种方法是使用内置字符串方法以及正则表达式的 re 标准库模块：\nimport re\n\ndef clean_strings(strings):\n    result = []\n    for value in strings:\n        value = value.strip()\n        value = re.sub(\"[!#?]\", \"\", value)\n        value = value.title()\n        result.append(value)\n    return result\n结果如下：\nIn [195]: clean_strings(states)\nOut[195]: \n['Alabama',\n 'Georgia',\n 'Georgia',\n 'Georgia',\n 'Florida',\n 'South   Carolina',\n 'West Virginia']\n您可能会发现有用的另一种方法是列出要应用于特定字符串集的操作：\ndef remove_punctuation(value):\n    return re.sub(\"[!#?]\", \"\", value)\n\nclean_ops = [str.strip, remove_punctuation, str.title]\n\ndef clean_strings(strings, ops):\n    result = []\n    for value in strings:\n        for func in ops:\n            value = func(value)\n        result.append(value)\n    return result\n然后我们有以下内容：\nIn [197]: clean_strings(states, clean_ops)\nOut[197]: \n['Alabama',\n 'Georgia',\n 'Georgia',\n 'Georgia',\n 'Florida',\n 'South   Carolina',\n 'West Virginia']\n像这样的更实用的模式使您能够轻松地在非常高的级别上修改字符串的转换方式。 clean_strings 函数现在也更加可重用和通用。\n您可以使用函数作为其他函数的参数，例如内置的映射函数，它将函数应用于某种序列：\nIn [198]: for x in map(remove_punctuation, states):\n   .....:     print(x)\nAlabama \nGeorgia\nGeorgia\ngeorgia\nFlOrIda\nsouth   carolina\nWest virginia\nmap 可以用作列表推导式的替代方案，无需任何过滤器。\n\n\n3.2.4 Anonymous (Lambda) Functions\nPython 支持所谓的匿名函数(anonymous)或 lambda 函数，它们是一种编写由单个语句组成的函数的方法，其结果是返回值。它们是用 lambda 关键字定义的，除了“我们正在声明一个匿名函数”之外没有任何意义：\nIn [199]: def short_function(x):\n   .....:     return x * 2\n\nIn [200]: equiv_anon = lambda x: x * 2\n在本书的其余部分中，我通常将这些称为 lambda 函数。它们在数据分析中特别方便，因为正如您将看到的，在很多情况下数据转换函数将函数作为参数。与编写完整的函数声明甚至将 lambda 函数分配给局部变量相比，传递 lambda 函数通常需要更少的输入（并且更清晰）。考虑这个例子：\nIn [201]: def apply_to_list(some_list, f):\n   .....:     return [f(x) for x in some_list]\n\nIn [202]: ints = [4, 0, 1, 5, 6]\n\nIn [203]: apply_to_list(ints, lambda x: x * 2)\nOut[203]: [8, 0, 2, 10, 12]\n您也可以编写 [x * 2 for x in ints]，但在这里我们能够简洁地将自定义运算符传递给 apply_to_list 函数。\n再举一个例子，假设您想按每个字符串中不同字母的数量对字符串集合进行排序：\nIn [204]: strings = [\"foo\", \"card\", \"bar\", \"aaaa\", \"abab\"]\n这里我们可以将 lambda 函数传递给列表的 sort 方法：\nIn [205]: strings.sort(key=lambda x: len(set(x)))\n\nIn [206]: strings\nOut[206]: ['aaaa', 'foo', 'abab', 'bar', 'card']\n\n\n3.2.5 Generators\nPython 中的许多对象都支持迭代，例如列表中的对象或文件中的行。这是通过迭代器协议来完成的，迭代器协议是使对象可迭代的通用方法。例如，迭代字典会产生字典键：\nIn [207]: some_dict = {\"a\": 1, \"b\": 2, \"c\": 3}\n\nIn [208]: for key in some_dict:\n   .....:     print(key)\na\nb\nc\n当您写入 for key in some_dict 时，Python 解释器首先尝试从 some_dict 创建一个迭代器：\nIn [209]: dict_iterator = iter(some_dict)\n\nIn [210]: dict_iterator\nOut[210]: &lt;dict_keyiterator at 0x17d60e020&gt;\n迭代器是在 for 循环等上下文中使用时将向 Python 解释器生成对象的任何对象。大多数需要列表或类列表对象的方法也将接受任何可迭代对象。这包括内置方法（例如 min、max 和 sum）以及类型构造函数（例如 list 和 tuple）：\nIn [211]: list(dict_iterator)\nOut[211]: ['a', 'b', 'c']\n生成器(generator)是一种构造新的可迭代对象的便捷方法，类似于编写普通函数。普通函数一次执行并返回一个结果，而生成器可以通过每次使用生成器时暂停和恢复执行来返回多个值的序列。要创建生成器，请在函数中使用 yield 关键字而不是 return：\ndef squares(n=10):\n    print(f\"Generating squares from 1 to {n ** 2}\")\n    for i in range(1, n + 1):\n        yield i ** 2\n当您实际调用生成器时，不会立即执行任何代码：\nIn [213]: gen = squares()\n\nIn [214]: gen\nOut[214]: &lt;generator object squares at 0x17d5fea40&gt;\n直到您从生成器请求元素后，它才开始执行其代码：\nIn [215]: for x in gen:\n   .....:     print(x, end=\" \")\nGenerating squares from 1 to 100\n1 4 9 16 25 36 49 64 81 100\n\n\n\n\n\n\nNote\n\n\n\n由于生成器一次生成一个元素而不是一次生成整个列表，因此它可以帮助您的程序使用更少的内存。\n\n\nGenerator expressions\n制作生成器的另一种方法是使用生成器表达式。这是一个类似于列表、字典和集合推导式的生成器。要创建一个，请将本来是列表理解的内容括在括号而不是方括号内：\nIn [216]: gen = (x ** 2 for x in range(100))\n\nIn [217]: gen\nOut[217]: &lt;generator object &lt;genexpr&gt; at 0x17d5feff0&gt;\n这相当于以下更详细的生成器：\ndef _make_gen():\n    for x in range(100):\n        yield x ** 2\ngen = _make_gen()\n在某些情况下，可以使用生成器表达式代替列表推导式作为函数参数：\nIn [218]: sum(x ** 2 for x in range(100))\nOut[218]: 328350\n\nIn [219]: dict((i, i ** 2) for i in range(5))\nOut[219]: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}\n根据理解表达式生成的元素数量，生成器版本有时可能会更快。\nitertools module\n标准库 itertools 模块包含许多常见数据算法的生成器集合。例如，groupby 接受任何序列和一个函数，根据函数的返回值对序列中的连续元素进行分组。这是一个例子：\nIn [220]: import itertools\n\nIn [221]: def first_letter(x):\n   .....:     return x[0]\n\nIn [222]: names = [\"Alan\", \"Adam\", \"Wes\", \"Will\", \"Albert\", \"Steven\"]\n\nIn [223]: for letter, names in itertools.groupby(names, first_letter):\n   .....:     print(letter, list(names)) # names is a generator\nA ['Alan', 'Adam']\nW ['Wes', 'Will']\nA ['Albert']\nS ['Steven']\n请参阅 Table 3.2，了解我经常发现有用的其他一些 itertools 函数的列表。您可能想查看 the official Python documentation，了解有关这个有用的内置实用程序模块的更多信息。\n\nTable 3.2: Some useful itertools functions\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nchain(*iterables)\n通过将迭代器链接在一起生成序列。一旦第一个迭代器中的元素耗尽，就会返回下一个迭代器中的元素，依此类推。\n\n\ncombinations(iterable, k)\n以可迭代的方式生成所有可能的 k 元组元素的序列，忽略顺序且不进行替换（另请参阅配套函数 Combinations_with_replacement）。\n\n\npermutations(iterable, k)\n以可迭代、尊重的顺序生成所有可能的 k 元组元素的序列。\n\n\ngroupby(iterable[, keyfunc])\n为每个唯一键生成（键，子迭代器）。\n\n\nproduct(*iterables, repeat=1)\n将输入可迭代对象的笛卡尔积生成为元组，类似于嵌套的 for 循环。\n\n\n\n\n\n3.2.6 Errors and Exception Handling\n优雅地处理 Python 错误或异常是构建健壮程序的重要组成部分。在数据分析应用程序中，许多函数仅适用于某些类型的输入。例如，Python 的 float 函数能够将字符串转换为浮点数，但在输入不正确时会失败并出现 ValueError：\nIn [224]: float(\"1.2345\")\nOut[224]: 1.2345\n\nIn [225]: float(\"something\")\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-225-5ccfe07933f4&gt; in &lt;module&gt;\n----&gt; 1 float(\"something\")\nValueError: could not convert string to float: 'something'\n假设我们想要一个能够正常失败并返回输入参数的 float 版本。我们可以通过编写一个函数来实现这一点，该函数将对 float 的调用封装在 try/except 块中（在 IPython 中执行此代码）：\ndef attempt_float(x):\n    try:\n        return float(x)\n    except:\n        return x\n仅当 float(x) 引发异常时才会执行该块的 except 部分中的代码：\nIn [227]: attempt_float(\"1.2345\")\nOut[227]: 1.2345\n\nIn [228]: attempt_float(\"something\")\nOut[228]: 'something'\n您可能会注意到 float 可以引发 ValueError 以外的异常：\nIn [229]: float((1, 2))\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-229-82f777b0e564&gt; in &lt;module&gt;\n----&gt; 1 float((1, 2))\nTypeError: float() argument must be a string or a real number, not 'tuple'\n您可能只想抑制 ValueError，因为 TypeError（输入不是字符串或数值）可能表明程序中存在合法错误。为此，请在 except 后面写入异常类型：\ndef attempt_float(x):\n    try:\n        return float(x)\n    except ValueError:\n        return x\n那么我们有：\nIn [231]: attempt_float((1, 2))\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-231-8b0026e9e6b7&gt; in &lt;module&gt;\n----&gt; 1 attempt_float((1, 2))\n&lt;ipython-input-230-6209ddecd2b5&gt; in attempt_float(x)\n      1 def attempt_float(x):\n      2     try:\n----&gt; 3         return float(x)\n      4     except ValueError:\n      5         return x\nTypeError: float() argument must be a string or a real number, not 'tuple'\n您可以通过编写异常类型的元组来捕获多个异常类型（括号是必需的）：\ndef attempt_float(x):\n    try:\n        return float(x)\n    except (TypeError, ValueError):\n        return x\n在某些情况下，您可能不想抑制异常，但希望无论 try 块中的代码是否成功都执行某些代码。为此，请使用 finally：\nf = open(path, mode=\"w\")\n\ntry:\n    write_to_file(f)\nfinally:\n    f.close()\n在这里，文件对象 f 将始终被关闭。类似地，您可以使用 else 使代码仅在 try: 块成功时才执行：\nf = open(path, mode=\"w\")\n\ntry:\n    write_to_file(f)\nexcept:\n    print(\"Failed\")\nelse:\n    print(\"Succeeded\")\nfinally:\n    f.close()\nExceptions in IPython\n如果在运行脚本或执行任何语句时引发异常，IPython 默认情况下将打印完整的调用堆栈跟踪（traceback），其中包含堆栈中每个点位置周围的几行上下文：\nIn [10]: %run examples/ipython_bug.py\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\n/home/wesm/code/pydata-book/examples/ipython_bug.py in &lt;module&gt;()\n     13     throws_an_exception()\n     14\n---&gt; 15 calling_things()\n\n/home/wesm/code/pydata-book/examples/ipython_bug.py in calling_things()\n     11 def calling_things():\n     12     works_fine()\n---&gt; 13     throws_an_exception()\n     14\n     15 calling_things()\n\n/home/wesm/code/pydata-book/examples/ipython_bug.py in throws_an_exception()\n      7     a = 5\n      8     b = 6\n----&gt; 9     assert(a + b == 10)\n     10\n     11 def calling_things():\n\nAssertionError:\n与标准 Python 解释器（不提供任何附加上下文）相比，拥有附加上下文本身是一个很大的优势。您可以使用 %xmode 魔术命令控制显示的上下文量，从 Plain（与标准 Python 解释器相同）到 Verbose（内联函数参数值等）。正如您稍后将在 Appendix B: More on the IPython System 中看到的那样，您可以在发生错误后进入堆栈（使用 %debug 或 %pdb 魔法）进行交互式事后调试。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Built-In Data Structures, Functions, and Files</span>"
    ]
  },
  {
    "objectID": "03.python-builtin.html#files-and-the-operating-system",
    "href": "03.python-builtin.html#files-and-the-operating-system",
    "title": "3  Built-In Data Structures, Functions, and Files",
    "section": "3.3 Files and the Operating System",
    "text": "3.3 Files and the Operating System\n本书的大部分内容都使用 pandas.read_csv 等高级工具将数据文件从磁盘读取到 Python 数据结构中。然而，了解如何在 Python 中使用文件的基础知识非常重要。幸运的是，它相对简单，这也是 Python 在文本和文件修改方面如此流行的原因之一。\n要打开文件进行读取或写入，请使用带有相对或绝对文件路径和可选文件编码的内置 open 函数：\nIn [233]: path = \"examples/segismundo.txt\"\n\nIn [234]: f = open(path, encoding=\"utf-8\")\n在这里，我将encoding=\"utf-8\"作为最佳实践，因为读取文件的默认 Unicode 编码因平台而异。\n默认情况下，文件以只读模式\"r\"打开。然后我们可以将文件对象 f 视为列表并迭代各行，如下所示：\nfor line in f:\n    print(line)\n这些行从文件中出来时，行尾 (EOL) 标记完好无损，因此您经常会看到在文件中获取无 EOL 行列表的代码，例如：\nIn [235]: lines = [x.rstrip() for x in open(path, encoding=\"utf-8\")]\n\nIn [236]: lines\nOut[236]: \n['Sueña el rico en su riqueza,',\n 'que más cuidados le ofrece;',\n '',\n 'sueña el pobre que padece',\n 'su miseria y su pobreza;',\n '',\n 'sueña el que a medrar empieza,',\n 'sueña el que afana y pretende,',\n 'sueña el que agravia y ofende,',\n '',\n 'y en el mundo, en conclusión,',\n 'todos sueñan lo que son,',\n 'aunque ninguno lo entiende.',\n '']\n当您使用 open 创建文件对象时，建议在使用完毕后关闭该文件。关闭文件会将其资源释放回操作系统：\nIn [237]: f.close()\n更轻松地清理打开的文件的方法之一是使用 with 语句：\nIn [238]: with open(path, encoding=\"utf-8\") as f:\n   .....:     lines = [x.rstrip() for x in f]\n这将在退出 with 块时自动关闭文件 f。无法确保文件关闭不会在许多小程序或脚本中导致问题，但在需要与大量文件交互的程序中可能会出现问题。\n如果我们输入 f = open(path, \"w\")，则会在 Examples/segismundo.txt 中创建一个新文件（小心！），覆盖其位置上的任何文件。还有\"x\"文件模式，它创建一个可写文件，但如果文件路径已经存在则失败。有关所有有效文件读/写模式的列表，请参阅 Table 3.3。\n\nTable 3.3: Python file modes\n\n\n\n\n\n\nMode\nDescription\n\n\n\n\nr\n只读模式\n\n\nw\n只写模式；创建一个新文件（删除任何同名文件的数据）\n\n\nx\n只写模式；创建新文件，但如果文件路径已存在则失败\n\n\na\n追加到现有文件（如果文件尚不存在则创建该文件）\n\n\nr+\n读和写\n\n\nb\n添加到二进制文件的模式（即\"rb\"或\"wb\"）\n\n\nt\n文件的文本模式（自动将字节解码为 Unicode）；如果未指定，则这是默认值\n\n\n\n对于可读文件，最常用的一些方法是 read、seek 和 tell。read 从文件中返回一定数量的字符。“字符”的构成由文件编码决定，如果文件以二进制模式打开，则由原始字节决定：\nIn [239]: f1 = open(path)\n\nIn [240]: f1.read(10)\nOut[240]: 'Sueña el r'\n\nIn [241]: f2 = open(path, mode=\"rb\")  # Binary mode\n\nIn [242]: f2.read(10)\nOut[242]: b'Sue\\xc3\\xb1a el '\nread 方法将文件对象位置前进所读取的字节数。告诉你当前的位置：\nIn [243]: f1.tell()\nOut[243]: 11\n\nIn [244]: f2.tell()\nOut[244]: 10\n即使我们从以文本模式打开的文件 f1 中读取了 10 个字符，位置也是 11，因为使用默认编码解码 10 个字符需要那么多字节。您可以检查 sys 模块中的默认编码：\nIn [245]: import sys\n\nIn [246]: sys.getdefaultencoding()\nOut[246]: 'utf-8'\n为了获得跨平台的一致行为，最好在打开文件时传递编码（例如广泛使用的encoding =\"utf-8\"）。\nseek 将文件位置更改为文件中指定的字节：\nIn [247]: f1.seek(3)\nOut[247]: 3\n\nIn [248]: f1.read(1)\nOut[248]: 'ñ'\n\nIn [249]: f1.tell()\nOut[249]: 5\n最后，我们记得关闭文件：\nIn [250]: f1.close()\n\nIn [251]: f2.close()\n要将文本写入文件，可以使用文件的 write 或 writelines 方法。例如，我们可以创建一个没有空行的 example/segismundo.txt 版本，如下所示：\nIn [252]: path\nOut[252]: 'examples/segismundo.txt'\n\nIn [253]: with open(\"tmp.txt\", mode=\"w\") as handle:\n   .....:     handle.writelines(x for x in open(path) if len(x) &gt; 1)\n\nIn [254]: with open(\"tmp.txt\") as f:\n   .....:     lines = f.readlines()\n\nIn [255]: lines\nOut[255]: \n['Sueña el rico en su riqueza,\\n',\n 'que más cuidados le ofrece;\\n',\n 'sueña el pobre que padece\\n',\n 'su miseria y su pobreza;\\n',\n 'sueña el que a medrar empieza,\\n',\n 'sueña el que afana y pretende,\\n',\n 'sueña el que agravia y ofende,\\n',\n 'y en el mundo, en conclusión,\\n',\n 'todos sueñan lo que son,\\n',\n 'aunque ninguno lo entiende.\\n']\n有关许多最常用的文件方法，请参阅 Table 3.4。\n\nTable 3.4: Important Python file methods or attributes\n\n\n\n\n\n\nMethod/attribute\nDescription\n\n\n\n\nread([size])\n根据文件模式以字节或字符串形式从文件返回数据，可选 size 参数指示要读取的字节数或字符串字符数\n\n\nreadable()\n如果文件支持 read 操作则返回 True\n\n\nreadlines([size])\n返回文件中的行列表，带有可选的 size 参数\n\n\nwrite(string)\n将传递的字符串写入文件\n\n\nwritable()\n如果文件支持 write 操作则返回 True\n\n\nwritelines(strings)\n将传递的字符串序列写入文件\n\n\nclose()\n关闭文件对象\n\n\nflush()\n将内部 I/O 缓冲区刷新到磁盘\n\n\nseek(pos)\n移动到指定的文件位置（整数）\n\n\nseekable()\n如果文件对象支持查找并因此支持随机访问（某些类似文件的对象不支持），则返回 True\n\n\ntell()\n以整数形式返回当前文件位置\n\n\nclosed\n如果文件已关闭则为 True\n\n\nencoding\n用于将文件中的字节解释为 Unicode（通常为 UTF-8）的编码\n\n\n\n\n3.3.1 Bytes and Unicode with Files\nPython 文件的默认行为（无论是可读还是可写）是文本模式，这意味着您打算使用 Python 字符串（即 Unicode）。这与二进制模式形成对比，您可以通过将 b 附加到文件模式来获得二进制模式。重新访问上一节中的文件（其中包含采用 UTF-8 编码的非 ASCII 字符），我们有：\nIn [258]: with open(path) as f:\n   .....:     chars = f.read(10)\n\nIn [259]: chars\nOut[259]: 'Sueña el r'\n\nIn [260]: len(chars)\nOut[260]: 10\nUTF-8 是一种可变长度的 Unicode 编码，因此当我从文件中请求一定数量的字符时，Python 会从文件中读取足够的字节（可能少至 10 个字节，也可能多至 40 个字节）来解码那么多字符。如果我以\"rb\"模式打开文件，则读取请求的确切字节数：\nIn [261]: with open(path, mode=\"rb\") as f:\n   .....:     data = f.read(10)\n\nIn [262]: data\nOut[262]: b'Sue\\xc3\\xb1a el '\n根据文本编码，您可以自己将字节解码为 str 对象，但前提是每个编码的 Unicode 字符都完全形成：\nIn [263]: data.decode(\"utf-8\")\nOut[263]: 'Sueña el '\n\nIn [264]: data[:4].decode(\"utf-8\")\n---------------------------------------------------------------------------\nUnicodeDecodeError                        Traceback (most recent call last)\n&lt;ipython-input-264-846a5c2fed34&gt; in &lt;module&gt;\n----&gt; 1 data[:4].decode(\"utf-8\")\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 3: unexpecte\nd end of data\n文本模式与 open 的 encoding 选项相结合，提供了一种从一种 Unicode 编码转换为另一种编码的便捷方法：\nIn [265]: sink_path = \"sink.txt\"\n\nIn [266]: with open(path) as source:\n   .....:     with open(sink_path, \"x\", encoding=\"iso-8859-1\") as sink:\n   .....:         sink.write(source.read())\n\nIn [267]: with open(sink_path, encoding=\"iso-8859-1\") as f:\n   .....:     print(f.read(10))\nSueña el r\n以二进制以外的任何模式打开文件时请注意使用 seek。如果文件位置位于定义 Unicode 字符的字节中间，则后续读取将导致错误：\nIn [269]: f = open(path, encoding='utf-8')\n\nIn [270]: f.read(5)\nOut[270]: 'Sueña'\n\nIn [271]: f.seek(4)\nOut[271]: 4\n\nIn [272]: f.read(1)\n---------------------------------------------------------------------------\nUnicodeDecodeError                        Traceback (most recent call last)\n&lt;ipython-input-272-5a354f952aa4&gt; in &lt;module&gt;\n----&gt; 1 f.read(1)\n~/miniforge-x86/envs/book-env/lib/python3.10/codecs.py in decode(self, input, fin\nal)\n    320         # decode input (taking the buffer into account)\n    321         data = self.buffer + input\n--&gt; 322         (result, consumed) = self._buffer_decode(data, self.errors, final\n)\n    323         # keep undecoded input until the next call\n    324         self.buffer = data[consumed:]\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xb1 in position 0: invalid s\ntart byte\n\nIn [273]: f.close()\n如果您发现自己经常对 non-ASCII 文本数据进行数据分析，那么掌握 Python 的 Unicode 功能将非常有价值。有关更多信息，请参阅 Python’s online documentation。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Built-In Data Structures, Functions, and Files</span>"
    ]
  },
  {
    "objectID": "03.python-builtin.html#conclusion",
    "href": "03.python-builtin.html#conclusion",
    "title": "3  Built-In Data Structures, Functions, and Files",
    "section": "3.4 Conclusion",
    "text": "3.4 Conclusion\n现在您已经掌握了 Python 环境和语言的一些基础知识，是时候继续学习 NumPy 和 Python 中面向数组的计算了。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Built-In Data Structures, Functions, and Files</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html",
    "href": "04.numpy-basics.html",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "",
    "text": "4.1 The NumPy ndarray: A Multidimensional Array Object\nNumPy 的主要功能之一是它的 N 维数组对象（或 ndarray），它是 Python 中大型数据集的快速、灵活的容器。数组使您能够使用与标量元素之间的等效运算类似的语法对整个数据块执行数学运算。\n为了让您了解 NumPy 如何使用与内置 Python 对象上的标量值类似的语法启用批量计算，我首先导入 NumPy 并创建一个小数组：\n然后我用 data 编写数学运算：\n在第一个示例中，所有元素都已乘以 10。在第二个示例中，数组中每个“单元格”中的对应值已相互相加。\nndarray 是同质数据的通用多维容器；也就是说，所有元素必须是同一类型。每个数组都有一个 shape（表示每个维度大小的元组）和一个 dtype（描述数组数据类型的对象）：\n本章将向您介绍使用 NumPy 数组的基础知识，这对于阅读本书的其余部分应该足够了。虽然对于许多数据分析应用程序来说，不需要深入了解 NumPy，但精通面向数组的编程和思维是成为科学 Python 大师的关键一步。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html#the-numpy-ndarray-a-multidimensional-array-object",
    "href": "04.numpy-basics.html#the-numpy-ndarray-a-multidimensional-array-object",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "",
    "text": "In [12]: import numpy as np\n\nIn [13]: data = np.array([[1.5, -0.1, 3], [0, -3, 6.5]])\n\nIn [14]: data\nOut[14]: \narray([[ 1.5, -0.1,  3. ],\n       [ 0. , -3. ,  6.5]])\n\nIn [15]: data * 10\nOut[15]: \narray([[ 15.,  -1.,  30.],\n       [  0., -30.,  65.]])\n\nIn [16]: data + data\nOut[16]: \narray([[ 3. , -0.2,  6. ],\n       [ 0. , -6. , 13. ]])\n\n\n\n\n\n\n\nNote\n\n\n\n在本章和整本书中，我使用标准 NumPy 约定，即始终使用 import numpy as np。可以在代码中放入 from numpy import * 以避免编写 np.，但我建议不要养成这种习惯。numpy 命名空间很大，包含许多名称与内置 Python 函数（例如 min 和 max）冲突的函数。遵循这些标准约定几乎总是一个好主意。\n\n\n\nIn [17]: data.shape\nOut[17]: (2, 3)\n\nIn [18]: data.dtype\nOut[18]: dtype('float64')\n\n\n\n\n\n\n\nNote\n\n\n\n每当您在书中看到 “array”、“NumPy array” 或 “ndarray” 时，大多数情况下它们都指的是 ndarray 对象。\n\n\n\n4.1.1 Creating ndarrays\n创建数组最简单的方法是使用 array 函数。这接受任何类似序列的对象（包括其他数组）并生成一个包含传递数据的新 NumPy 数组。例如，列表是一个很好的转换候选：\nIn [19]: data1 = [6, 7.5, 8, 0, 1]\n\nIn [20]: arr1 = np.array(data1)\n\nIn [21]: arr1\nOut[21]: array([6. , 7.5, 8. , 0. , 1. ])\n嵌套序列，就像等长列表的列表一样，将被转换为多维数组：\nIn [22]: data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]\n\nIn [23]: arr2 = np.array(data2)\n\nIn [24]: arr2\nOut[24]: \narray([[1, 2, 3, 4],\n       [5, 6, 7, 8]])\n由于 data2 是列表的列表，因此 NumPy 数组 arr2 具有两个维度，其形状从数据推断。我们可以通过检查 ndim 和 shape 属性来确认这一点：\nIn [25]: arr2.ndim\nOut[25]: 2\n\nIn [26]: arr2.shape\nOut[26]: (2, 4)\n除非明确指定（在 Data Types for ndarrays 中讨论），否则 numpy.array 会尝试为其创建的数组推断良好的数据类型。数据类型存储在特殊的 dtype metadata 对象中；例如，在前面的两个例子中，我们有：\nIn [27]: arr1.dtype\nOut[27]: dtype('float64')\n\nIn [28]: arr2.dtype\nOut[28]: dtype('int64')\n除了 numpy.array 之外，还有许多其他函数用于创建新数组。例如，numpy.zeros 和 numpy.ones 分别创建具有给定长度或形状的 0 或 1 数组。numpy.empty 创建一个数组，而不将其值初始化为任何特定值。要使用这些方法创建高维数组，请传递形状的元组：\nIn [29]: np.zeros(10)\nOut[29]: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n\nIn [30]: np.zeros((3, 6))\nOut[30]: \narray([[0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0.]])\n\nIn [31]: np.empty((2, 3, 2))\nOut[31]: \narray([[[0., 0.],\n        [0., 0.],\n        [0., 0.]],\n       [[0., 0.],\n        [0., 0.],\n        [0., 0.]]])\n\n\n\n\n\n\nCaution\n\n\n\n假设 numpy.empty 将返回全零的数组是不安全的。该函数返回未初始化的内存，因此可能包含非零“垃圾”值。仅当您打算用数据填充新数组时才应使用此函数。\n\n\nnumpy.arange 是内置 Python range 函数的数组值版本：\nIn [32]: np.arange(15)\nOut[32]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\n有关标准数组创建函数的简短列表，请参阅 Table 4.1。由于 NumPy 专注于数值计算，因此如果未指定数据类型，在许多情况下将是 float64（浮点）。\n\nTable 4.1: Some important NumPy array creation functions\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\narray\n通过推断数据类型或显式指定数据类型，将输入数据（列表、元组、数组或其他序列类型）转换为 ndarray；默认复制输入数据\n\n\nasarray\n将输入转换为 ndarray，但如果输入已经是 ndarray，则不复制\n\n\narange\n与内置 range 类似，但返回 ndarray 而不是列表\n\n\nones, ones_like\n生成具有给定形状和数据类型的全 1 数组；ones_Like 采用另一个数组并生成具有相同形状和数据类型的 ones 数组\n\n\nzeros, zeros_like\n与 ones 和 ones_like 类似，但生成 0 数组\n\n\nempty, empty_like\n通过分配新内存来创建新数组，但不填充任何值\n\n\nfull, full_like\n生成给定形状和数据类型的数组，并将所有值设置为指示的“填充值”；full_like 接受另一个数组并生成具有相同形状和数据类型的填充数组\n\n\neye, identity\n创建一个 N × N 方阵单位矩阵（对角线上为 1，其他位置为 0）\n\n\n\n\n\n4.1.2 Data Types for ndarrays\n数据类型或 dtype 是一个特殊对象，包含 ndarray 将一块内存解释为特定类型数据所需的信息（或元数据、有关数据的数据）：\nIn [33]: arr1 = np.array([1, 2, 3], dtype=np.float64)\n\nIn [34]: arr2 = np.array([1, 2, 3], dtype=np.int32)\n\nIn [35]: arr1.dtype\nOut[35]: dtype('float64')\n\nIn [36]: arr2.dtype\nOut[36]: dtype('int32')\n数据类型是 NumPy 与来自其他系统的数据交互的灵活性的来源。在大多数情况下，它们直接提供到底层磁盘或内存表示的映射，这使得可以在磁盘上读取和写入二进制数据流，并连接到用 C 或 FORTRAN 等低级语言编写的代码。数字数据类型的命名方式相同：类型名称，如 float 或 int，后跟一个数字，表示每个元素的位数。标准双精度浮点值（Python 的 float 对象中使用的值）占用 8 个字节或 64 位。因此，这种类型在 NumPy 中称为 float64。有关 NumPy 支持的数据类型的完整列表，请参阅 Table 4.2。\n\n\n\n\n\n\nNote\n\n\n\n不用担心记住 NumPy 数据类型，特别是如果您是新用户。通常只需要关心正在处理的一般数据类型，无论是浮点、复数、整数、布尔值、字符串还是一般的 Python 对象。当您需要更多地控制数据在内存和磁盘上的存储方式（尤其是大型数据集）时，最好知道您可以控制存储类型。\n\n\n\nTable 4.2: NumPy data types\n\n\n\n\n\n\n\nType\nType code\nDescription\n\n\n\n\nint8, uint8\ni1, u1\nSigned and unsigned 8-bit (1 byte) integer types\n\n\nint16, uint16\ni2, u2\nSigned and unsigned 16-bit integer types\n\n\nint32, uint32\ni4, u4\nSigned and unsigned 32-bit integer types\n\n\nint64, uint64\ni8, u8\nSigned and unsigned 64-bit integer types\n\n\nfloat16\nf2\nHalf-precision floating point\n\n\nfloat32\nf4 or f\nStandard single-precision floating point; compatible with C float\n\n\nfloat64\nf8 or d\nStandard double-precision floating point; compatible with C double and Python float object\n\n\nfloat128\nf16 or g\nExtended-precision floating point\n\n\ncomplex64, complex128, complex256\nc8, c16, c32\nComplex numbers represented by two 32, 64, or 128 floats, respectively\n\n\nbool\n?\nBoolean type storing True and False values\n\n\nobject\nO\nPython object type; a value can be any Python object\n\n\nstring_\nS\nFixed-length ASCII string type (1 byte per character); for example, to create a string data type with length 10, use 'S10'\n\n\nunicode_\nU\nFixed-length Unicode type (number of bytes platform specific); same specification semantics as string_ (e.g., 'U10')\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n整数类型有有符号和无符号之分，许多读者对这个术语并不熟悉。有符号整数可以表示正整数和负整数，而无符号整数只能表示非零整数。例如，int8（有符号 8-bit 整数）可以表示从 -128 到 127（含）的整数，而 uint8（无符号 8-bit 整数）可以表示 0 到 255。\n\n\n您可以使用 ndarray 的 astype 方法将数组从一种数据类型显式转换或转换为另一种数据类型：\nIn [37]: arr = np.array([1, 2, 3, 4, 5])\n\nIn [38]: arr.dtype\nOut[38]: dtype('int64')\n\nIn [39]: float_arr = arr.astype(np.float64)\n\nIn [40]: float_arr\nOut[40]: array([1., 2., 3., 4., 5.])\n\nIn [41]: float_arr.dtype\nOut[41]: dtype('float64')\n在此示例中，整数被转换为浮点数。如果我将一些浮点数转换为整数数据类型，小数部分将被截断：\nIn [42]: arr = np.array([3.7, -1.2, -2.6, 0.5, 12.9, 10.1])\n\nIn [43]: arr\nOut[43]: array([ 3.7, -1.2, -2.6,  0.5, 12.9, 10.1])\n\nIn [44]: arr.astype(np.int32)\nOut[44]: array([ 3, -1, -2,  0, 12, 10], dtype=int32)\n如果您有一个表示数字的字符串数组，则可以使用 astype 将它们转换为数字形式：\nIn [45]: numeric_strings = np.array([\"1.25\", \"-9.6\", \"42\"], dtype=np.string_)\n\nIn [46]: numeric_strings.astype(float)\nOut[46]: array([ 1.25, -9.6 , 42.  ])\n\n\n\n\n\n\nCaution\n\n\n\n使用 numpy.string_ 类型时要小心，因为 NumPy 中的字符串数据是固定大小的，可能会在没有警告的情况下截断输入。pandas 对非数字数据有更直观的开箱即用行为。\n\n\n如果由于某种原因转换失败（例如无法转换为 float64 的字符串），则会引发 ValueError。之前我有点懒，写了 float 而不是 np.float64；NumPy 将 Python 类型别名为其自己的等效数据类型。\n您还可以使用另一个数组的 dtype 属性：\nIn [47]: int_array = np.arange(10)\n\nIn [48]: calibers = np.array([.22, .270, .357, .380, .44, .50], dtype=np.float64)\n\nIn [49]: int_array.astype(calibers.dtype)\nOut[49]: array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n您还可以使用速记类型代码字符串来引用 dtype：\nIn [50]: zeros_uint32 = np.zeros(8, dtype=\"u4\")\n\nIn [51]: zeros_uint32\nOut[51]: array([0, 0, 0, 0, 0, 0, 0, 0], dtype=uint32)\n\n\n\n\n\n\nNote\n\n\n\n调用 astype 始终会创建一个新数组（数据的副本），即使新数据类型与旧数据类型相同。\n\n\n\n\n4.1.3 Arithmetic with NumPy Arrays\n数组很重要，因为它们使您能够表达对数据的批量操作，而无需编写任何 for 循环。NumPy 用户将此称为矢量化(vectorization)。大小相等的数组之间的任何算术运算都按元素应用运算：\nIn [52]: arr = np.array([[1., 2., 3.], [4., 5., 6.]])\n\nIn [53]: arr\nOut[53]: \narray([[1., 2., 3.],\n       [4., 5., 6.]])\n\nIn [54]: arr * arr\nOut[54]: \narray([[ 1.,  4.,  9.],\n       [16., 25., 36.]])\n\nIn [55]: arr - arr\nOut[55]: \narray([[0., 0., 0.],\n       [0., 0., 0.]])\n标量算术运算将标量参数传播到数组中的每个元素：\nIn [56]: 1 / arr\nOut[56]: \narray([[1.    , 0.5   , 0.3333],\n       [0.25  , 0.2   , 0.1667]])\n\nIn [57]: arr ** 2\nOut[57]: \narray([[ 1.,  4.,  9.],\n       [16., 25., 36.]])\n相同大小的数组之间的比较会产生布尔数组：\nIn [58]: arr2 = np.array([[0., 4., 1.], [7., 2., 12.]])\n\nIn [59]: arr2\nOut[59]: \narray([[ 0.,  4.,  1.],\n       [ 7.,  2., 12.]])\n\nIn [60]: arr2 &gt; arr\nOut[60]: \narray([[False,  True, False],\n       [ True, False,  True]])\n评估不同大小的数组之间的操作称为广播(broadcasting)，将在 Appendix A: Advanced NumPy 中更详细地讨论。对于本书的大部分内容来说，并不需要对广播有深入的了解。\n\n\n4.1.4 Basic Indexing and Slicing\nNumPy 数组索引是一个深入的主题，因为您可能希望通过多种方式选择数据子集或单个元素。一维数组很简单；从表面上看，它们的行为与 Python 列表类似：\nIn [61]: arr = np.arange(10)\n\nIn [62]: arr\nOut[62]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nIn [63]: arr[5]\nOut[63]: 5\n\nIn [64]: arr[5:8]\nOut[64]: array([5, 6, 7])\n\nIn [65]: arr[5:8] = 12\n\nIn [66]: arr\nOut[66]: array([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9])\n正如您所看到的，如果您将标量值分配给切片，如 arr[5:8] = 12 所示，该值将传播（或广播）到整个选择。\n\n\n\n\n\n\nNote\n\n\n\n与 Python 内置列表的第一个重要区别是数组切片是原始数组的视图。这意味着数据不会被复制，对视图的任何修改都将反映在源数组中。\n\n\n举个例子，我首先创建 arr 的切片：\nIn [67]: arr_slice = arr[5:8]\n\nIn [68]: arr_slice\nOut[68]: array([12, 12, 12])\n现在，当我更改 arr_slice 中的值时，突变会反映在原始数组 arr 中：\nIn [69]: arr_slice[1] = 12345\n\nIn [70]: arr\nOut[70]: \narray([    0,     1,     2,     3,     4,    12, 12345,    12,     8,\n           9])\n“裸”切片 [:] 将分配给数组中的所有值：\nIn [71]: arr_slice[:] = 64\n\nIn [72]: arr\nOut[72]: array([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])\n如果您是 NumPy 的新手，您可能会对此感到惊讶，特别是如果您使用过其他更热衷于复制数据的数组编程语言。由于 NumPy 被设计为能够处理非常大的数组，因此如果 NumPy 坚持始终复制数据，您可以想象性能和内存问题。\n\n\n\n\n\n\nCaution\n\n\n\n如果您想要 ndarray 切片的副本而不是视图，则需要显式复制该数组，例如 arr[5:8].copy()。正如您将看到的，pandas 也是这样工作的。\n\n\n对于更高维的数组，您有更多的选择。在二维数组中，每个索引处的元素不再是标量，而是一维数组：\nIn [73]: arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nIn [74]: arr2d[2]\nOut[74]: array([7, 8, 9])\n因此，可以递归地访问各个元素。但这有点太多的工作，因此您可以传递一个以逗号分隔的索引列表来选择单个元素。所以这些是等价的：\nIn [75]: arr2d[0][2]\nOut[75]: 3\n\nIn [76]: arr2d[0, 2]\nOut[76]: 3\n有关二维数组索引的说明，请参见 Figure 4.1。我发现将 axis 0 视为数组的 “rows”，将 axis 1 视为 “columns” 很有帮助。\n\n\n\nFigure 4.1: Indexing elements in a NumPy array\n\n\n在多维数组中，如果省略后面的索引，则返回的对象将是一个较低维度的 ndarray，由较高维度上的所有数据组成。所以在 2 × 2 × 3 数组 arr3d 中：\nIn [77]: arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n\nIn [78]: arr3d\nOut[78]: \narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n       [[ 7,  8,  9],\n        [10, 11, 12]]])\narr3d[0] 是一个 2 × 3 数组：\nIn [79]: arr3d[0]\nOut[79]: \narray([[1, 2, 3],\n       [4, 5, 6]])\n标量值和数组都可以分配给 arr3d[0]：\nIn [80]: old_values = arr3d[0].copy()\n\nIn [81]: arr3d[0] = 42\n\nIn [82]: arr3d\nOut[82]: \narray([[[42, 42, 42],\n        [42, 42, 42]],\n       [[ 7,  8,  9],\n        [10, 11, 12]]])\n\nIn [83]: arr3d[0] = old_values\n\nIn [84]: arr3d\nOut[84]: \narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n       [[ 7,  8,  9],\n        [10, 11, 12]]])\n类似地，arr3d[1, 0] 给出索引以 (1, 0) 开头的所有值，形成一维数组：\nIn [85]: arr3d[1, 0]\nOut[85]: array([7, 8, 9])\n这个表达式与我们分两步索引的表达式相同：\nIn [86]: x = arr3d[1]\n\nIn [87]: x\nOut[87]: \narray([[ 7,  8,  9],\n       [10, 11, 12]])\n\nIn [88]: x[0]\nOut[88]: array([7, 8, 9])\n请注意，在所有选择数组子部分的情况下，返回的数组都是视图。\n\n\n\n\n\n\nCaution\n\n\n\nNumPy 数组的这种多维索引语法不适用于常规 Python 对象，例如列表列表。\n\n\nIndexing with slices\n与 Python 列表等一维对象一样，ndarray 可以使用熟悉的语法进行切片：\nIn [89]: arr\nOut[89]: array([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])\n\nIn [90]: arr[1:6]\nOut[90]: array([ 1,  2,  3,  4, 64])\n考虑之前的二维数组 arr2d。对该数组进行切片有点不同：\nIn [91]: arr2d\nOut[91]: \narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\nIn [92]: arr2d[:2]\nOut[92]: \narray([[1, 2, 3],\n       [4, 5, 6]])\n如您所见，它已沿 axis 0（第一个轴）进行切片。因此，切片沿着轴选择一系列元素。将表达式 arr2d[:2] 理解为“选择 arr2d 的前两行”会很有帮助。\n您可以传递多个切片，就像传递多个索引一样：\nIn [93]: arr2d[:2, 1:]\nOut[93]: \narray([[2, 3],\n       [5, 6]])\n当像这样切片时，您总是获得相同维数的数组视图。通过混合整数索引和切片，您可以获得较低维度的切片。\n例如，我可以选择第二行，但只能选择前两列，如下所示：\nIn [94]: lower_dim_slice = arr2d[1, :2]\n这里，arr2d 是二维的，而 lower_dim_slice 是一维的，它的形状是一个只有一个 axis 大小的元组：\nIn [95]: lower_dim_slice.shape\nOut[95]: (2,)\n同样，我可以选择第三列，但只能选择前两行，如下所示：\nIn [96]: arr2d[:2, 2]\nOut[96]: array([3, 6])\n有关说明，请参见 Figure 4.2。请注意，冒号本身意味着获取整个轴，因此您可以通过执行以下操作仅切片更高维度的轴：\nIn [97]: arr2d[:, :1]\nOut[97]: \narray([[1],\n       [4],\n       [7]])\n当然，分配给切片表达式会分配给整个选择：\nIn [98]: arr2d[:2, 1:] = 0\n\nIn [99]: arr2d\nOut[99]: \narray([[1, 0, 0],\n       [4, 0, 0],\n       [7, 8, 9]])\n\n\n\nFigure 4.2: Two-dimensional array slicing\n\n\n\n\n4.1.5 Boolean Indexing\n让我们考虑一个示例，其中数组中有一些数据，并且名称数组中有重复项：\nIn [100]: names = np.array([\"Bob\", \"Joe\", \"Will\", \"Bob\", \"Will\", \"Joe\", \"Joe\"])\n\nIn [101]: data = np.array([[4, 7], [0, 2], [-5, 6], [0, 0], [1, 2],\n   .....:                  [-12, -4], [3, 4]])\n\nIn [102]: names\nOut[102]: array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'], dtype='&lt;U4')\n\nIn [103]: data\nOut[103]: \narray([[  4,   7],\n       [  0,   2],\n       [ -5,   6],\n       [  0,   0],\n       [  1,   2],\n       [-12,  -4],\n       [  3,   4]])\n假设每个名称对应于 data 数组中的一行，并且我们想要选择具有相应名称\"Bob\"的所有行。与算术运算一样，与数组的比较（例如 ==）也被向量化。因此，将name与字符串\"Bob\"进行比较会产生一个布尔数组：\nIn [104]: names == \"Bob\"\nOut[104]: array([ True, False, False,  True, False, False, False])\n索引数组时可以传递这个布尔数组：\nIn [105]: data[names == \"Bob\"]\nOut[105]: \narray([[4, 7],\n       [0, 0]])\n布尔数组的长度必须与其索引的数组轴的长度相同。您甚至可以将布尔数组与切片或整数（或整数序列；稍后详细介绍）混合搭配。\n在这些示例中，我从names==\"Bob\"的行中进行选择，并对列进行索引：\nIn [106]: data[names == \"Bob\", 1:]\nOut[106]: \narray([[7],\n       [0]])\n\nIn [107]: data[names == \"Bob\", 1]\nOut[107]: array([7, 0])\n要选择除\"Bob\"之外的所有内容，您可以使用 != 或使用 ~ 否定条件：\nIn [108]: names != \"Bob\"\nOut[108]: array([False,  True,  True, False,  True,  True,  True])\n\nIn [109]: ~(names == \"Bob\")\nOut[109]: array([False,  True,  True, False,  True,  True,  True])\n\nIn [110]: data[~(names == \"Bob\")]\nOut[110]: \narray([[  0,   2],\n       [ -5,   6],\n       [  1,   2],\n       [-12,  -4],\n       [  3,   4]])\n当您想要反转变量引用的布尔数组时，~ 运算符会很有用：\nIn [111]: cond = names == \"Bob\"\n\nIn [112]: data[~cond]\nOut[112]: \narray([[  0,   2],\n       [ -5,   6],\n       [  1,   2],\n       [-12,  -4],\n       [  3,   4]])\n要选择三个名称中的两个来组合多个布尔条件，请使用布尔算术运算符，例如 &（and）和 |（or）：\nIn [113]: mask = (names == \"Bob\") | (names == \"Will\")\n\nIn [114]: mask\nOut[114]: array([ True, False,  True,  True,  True, False, False])\n\nIn [115]: data[mask]\nOut[115]: \narray([[ 4,  7],\n       [-5,  6],\n       [ 0,  0],\n       [ 1,  2]])\n通过布尔索引从数组中选择数据并将结果分配给新变量始终会创建数据的副本，即使返回的数组未更改也是如此。\n\n\n\n\n\n\nCaution\n\n\n\nPython 关键字 and 和 or 不适用于布尔数组。使用 &（and）和 | （or）代替。\n\n\n使用布尔数组设置值的方法是将右侧的一个或多个值替换到布尔数组值为 True 的位置。要将 data 中的所有负值设置为 0，我们只需要做：\nIn [116]: data[data &lt; 0] = 0\n\nIn [117]: data\nOut[117]: \narray([[4, 7],\n       [0, 2],\n       [0, 6],\n       [0, 0],\n       [1, 2],\n       [0, 0],\n       [3, 4]])\n您还可以使用一维布尔数组设置整行或整列：\nIn [118]: data[names != \"Joe\"] = 7\n\nIn [119]: data\nOut[119]: \narray([[7, 7],\n       [0, 2],\n       [7, 7],\n       [7, 7],\n       [7, 7],\n       [0, 0],\n       [3, 4]])\n正如我们稍后将看到的，使用 pandas 可以方便地对二维数据进行这些类型的操作。\n\n\n4.1.6 Fancy Indexing\n花式索引是 NumPy 采用的一个术语，用于描述使用整数数组进行索引。假设我们有一个 8 × 4 数组：\nIn [120]: arr = np.zeros((8, 4))\n\nIn [121]: for i in range(8):\n   .....:     arr[i] = i\n\nIn [122]: arr\nOut[122]: \narray([[0., 0., 0., 0.],\n       [1., 1., 1., 1.],\n       [2., 2., 2., 2.],\n       [3., 3., 3., 3.],\n       [4., 4., 4., 4.],\n       [5., 5., 5., 5.],\n       [6., 6., 6., 6.],\n       [7., 7., 7., 7.]])\n要按特定顺序选择行的子集，您可以简单地传递指定所需顺序的整数列表或 ndarray：\nIn [123]: arr[[4, 3, 0, 6]]\nOut[123]: \narray([[4., 4., 4., 4.],\n       [3., 3., 3., 3.],\n       [0., 0., 0., 0.],\n       [6., 6., 6., 6.]])\n希望这段代码达到了您的预期！使用负索引从末尾选择行：\nIn [124]: arr[[-3, -5, -7]]\nOut[124]: \narray([[5., 5., 5., 5.],\n       [3., 3., 3., 3.],\n       [1., 1., 1., 1.]])\n传递多个索引数组的作用略有不同；它选择与每个索引元组相对应的一维元素数组：\nIn [125]: arr = np.arange(32).reshape((8, 4))\n\nIn [126]: arr\nOut[126]: \narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15],\n       [16, 17, 18, 19],\n       [20, 21, 22, 23],\n       [24, 25, 26, 27],\n       [28, 29, 30, 31]])\n\nIn [127]: arr[[1, 5, 7, 2], [0, 3, 1, 2]]\nOut[127]: array([ 4, 23, 29, 10])\n要了解有关 reshape 方法的更多信息，请查看 Appendix A: Advanced NumPy。\n这里选择元素 (1, 0)、(5, 3)、(7, 1)、(2, 2)。使用与轴数量一样多的整数数组进行花式索引的结果始终是一维的。\n在这种情况下，花式索引的行为与某些用户（包括我自己）的预期有点不同，即通过选择矩阵的行和列的子集形成的矩形区域。这是实现这一点的一种方法：\nIn [128]: arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]]\nOut[128]: \narray([[ 4,  7,  5,  6],\n       [20, 23, 21, 22],\n       [28, 31, 29, 30],\n       [ 8, 11,  9, 10]])\n请记住，与切片不同，花式索引在将结果分配给新变量时始终将数据复制到新数组中。如果您使用花哨的索引分配值，则索引值将被修改：\nIn [129]: arr[[1, 5, 7, 2], [0, 3, 1, 2]]\nOut[129]: array([ 4, 23, 29, 10])\n\nIn [130]: arr[[1, 5, 7, 2], [0, 3, 1, 2]] = 0\n\nIn [131]: arr\nOut[131]: \narray([[ 0,  1,  2,  3],\n       [ 0,  5,  6,  7],\n       [ 8,  9,  0, 11],\n       [12, 13, 14, 15],\n       [16, 17, 18, 19],\n       [20, 21, 22,  0],\n       [24, 25, 26, 27],\n       [28,  0, 30, 31]])\n\n\n4.1.7 Transposing Arrays and Swapping Axes\n转置是一种特殊的重塑形式，它同样会返回基础数据的视图，而无需复制任何内容。数组具有 transpose 方法和特殊的 T 属性：\nIn [132]: arr = np.arange(15).reshape((3, 5))\n\nIn [133]: arr\nOut[133]: \narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])\n\nIn [134]: arr.T\nOut[134]: \narray([[ 0,  5, 10],\n       [ 1,  6, 11],\n       [ 2,  7, 12],\n       [ 3,  8, 13],\n       [ 4,  9, 14]])\n在进行矩阵计算时，您可能会经常这样做 - 例如，在使用 numpy.dot 计算内部矩阵乘积时：\nIn [135]: arr = np.array([[0, 1, 0], [1, 2, -2], [6, 3, 2], [-1, 0, -1], [1, 0, 1\n]])\n\nIn [136]: arr\nOut[136]: \narray([[ 0,  1,  0],\n       [ 1,  2, -2],\n       [ 6,  3,  2],\n       [-1,  0, -1],\n       [ 1,  0,  1]])\n\nIn [137]: np.dot(arr.T, arr)\nOut[137]: \narray([[39, 20, 12],\n       [20, 14,  2],\n       [12,  2, 10]])\n@ 中缀运算符是进行矩阵乘法的另一种方法：\nIn [138]: arr.T @ arr\nOut[138]: \narray([[39, 20, 12],\n       [20, 14,  2],\n       [12,  2, 10]])\n使用 .T 进行简单转置是交换轴的特殊情况。ndarray 具有 swapaxes 方法，该方法采用一对轴编号并切换指示的轴以重新排列数据：\nIn [139]: arr\nOut[139]: \narray([[ 0,  1,  0],\n       [ 1,  2, -2],\n       [ 6,  3,  2],\n       [-1,  0, -1],\n       [ 1,  0,  1]])\n\nIn [140]: arr.swapaxes(0, 1)\nOut[140]: \narray([[ 0,  1,  6, -1,  1],\n       [ 1,  2,  3,  0,  0],\n       [ 0, -2,  2, -1,  1]])\nswapaxes 类似地返回数据视图而不制作副本。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html#pseudorandom-number-generation",
    "href": "04.numpy-basics.html#pseudorandom-number-generation",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "4.2 Pseudorandom Number Generation",
    "text": "4.2 Pseudorandom Number Generation\nnumpy.random 模块补充了内置 Python random 模块的功能，可从多种概率分布中高效生成样本值的整个数组。例如，您可以使用 numpy.random.standard_normal 从标准正态分布中获取 4 × 4 样本数组：\nIn [141]: samples = np.random.standard_normal(size=(4, 4))\n\nIn [142]: samples\nOut[142]: \narray([[-0.2047,  0.4789, -0.5194, -0.5557],\n       [ 1.9658,  1.3934,  0.0929,  0.2817],\n       [ 0.769 ,  1.2464,  1.0072, -1.2962],\n       [ 0.275 ,  0.2289,  1.3529,  0.8864]])\n相比之下，Python 的内置 random 模块一次仅采样一个值。从这个基准测试中可以看出，numpy.random 生成非常大的样本的速度要快一个数量级：\nIn [143]: from random import normalvariate\n\nIn [144]: N = 1_000_000\n\nIn [145]: %timeit samples = [normalvariate(0, 1) for _ in range(N)]\n490 ms +- 2.23 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)\n\nIn [146]: %timeit np.random.standard_normal(N)\n32.6 ms +- 271 us per loop (mean +- std. dev. of 7 runs, 10 loops each)\n这些随机数不是真正随机的（而是伪随机的），而是由可配置的随机数生成器生成，该生成器确定性地确定创建什么值。像 numpy.random.standard_normal 这样的函数使用 numpy.random 模块的默认随机数生成器，但您的代码可以配置为使用显式生成器：\nIn [147]: rng = np.random.default_rng(seed=12345)\n\nIn [148]: data = rng.standard_normal((2, 3))\nseed 参数决定了生成器的初始状态，每次使用 rng 对象生成数据时状态都会发生变化。生成器对象 rng 也与可能使用 numpy.random 模块的其他代码隔离：\nIn [149]: type(rng)\nOut[149]: numpy.random._generator.Generator\n请参阅 Table 4.3，了解随机生成器对象（如 rng）上可用的方法的部分列表。在本章的其余部分中，我将使用上面创建的 rng 对象来生成随机数据。\n\nTable 4.3: NumPy random number generator methods\n\n\nMethod\nDescription\n\n\n\n\npermutation\n返回序列的随机排列，或返回排列范围\n\n\nshuffle\n就地随机排列序列\n\n\nuniform\n从均匀分布中抽取样本\n\n\nintegers\n从给定的低到高范围内抽取随机整数\n\n\nstandard_normal\n从平均值为 0、标准差为 1 的正态分布中抽取样本\n\n\nbinomial\n从二项式分布中抽取样本\n\n\nnormal\n从正态（高斯）分布中抽取样本\n\n\nbeta\n从 beta 分布中抽取样本\n\n\nchisquare\n从卡方分布中抽取样本\n\n\ngamma\n从伽玛分布中提取样本\n\n\nuniform\n从均匀 [0, 1) 分布中抽取样本",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html#universal-functions-fast-element-wise-array-functions",
    "href": "04.numpy-basics.html#universal-functions-fast-element-wise-array-functions",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "4.3 Universal Functions: Fast Element-Wise Array Functions",
    "text": "4.3 Universal Functions: Fast Element-Wise Array Functions\n通用函数（或 ufunc）是对 ndarray 中的数据执行逐元素操作的函数。您可以将它们视为简单函数的快速矢量化包装器，这些函数采用一个或多个标量值并生成一个或多个标量结果。\n许多 ufunc 都是简单的逐元素转换，例如 numpy.sqrt 或 numpy.exp：\nIn [150]: arr = np.arange(10)\n\nIn [151]: arr\nOut[151]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nIn [152]: np.sqrt(arr)\nOut[152]: \narray([0.    , 1.    , 1.4142, 1.7321, 2.    , 2.2361, 2.4495, 2.6458,\n       2.8284, 3.    ])\n\nIn [153]: np.exp(arr)\nOut[153]: \narray([   1.    ,    2.7183,    7.3891,   20.0855,   54.5982,  148.4132,\n        403.4288, 1096.6332, 2980.958 , 8103.0839])\n这些被称为一元 ufunc。其他的，例如 numpy.add 或 numpy.maximum，采用两个数组（因此，二进制 ufunc）并返回一个数组作为结果：\nIn [154]: x = rng.standard_normal(8)\n\nIn [155]: y = rng.standard_normal(8)\n\nIn [156]: x\nOut[156]: \narray([-1.3678,  0.6489,  0.3611, -1.9529,  2.3474,  0.9685, -0.7594,\n        0.9022])\n\nIn [157]: y\nOut[157]: \narray([-0.467 , -0.0607,  0.7888, -1.2567,  0.5759,  1.399 ,  1.3223,\n       -0.2997])\n\nIn [158]: np.maximum(x, y)\nOut[158]: \narray([-0.467 ,  0.6489,  0.7888, -1.2567,  2.3474,  1.399 ,  1.3223,\n        0.9022])\n在此示例中，numpy.maximum 计算 x 和 y 中元素的逐元素最大值。\n虽然不常见，但 ufunc 可以返回多个数组。numpy.modf 是一个示例：内置 Python math.modf 的矢量化版本，它返回浮点数组的小数部分和整数部分：\nIn [159]: arr = rng.standard_normal(7) * 5\n\nIn [160]: arr\nOut[160]: array([ 4.5146, -8.1079, -0.7909,  2.2474, -6.718 , -0.4084,  8.6237])\n\nIn [161]: remainder, whole_part = np.modf(arr)\n\nIn [162]: remainder\nOut[162]: array([ 0.5146, -0.1079, -0.7909,  0.2474, -0.718 , -0.4084,  0.6237])\n\nIn [163]: whole_part\nOut[163]: array([ 4., -8., -0.,  2., -6., -0.,  8.])\nUfunc 接受一个可选的 out 参数，该参数允许它们将结果分配到现有数组中，而不是创建一个新数组：\nIn [164]: arr\nOut[164]: array([ 4.5146, -8.1079, -0.7909,  2.2474, -6.718 , -0.4084,  8.6237])\n\nIn [165]: out = np.zeros_like(arr)\n\nIn [166]: np.add(arr, 1)\nOut[166]: array([ 5.5146, -7.1079,  0.2091,  3.2474, -5.718 ,  0.5916,  9.6237])\n\nIn [167]: np.add(arr, 1, out=out)\nOut[167]: array([ 5.5146, -7.1079,  0.2091,  3.2474, -5.718 ,  0.5916,  9.6237])\n\nIn [168]: out\nOut[168]: array([ 5.5146, -7.1079,  0.2091,  3.2474, -5.718 ,  0.5916,  9.6237])\n请参阅 Table 4.4 和 Table 4.5，了解一些 NumPy ufunc 的列表。新的 ufunc 不断添加到 NumPy 中，因此查阅在线 NumPy 文档是获取全面列表并保持最新状态的最佳方式。\n\nTable 4.4: Some unary universal functions\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nabs, fabs\n按元素计算整数、浮点或复数值的绝对值\n\n\nsqrt\n计算每个元素的平方根（相当于arr ** 0.5）\n\n\nsquare\n计算每个元素的平方（相当于 arr ** 2）\n\n\nexp\n计算每个元素的指数 \\(e^x\\)\n\n\nlog, log10, log2, log1p\n分别为自然对数（以 \\(e\\) 为底）、以 10 为底的对数、以 2 为底的对数和 log(1 + x)\n\n\nsign\n计算每个元素的符号：1（正）、0（零）或 –1（负）\n\n\nceil\n计算每个元素的上限（即大于或等于该数字的最小整数）\n\n\nfloor\n计算每个元素的下限（即小于或等于每个元素的最大整数）\n\n\nrint\n将元素舍入到最接近的整数，保留 dtype\n\n\nmodf\n将数组的小数部分和整数部分作为单独的数组返回\n\n\nisnan\n返回布尔数组，指示每个值是否为 NaN（非数字）\n\n\nisfinite, isinf\n返回布尔数组，分别指示每个元素是有限（non-inf, non-NaN）还是无限\n\n\ncos, cosh, sin, sinh, tan, tanh\n正则和双曲三角函数\n\n\narccos, arccosh, arcsin, arcsinh, arctan, arctanh\n反三角函数\n\n\nlogical_not\n按元素计算 not x 的真值（相当于 ~arr）\n\n\n\n\nTable 4.5: Some binary universal functions\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nadd\n添加数组中对应的元素\n\n\nsubtract\n从第一个数组中减去第二个数组中的元素\n\n\nmultiply\n数组元素相乘\n\n\ndivide, floor_divide\n除法或地板除法（截断余数）\n\n\npower\n将第一个数组中的元素计算为第二个数组中指示的幂\n\n\nmaximum, fmax\n逐元素最大值；fmax 忽略 NaN\n\n\nminimum, fmin\n逐元素最小值；fmin 忽略 NaN\n\n\nmod\n逐元素模（除法的余数）\n\n\ncopysign\n将第二个参数中的值的符号复制到第一个参数中的值\n\n\ngreater, greater_equal, less, less_equal, equal, not_equal\n执行逐元素比较，生成布尔数组（相当于中缀运算符 &gt;、&gt;=、&lt;、&lt;=、==、!=）\n\n\nlogical_and\n计算 AND (&) 逻辑运算的逐元素真值\n\n\nlogical_or\n计算 OR (|) 逻辑运算的逐元素真值\n\n\nlogical_xor\n计算 XOR (^) 逻辑运算的逐元素真值",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html#array-oriented-programming-with-arrays",
    "href": "04.numpy-basics.html#array-oriented-programming-with-arrays",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "4.4 Array-Oriented Programming with Arrays",
    "text": "4.4 Array-Oriented Programming with Arrays\n使用 NumPy 数组使您能够将多种数据处理任务表示为简洁的数组表达式，否则可能需要编写循环。这种用数组表达式替换显式循环的做法被一些人称为矢量化(vectorization)。一般来说，矢量化数组运算通常比纯 Python 运算要快得多，这对任何类型的数值计算都有最大的影响。随后，在 Appendix A: Advanced NumPy 中，我解释了广播(broadcasting)，这是一种用于矢量化计算的强大方法。\n举一个简单的例子，假设我们希望在规则的值网格上计算函数 sqrt(x^2 + y^2)。numpy.meshgrid 函数接受两个一维数组并生成两个二维矩阵，对应于这两个数组中的所有 (x, y) 对：\nIn [169]: points = np.arange(-5, 5, 0.01) # 100 equally spaced points\n\nIn [170]: xs, ys = np.meshgrid(points, points)\n\nIn [171]: ys\nOut[171]: \narray([[-5.  , -5.  , -5.  , ..., -5.  , -5.  , -5.  ],\n       [-4.99, -4.99, -4.99, ..., -4.99, -4.99, -4.99],\n       [-4.98, -4.98, -4.98, ..., -4.98, -4.98, -4.98],\n       ...,\n       [ 4.97,  4.97,  4.97, ...,  4.97,  4.97,  4.97],\n       [ 4.98,  4.98,  4.98, ...,  4.98,  4.98,  4.98],\n       [ 4.99,  4.99,  4.99, ...,  4.99,  4.99,  4.99]])\n现在，评估函数只需编写与使用两点编写的相同表达式：\nIn [172]: z = np.sqrt(xs ** 2 + ys ** 2)\n\nIn [173]: z\nOut[173]: \narray([[7.0711, 7.064 , 7.0569, ..., 7.0499, 7.0569, 7.064 ],\n       [7.064 , 7.0569, 7.0499, ..., 7.0428, 7.0499, 7.0569],\n       [7.0569, 7.0499, 7.0428, ..., 7.0357, 7.0428, 7.0499],\n       ...,\n       [7.0499, 7.0428, 7.0357, ..., 7.0286, 7.0357, 7.0428],\n       [7.0569, 7.0499, 7.0428, ..., 7.0357, 7.0428, 7.0499],\n       [7.064 , 7.0569, 7.0499, ..., 7.0428, 7.0499, 7.0569]])\n作为 Ch 9: Plotting and Visualization 的预览，我使用 matplotlib 创建此二维数组的可视化：\nIn [174]: import matplotlib.pyplot as plt\n\nIn [175]: plt.imshow(z, cmap=plt.cm.gray, extent=[-5, 5, -5, 5])\nOut[175]: &lt;matplotlib.image.AxesImage at 0x17f04b040&gt;\n\nIn [176]: plt.colorbar()\nOut[176]: &lt;matplotlib.colorbar.Colorbar at 0x1810661a0&gt;\n\nIn [177]: plt.title(\"Image plot of $\\sqrt{x^2 + y^2}$ for a grid of values\")\nOut[177]: Text(0.5, 1.0, 'Image plot of $\\\\sqrt{x^2 + y^2}$ for a grid of values'\n)\n在 Plot of function evaluated on a grid 中，我使用 matplotlib 函数 imshow 从函数值的二维数组创建图像图。\n\n\n\nFigure 4.3: Plot of function evaluated on a grid\n\n\n如果您使用 IPython，则可以通过执行 plt.close(\"all\") 关闭所有打开的绘图窗口：\nIn [179]: plt.close(\"all\")\n\n\n\n\n\n\nNote\n\n\n\n术语矢量化(vectorization)用于描述其他一些计算机科学概念，但在本书中，我使用它来描述一次对整个数据数组的操作，而不是使用 Python for 循环逐个值进行操作。\n\n\n\n4.4.1 Expressing Conditional Logic as Array Operations\nnumpy.where 函数是三元表达式 x if condition else y 的矢量化版本。假设我们有一个布尔数组和两个值数组：\nIn [180]: xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])\n\nIn [181]: yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])\n\nIn [182]: cond = np.array([True, False, True, True, False])\n假设我们想在 cond 中对应的值为 True 时从 xarr 中获取值，否则从 yarr 中获取值。执行此操作的列表理解可能如下所示：\nIn [183]: result = [(x if c else y)\n   .....:           for x, y, c in zip(xarr, yarr, cond)]\n\nIn [184]: result\nOut[184]: [1.1, 2.2, 1.3, 1.4, 2.5]\n这有多个问题。首先，对于大型数组来说，它不会很快（因为所有工作都是在解释的 Python 代码中完成的）。其次，它不适用于多维数组。使用 numpy.where 您可以通过单个函数调用来完成此操作：\nIn [185]: result = np.where(cond, xarr, yarr)\n\nIn [186]: result\nOut[186]: array([1.1, 2.2, 1.3, 1.4, 2.5])\nnumpy.where 的第二个和第三个参数不需要是数组；它们之一或两者都可以是标量。数据分析中 where 的典型用途是根据另一个数组生成一个新的值数组。假设您有一个随机生成的数据矩阵，并且您希望将所有正值替换为 2，将所有负值替换为 –2。这可以通过 numpy.where 来完成：\nIn [187]: arr = rng.standard_normal((4, 4))\n\nIn [188]: arr\nOut[188]: \narray([[ 2.6182,  0.7774,  0.8286, -0.959 ],\n       [-1.2094, -1.4123,  0.5415,  0.7519],\n       [-0.6588, -1.2287,  0.2576,  0.3129],\n       [-0.1308,  1.27  , -0.093 , -0.0662]])\n\nIn [189]: arr &gt; 0\nOut[189]: \narray([[ True,  True,  True, False],\n       [False, False,  True,  True],\n       [False, False,  True,  True],\n       [False,  True, False, False]])\n\nIn [190]: np.where(arr &gt; 0, 2, -2)\nOut[190]: \narray([[ 2,  2,  2, -2],\n       [-2, -2,  2,  2],\n       [-2, -2,  2,  2],\n       [-2,  2, -2, -2]])\n使用 numpy.where 时可以组合标量和数组。例如，我可以将 arr 中的所有正值替换为常数 2，如下所示：\nIn [191]: np.where(arr &gt; 0, 2, arr) # set only positive values to 2\nOut[191]: \narray([[ 2.    ,  2.    ,  2.    , -0.959 ],\n       [-1.2094, -1.4123,  2.    ,  2.    ],\n       [-0.6588, -1.2287,  2.    ,  2.    ],\n       [-0.1308,  2.    , -0.093 , -0.0662]])\n\n\n4.4.2 Mathematical and Statistical Methods\n一组数学函数，用于计算整个数组或沿轴的数据的统计数据，可作为数组类的方法进行访问。您可以通过调用数组实例方法或使用顶级 NumPy 函数来使用聚合（有时称为缩减），例如 sum、mean 和 std（标准差）。当您使用 NumPy 函数（如 numpy.sum）时，您必须传递要聚合的数组作为第一个参数。\n在这里，我生成一些正态分布的随机数据并计算一些聚合统计数据：\nIn [192]: arr = rng.standard_normal((5, 4))\n\nIn [193]: arr\nOut[193]: \narray([[-1.1082,  0.136 ,  1.3471,  0.0611],\n       [ 0.0709,  0.4337,  0.2775,  0.5303],\n       [ 0.5367,  0.6184, -0.795 ,  0.3   ],\n       [-1.6027,  0.2668, -1.2616, -0.0713],\n       [ 0.474 , -0.4149,  0.0977, -1.6404]])\n\nIn [194]: arr.mean()\nOut[194]: -0.08719744457434529\n\nIn [195]: np.mean(arr)\nOut[195]: -0.08719744457434529\n\nIn [196]: arr.sum()\nOut[196]: -1.743948891486906\n像 mean 和 sum 这样的函数采用一个可选的轴参数来计算给定轴上的统计数据，从而产生一个少一维的数组：\nIn [197]: arr.mean(axis=1)\nOut[197]: array([ 0.109 ,  0.3281,  0.165 , -0.6672, -0.3709])\n\nIn [198]: arr.sum(axis=0)\nOut[198]: array([-1.6292,  1.0399, -0.3344, -0.8203])\n此处，arr.mean(axis=1) 表示“计算各列的平均值”，其中 arr.sum(axis=0) 表示“计算各行的总和”。\n其他方法（如 cumsum 和 cumprod）不会聚合，而是生成中间结果数组：\nIn [199]: arr = np.array([0, 1, 2, 3, 4, 5, 6, 7])\n\nIn [200]: arr.cumsum()\nOut[200]: array([ 0,  1,  3,  6, 10, 15, 21, 28])\n在多维数组中，像 cumsum 这样的累积函数返回一个大小相同的数组，但根据每个较低维度的切片沿指示轴计算部分聚合：\nIn [201]: arr = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n\nIn [202]: arr\nOut[202]: \narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n表达式 arr.cumsum(axis=0) 计算沿行的累积总和，而 arr.cumsum(axis=1) 计算沿列的总和：\nIn [203]: arr.cumsum(axis=0)\nOut[203]: \narray([[ 0,  1,  2],\n       [ 3,  5,  7],\n       [ 9, 12, 15]])\n\nIn [204]: arr.cumsum(axis=1)\nOut[204]: \narray([[ 0,  1,  3],\n       [ 3,  7, 12],\n       [ 6, 13, 21]])\n完整列表请参见 Table 4.6。我们将在后面的章节中看到这些方法的许多实际例子。\n\nTable 4.6: Basic array statistical methods\n\n\nMethod\nDescription\n\n\n\n\nsum\n数组中或沿轴的所有元素的总和；零长度数组的总和为 0\n\n\nmean\n算术平均值；对零长度数组无效（返回 NaN）\n\n\nstd, var\n分别为标准差和方差\n\n\nmin, max\n最小值和最大值\n\n\nargmin, argmax\n分别是最小和最大元素的索引\n\n\ncumsum\n从0开始的元素累加和\n\n\ncumprod\n从1开始的元素的累积乘积\n\n\n\n\n\n4.4.3 Methods for Boolean Arrays\n在前面的方法中，布尔值被强制为 1 (True) 和 0 (False)。因此，sum 通常用作计算布尔数组中 True 值的方法：\nIn [205]: arr = rng.standard_normal(100)\n\nIn [206]: (arr &gt; 0).sum() # Number of positive values\nOut[206]: 48\n\nIn [207]: (arr &lt;= 0).sum() # Number of non-positive values\nOut[207]: 52\n表达式 (arr &gt; 0).sum() 中的括号是能够对 arr &gt; 0 的临时结果调用 sum() 所必需的。\n两个附加方法，any 和 all，对于布尔数组尤其有用。any 测试数组中的一个或多个值是否为 True，而 all 则检查每个值是否为 True：\nIn [208]: bools = np.array([False, False, True, False])\n\nIn [209]: bools.any()\nOut[209]: True\n\nIn [210]: bools.all()\nOut[210]: False\n这些方法也适用于非布尔数组，其中非零元素被视为 True。\n\n\n4.4.4 Sorting\n与 Python 的内置列表类型一样，NumPy 数组可以使用 sort 方法就地排序：\nIn [211]: arr = rng.standard_normal(6)\n\nIn [212]: arr\nOut[212]: array([ 0.0773, -0.6839, -0.7208,  1.1206, -0.0548, -0.0824])\n\nIn [213]: arr.sort()\n\nIn [214]: arr\nOut[214]: array([-0.7208, -0.6839, -0.0824, -0.0548,  0.0773,  1.1206])\n您可以通过传递要排序的轴编号，沿轴对多维数组中值的每个一维部分进行排序。本例中的数据：\nIn [215]: arr = rng.standard_normal((5, 3))\n\nIn [216]: arr\nOut[216]: \narray([[ 0.936 ,  1.2385,  1.2728],\n       [ 0.4059, -0.0503,  0.2893],\n       [ 0.1793,  1.3975,  0.292 ],\n       [ 0.6384, -0.0279,  1.3711],\n       [-2.0528,  0.3805,  0.7554]])\narr.sort(axis=0) 对每列中的值进行排序，而 arr.sort(axis=1) 对每行进行排序：\nIn [217]: arr.sort(axis=0)\n\nIn [218]: arr\nOut[218]: \narray([[-2.0528, -0.0503,  0.2893],\n       [ 0.1793, -0.0279,  0.292 ],\n       [ 0.4059,  0.3805,  0.7554],\n       [ 0.6384,  1.2385,  1.2728],\n       [ 0.936 ,  1.3975,  1.3711]])\n\nIn [219]: arr.sort(axis=1)\n\nIn [220]: arr\nOut[220]: \narray([[-2.0528, -0.0503,  0.2893],\n       [-0.0279,  0.1793,  0.292 ],\n       [ 0.3805,  0.4059,  0.7554],\n       [ 0.6384,  1.2385,  1.2728],\n       [ 0.936 ,  1.3711,  1.3975]])\n顶级方法 numpy.sort 返回数组的排序副本（如 Python 内置函数 sorted），而不是就地修改数组。例如：\nIn [221]: arr2 = np.array([5, -10, 7, 1, 0, -3])\n\nIn [222]: sorted_arr2 = np.sort(arr2)\n\nIn [223]: sorted_arr2\nOut[223]: array([-10,  -3,   0,   1,   5,   7])\n有关使用 NumPy 排序方法以及间接排序等更高级技术的更多详细信息，请参阅 Appendix A: Advanced NumPy。pandas 中还可以找到与排序相关的其他几种数据操作（例如，按一列或多列对数据表进行排序）。\n\n\n4.4.5 Unique and Other Set Logic\nNumPy 对一维 ndarray 有一些基本的集合运算。常用的是 numpy.unique，它返回数组中排序后的唯一值：\nIn [224]: names = np.array([\"Bob\", \"Will\", \"Joe\", \"Bob\", \"Will\", \"Joe\", \"Joe\"])\n\nIn [225]: np.unique(names)\nOut[225]: array(['Bob', 'Joe', 'Will'], dtype='&lt;U4')\n\nIn [226]: ints = np.array([3, 3, 3, 2, 2, 1, 1, 4, 4])\n\nIn [227]: np.unique(ints)\nOut[227]: array([1, 2, 3, 4])\n将 numpy.unique 与纯 Python 替代方案进行对比：\nIn [228]: sorted(set(names))\nOut[228]: ['Bob', 'Joe', 'Will']\n在许多情况下，NumPy 版本速度更快，并且返回 NumPy 数组而不是 Python 列表。\n另一个函数 numpy.in1d 测试一个数组中的值在另一个数组中的成员资格，返回一个布尔数组：\nIn [229]: values = np.array([6, 0, 0, 3, 2, 5, 6])\n\nIn [230]: np.in1d(values, [2, 3, 6])\nOut[230]: array([ True, False, False,  True,  True, False,  True])\n有关 NumPy 中数组集合运算的列表，请参阅 Table 4.7。\n\nTable 4.7: Array set operations\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nunique(x)\n计算 x 中已排序的唯一元素\n\n\nintersect1d(x, y)\n计算 x 和 y 中已排序的公共元素\n\n\nunion1d(x, y)\n计算元素的排序并集\n\n\nin1d(x, y)\n计算一个布尔数组，指示 x 的每个元素是否包含在 y 中\n\n\nsetdiff1d(x, y)\n设置差异，x 中不在 y 中的元素\n\n\nsetxor1d(x, y)\n设置对称差异；元素存在于任一数组中，但不能同时存在于两个数组中",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html#file-input-and-output-with-arrays",
    "href": "04.numpy-basics.html#file-input-and-output-with-arrays",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "4.5 File Input and Output with Arrays",
    "text": "4.5 File Input and Output with Arrays\nNumPy 能够以某些文本或二进制格式将数据保存到磁盘或从磁盘加载数据。在本节中，我仅讨论 NumPy 的内置二进制格式，因为大多数用户更喜欢 pandas 和其他工具来加载文本或表格数据（有关更多信息，请参阅 Ch 6: Data Loading, Storage, and File Formats）。\nnumpy.save 和 numpy.load 是在磁盘上高效保存和加载数组数据的两个主力函数。数组默认以未压缩的原始二进制格式保存，文件扩展名为 .npy：\nIn [231]: arr = np.arange(10)\n\nIn [232]: np.save(\"some_array\", arr)\n如果文件路径尚未以 .npy 结尾，则会附加扩展名。然后可以使用 numpy.load 加载磁盘上的数组：\nIn [233]: np.load(\"some_array.npy\")\nOut[233]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n您可以使用 numpy.savez 将多个数组保存在未压缩的存档中，并将数组作为关键字参数传递：\nIn [234]: np.savez(\"array_archive.npz\", a=arr, b=arr)\n加载 .npz 文件时，您会返回一个类似字典的对象，该对象会延迟加载各个数组：\nIn [235]: arch = np.load(\"array_archive.npz\")\n\nIn [236]: arch[\"b\"]\nOut[236]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n如果你的数据压缩得很好，你可能希望使用 numpy.savez_compressed 代替：\nIn [237]: np.savez_compressed(\"arrays_compressed.npz\", a=arr, b=arr)",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html#linear-algebra",
    "href": "04.numpy-basics.html#linear-algebra",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "4.6 Linear Algebra",
    "text": "4.6 Linear Algebra\n线性代数运算，如矩阵乘法、分解、行列式和其他方阵数学，是许多数组库的重要组成部分。将两个二维数组与 * 相乘是逐元素乘积，而矩阵乘法需要使用 dot 函数或 @ 中缀运算符。dot 既是一个数组方法，也是 numpy 命名空间中用于进行矩阵乘法的函数：\nIn [241]: x = np.array([[1., 2., 3.], [4., 5., 6.]])\n\nIn [242]: y = np.array([[6., 23.], [-1, 7], [8, 9]])\n\nIn [243]: x\nOut[243]: \narray([[1., 2., 3.],\n       [4., 5., 6.]])\n\nIn [244]: y\nOut[244]: \narray([[ 6., 23.],\n       [-1.,  7.],\n       [ 8.,  9.]])\n\nIn [245]: x.dot(y)\nOut[245]: \narray([[ 28.,  64.],\n       [ 67., 181.]])\nx.dot(y) 等价于 np.dot(x, y)：\nIn [246]: np.dot(x, y)\nOut[246]: \narray([[ 28.,  64.],\n       [ 67., 181.]])\n二维数组和适当大小的一维数组之间的矩阵乘积会生成一维数组：\nIn [247]: x @ np.ones(3)\nOut[247]: array([ 6., 15.])\nnumpy.linalg 有一组标准的矩阵分解以及逆矩阵和行列式等：\nIn [248]: from numpy.linalg import inv, qr\n\nIn [249]: X = rng.standard_normal((5, 5))\n\nIn [250]: mat = X.T @ X\n\nIn [251]: inv(mat)\nOut[251]: \narray([[  3.4993,   2.8444,   3.5956, -16.5538,   4.4733],\n       [  2.8444,   2.5667,   2.9002, -13.5774,   3.7678],\n       [  3.5956,   2.9002,   4.4823, -18.3453,   4.7066],\n       [-16.5538, -13.5774, -18.3453,  84.0102, -22.0484],\n       [  4.4733,   3.7678,   4.7066, -22.0484,   6.0525]])\n\nIn [252]: mat @ inv(mat)\nOut[252]: \narray([[ 1.,  0.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1., -0.,  0.],\n       [ 0.,  0.,  0.,  1.,  0.],\n       [-0.,  0.,  0.,  0.,  1.]])\n表达式 X.T.dot(X) 计算 X 与其转置 X.T 的点积。\n请参阅 Table 4.8，了解一些最常用的线性代数函数的列表。\n\nTable 4.8: Commonly used numpy.linalg functions\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\ndiag\n将方阵的对角线（或非对角线）元素作为一维数组返回，或将一维数组转换为非对角线为零的方阵\n\n\ndot\n矩阵乘法\n\n\ntrace\n计算对角线元素的总和\n\n\ndet\n计算矩阵行列式\n\n\neig\n计算方阵的特征值和特征向量\n\n\ninv\n计算方阵的逆矩阵\n\n\npinv\n计算矩阵的 Moore-Penrose 伪逆\n\n\nqr\n计算 QR 分解\n\n\nsvd\n计算奇异值分解 (SVD)\n\n\nsolve\n求解线性方程组 Ax = b for x，其中 A 是方阵\n\n\nlstsq\n计算 Ax = b 的最小二乘解",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html#example-random-walks",
    "href": "04.numpy-basics.html#example-random-walks",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "4.7 Example: Random Walks",
    "text": "4.7 Example: Random Walks\nrandom walks 的模拟提供了利用数组操作的说明性应用。我们首先考虑一个从 0 开始的简单随机游走，步长为 1 和 –1 的概率相等。\n下面是使用内置 random 模块实现 1,000 步的单次随机游走的纯 Python 方法：\n#! blockstart\nimport random\nposition = 0\nwalk = [position]\nnsteps = 1000\nfor _ in range(nsteps):\n    step = 1 if random.randint(0, 1) else -1\n    position += step\n    walk.append(position)\n#! blockend\n有关这些随机游走之一的前 100 个值的示例图，请参见 Figure 4.4：\nIn [255]: plt.plot(walk[:100])\n\n\n\nFigure 4.4: A simple random walk\n\n\n您可能会发现 walk 是随机步骤的累积和，并且可以作为数组表达式进行计算。因此，我使用 numpy.random 模块一次抽取 1,000 次硬币翻转，将它们设置为 1 和 –1，并计算累积和：\nIn [256]: nsteps = 1000\n\nIn [257]: rng = np.random.default_rng(seed=12345)  # fresh random generator\n\nIn [258]: draws = rng.integers(0, 2, size=nsteps)\n\nIn [259]: steps = np.where(draws == 0, 1, -1)\n\nIn [260]: walk = steps.cumsum()\n由此我们可以开始提取统计数据，例如步行轨迹上的最小值和最大值：\nIn [261]: walk.min()\nOut[261]: -8\n\nIn [262]: walk.max()\nOut[262]: 50\n更复杂的统计数据是第一次交叉时间，即随机游走达到特定值的步骤。这里我们可能想知道随机游走在任一方向上距离原点 0 至少 10 步需要多长时间。np.abs(walk) &gt;= 10 为我们提供了一个布尔数组，指示步行已达到或超过 10，但我们需要前 10 或 –10 的索引。事实证明，我们可以使用 argmax 来计算它，它返回布尔数组中最大值的第一个索引（True 是最大值）：\nIn [263]: (np.abs(walk) &gt;= 10).argmax()\nOut[263]: 155\n请注意，此处使用 argmax 并不总是有效，因为它总是对数组进行完整扫描。在这种特殊情况下，一旦观察到 True，我们就知道它是最大值。\n\n4.7.1 Simulating Many Random Walks at Once\n如果您的目标是模拟许多随机游走，例如 5000 次，则只需对前面的代码进行少量修改即可生成所有随机游走。如果传递一个 2 元组，numpy.random 函数将生成一个二维绘图数组，我们可以计算每一行的累积和，从而一次计算所有 5000 个随机游走：\nIn [264]: nwalks = 5000\n\nIn [265]: nsteps = 1000\n\nIn [266]: draws = rng.integers(0, 2, size=(nwalks, nsteps)) # 0 or 1\n\nIn [267]: steps = np.where(draws &gt; 0, 1, -1)\n\nIn [268]: walks = steps.cumsum(axis=1)\n\nIn [269]: walks\nOut[269]: \narray([[  1,   2,   3, ...,  22,  23,  22],\n       [  1,   0,  -1, ..., -50, -49, -48],\n       [  1,   2,   3, ...,  50,  49,  48],\n       ...,\n       [ -1,  -2,  -1, ..., -10,  -9, -10],\n       [ -1,  -2,  -3, ...,   8,   9,   8],\n       [ -1,   0,   1, ...,  -4,  -3,  -2]])\n现在，我们可以计算所有行走中获得的最大值和最小值：\nIn [270]: walks.max()\nOut[270]: 114\n\nIn [271]: walks.min()\nOut[271]: -120\n在这些步行中，我们计算最短的穿越时间为 30 或 –30。这有点棘手，因为并非所有 5,000 个都达到 30。我们可以使用 any 方法检查这一点：\nIn [272]: hits30 = (np.abs(walks) &gt;= 30).any(axis=1)\n\nIn [273]: hits30\nOut[273]: array([False,  True,  True, ...,  True, False,  True])\n\nIn [274]: hits30.sum() # Number that hit 30 or -30\nOut[274]: 3395\n我们可以使用这个布尔数组来选择实际穿过绝对 30 层的 walks 行，并跨轴 1 调用 argmax 来获取交叉时间：\nIn [275]: crossing_times = (np.abs(walks[hits30]) &gt;= 30).argmax(axis=1)\n\nIn [276]: crossing_times\nOut[276]: array([201, 491, 283, ..., 219, 259, 541])\n最后，我们计算平均最短穿越时间：\nIn [277]: crossing_times.mean()\nOut[277]: 500.5699558173785\n除了抛等大小的硬币之外，请随意尝试其他分布的步骤。您只需要使用不同的随机生成器方法，例如 standard_normal 来生成具有一定平均值和标准差的正态分布步骤：\nIn [278]: draws = 0.25 * rng.standard_normal((nwalks, nsteps))\n\n\n\n\n\n\nNote\n\n\n\n请记住，这种矢量化方法需要创建一个包含 nwalks * nsteps 元素的数组，这可能会使用大量内存进行大型模拟。如果内存更受限制，则需要采用不同的方法。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "04.numpy-basics.html#conclusion",
    "href": "04.numpy-basics.html#conclusion",
    "title": "4  NumPy Basics: Arrays and Vectorized Computation",
    "section": "4.8 Conclusion",
    "text": "4.8 Conclusion\n虽然本书的其余部分将重点关注如何使用 pandas 构建数据整理技能，但我们将继续以类似的基于数组的风格进行工作。在 Appendix A: Advanced NumPy 中，我们将深入探讨 NumPy 功能，以帮助您进一步发展数组计算技能。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy Basics: Arrays and Vectorized Computation</span>"
    ]
  },
  {
    "objectID": "05.pandas-basics.html",
    "href": "05.pandas-basics.html",
    "title": "5  Getting Started with pandas",
    "section": "",
    "text": "5.1 Introduction to pandas Data Structures\n要开始使用 pandas，您需要熟悉它的两种主力数据结构：Series 和 DataFrame。虽然它们并不是解决所有问题的通用解决方案，但它们为各种数据任务提供了坚实的基础。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Getting Started with pandas</span>"
    ]
  },
  {
    "objectID": "05.pandas-basics.html#introduction-to-pandas-data-structures",
    "href": "05.pandas-basics.html#introduction-to-pandas-data-structures",
    "title": "5  Getting Started with pandas",
    "section": "",
    "text": "5.1.1 Series\nSeries 是一个类似一维数组的对象，包含相同类型的值序列（与 NumPy 类型类似）和关联的数据标签数组（称为 index）。最简单的 Series 仅由数据数组组成：\nIn [14]: obj = pd.Series([4, 7, -5, 3])\n\nIn [15]: obj\nOut[15]: \n0    4\n1    7\n2   -5\n3    3\ndtype: int64\n以交互方式显示的 Series 的字符串表示形式在左侧显示 index，在右侧显示值。由于我们没有为数据指定 index，因此会创建一个由整数 0 到 N - 1（其中 N 是数据的长度）组成的默认索引。您可以分别通过其 array 和 index 属性获取 Series 的 array 表示形式和 index 对象：\nIn [16]: obj.array\nOut[16]: \n&lt;PandasArray&gt;\n[4, 7, -5, 3]\nLength: 4, dtype: int64\n\nIn [17]: obj.index\nOut[17]: RangeIndex(start=0, stop=4, step=1)\n.array 属性的结果是一个 PandasArray，它通常包装一个 NumPy 数组，但也可以包含特殊的扩展数组类型，这将在 Ch 7.3: Extension Data Types 中详细讨论。\n通常，您需要创建一个带有 index 的 Series，该 index 用标签标识每个数据点：\nIn [18]: obj2 = pd.Series([4, 7, -5, 3], index=[\"d\", \"b\", \"a\", \"c\"])\n\nIn [19]: obj2\nOut[19]: \nd    4\nb    7\na   -5\nc    3\ndtype: int64\n\nIn [20]: obj2.index\nOut[20]: Index(['d', 'b', 'a', 'c'], dtype='object')\n与 NumPy 数组相比，在选择单个值或一组值时可以在 index 中使用标签：\nIn [21]: obj2[\"a\"]\nOut[21]: -5\n\nIn [22]: obj2[\"d\"] = 6\n\nIn [23]: obj2[[\"c\", \"a\", \"d\"]]\nOut[23]: \nc    3\na   -5\nd    6\ndtype: int64\n这里 [\"c\", \"a\", \"d\"] 被解释为索引列表，即使它包含字符串而不是整数。\n使用 NumPy 函数或类似 NumPy 的操作（例如使用布尔数组进行过滤、标量乘法或应用数学函数）将保留索引值链接：\nIn [24]: obj2[obj2 &gt; 0]\nOut[24]: \nd    6\nb    7\nc    3\ndtype: int64\n\nIn [25]: obj2 * 2\nOut[25]: \nd    12\nb    14\na   -10\nc     6\ndtype: int64\n\nIn [26]: import numpy as np\n\nIn [27]: np.exp(obj2)\nOut[27]: \nd     403.428793\nb    1096.633158\na       0.006738\nc      20.085537\ndtype: float64\n将 Series 视为固定长度的有序字典的另一种方式，因为它是索引值到数据值的映射。它可以在许多可能使用字典的情况下使用：\nIn [28]: \"b\" in obj2\nOut[28]: True\n\nIn [29]: \"e\" in obj2\nOut[29]: False\n如果 Python 字典中包含数据，则可以通过传递字典来创建 Series：\nIn [30]: sdata = {\"Ohio\": 35000, \"Texas\": 71000, \"Oregon\": 16000, \"Utah\": 5000}\n\nIn [31]: obj3 = pd.Series(sdata)\n\nIn [32]: obj3\nOut[32]: \nOhio      35000\nTexas     71000\nOregon    16000\nUtah       5000\ndtype: int64\nSeries 可以使用其 to_dict 方法转换回字典：\nIn [33]: obj3.to_dict()\nOut[33]: {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n当您仅传递字典时，结果 Series 中的索引将根据字典的键方法遵循键的顺序，这取决于键插入顺序。您可以通过传递带有字典键的索引来覆盖它，按照您希望它们在结果系列中出现的顺序：\nIn [34]: states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]\n\nIn [35]: obj4 = pd.Series(sdata, index=states)\n\nIn [36]: obj4\nOut[36]: \nCalifornia        NaN\nOhio          35000.0\nOregon        16000.0\nTexas         71000.0\ndtype: float64\n在这里，在 sdata 中找到的三个值被放置在适当的位置，但由于没有找到 \"California\" 的值，因此它显示为 NaN（Not a Number），这在 pandas 中被视为标记缺失或 NA 值。由于 \"Utah\" 未包含在 states 中，因此它被排除在结果对象之外。\n我将交替使用术语 “missing”、“NA” 或 “null” 来指代缺失的数据。pandas 中的 isna 和 notna 函数应该用于检测丢失的数据：\nIn [37]: pd.isna(obj4)\nOut[37]: \nCalifornia     True\nOhio          False\nOregon        False\nTexas         False\ndtype: bool\n\nIn [38]: pd.notna(obj4)\nOut[38]: \nCalifornia    False\nOhio           True\nOregon         True\nTexas          True\ndtype: bool\nSeries 还有这些实例方法：\nIn [39]: obj4.isna()\nOut[39]: \nCalifornia     True\nOhio          False\nOregon        False\nTexas         False\ndtype: bool\n我在 Ch 7: Data Cleaning and Preparation 中更详细地讨论了如何处理丢失的数据。\n对于许多应用程序来说，一个有用的 Series 功能是它在算术运算中按索引标签自动对齐：\nIn [40]: obj3\nOut[40]: \nOhio      35000\nTexas     71000\nOregon    16000\nUtah       5000\ndtype: int64\n\nIn [41]: obj4\nOut[41]: \nCalifornia        NaN\nOhio          35000.0\nOregon        16000.0\nTexas         71000.0\ndtype: float64\n\nIn [42]: obj3 + obj4\nOut[42]: \nCalifornia         NaN\nOhio           70000.0\nOregon         32000.0\nTexas         142000.0\nUtah               NaN\ndtype: float64\n稍后将更详细地讨论数据对齐功能。如果您有数据库方面的经验，您可以将其视为类似于连接操作。\nSeries 对象本身及其索引都有一个 name 属性，它与 pandas 功能的其他区域集成：\nIn [43]: obj4.name = \"population\"\n\nIn [44]: obj4.index.name = \"state\"\n\nIn [45]: obj4\nOut[45]: \nstate\nCalifornia        NaN\nOhio          35000.0\nOregon        16000.0\nTexas         71000.0\nName: population, dtype: float64\nSeries 的索引可以通过赋值来改变：\nIn [46]: obj\nOut[46]: \n0    4\n1    7\n2   -5\n3    3\ndtype: int64\n\nIn [47]: obj.index = [\"Bob\", \"Steve\", \"Jeff\", \"Ryan\"]\n\nIn [48]: obj\nOut[48]: \nBob      4\nSteve    7\nJeff    -5\nRyan     3\ndtype: int64\n\n\n5.1.2 DataFrame\nDataFrame 表示一个矩形数据表，并包含有序的、命名的列集合，每个列可以是不同的值类型（数字、字符串、布尔值等）。DataFrame 同时具有行索引和列索引；它可以被认为是共享相同索引的 Series 的字典。\n\n\n\n\n\n\nNote\n\n\n\n虽然 DataFrame 物理上是二维的，但您可以使用分层索引以表格格式表示更高维的数据，我们将在 Ch 8: Data Wrangling: Join, Combine, and Reshape 中讨论该主题，也是某些 pandas 中更高级的数据处理功能。\n\n\n构造 DataFrame 的方法有很多，最常见的方法之一是使用等长列表或 NumPy 数组的字典：\ndata = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\nframe = pd.DataFrame(data)\n与 Series 一样，生成的 DataFrame 将自动分配其索引，并且列根据数据中键的顺序放置（这取决于它们在字典中的插入顺序）：\nIn [50]: frame\nOut[50]: \n    state  year  pop\n0    Ohio  2000  1.5\n1    Ohio  2001  1.7\n2    Ohio  2002  3.6\n3  Nevada  2001  2.4\n4  Nevada  2002  2.9\n5  Nevada  2003  3.2\n\n\n\n\n\n\nNote\n\n\n\n如果您使用的是 Jupyter notebook，pandas DataFrame 对象将显示为对浏览器更友好的 HTML 表格。有关示例，请参见 Figure 5.1。\n\n\n\n\n\nFigure 5.1: How pandas DataFrame objects look in Jupyter\n\n\n对于大型 DataFrame，head 方法仅选择前五行：\nIn [51]: frame.head()\nOut[51]: \n    state  year  pop\n0    Ohio  2000  1.5\n1    Ohio  2001  1.7\n2    Ohio  2002  3.6\n3  Nevada  2001  2.4\n4  Nevada  2002  2.9\n同样，tail 返回最后五行：\nIn [52]: frame.tail()\nOut[52]: \n    state  year  pop\n1    Ohio  2001  1.7\n2    Ohio  2002  3.6\n3  Nevada  2001  2.4\n4  Nevada  2002  2.9\n5  Nevada  2003  3.2\n如果指定列序列，DataFrame 的列将按该顺序排列：\nIn [53]: pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"])\nOut[53]: \n   year   state  pop\n0  2000    Ohio  1.5\n1  2001    Ohio  1.7\n2  2002    Ohio  3.6\n3  2001  Nevada  2.4\n4  2002  Nevada  2.9\n5  2003  Nevada  3.2\n如果您传递字典中未包含的列，则结果中将显示缺失值：\nIn [54]: frame2 = pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"])\n\nIn [55]: frame2\nOut[55]: \n   year   state  pop debt\n0  2000    Ohio  1.5  NaN\n1  2001    Ohio  1.7  NaN\n2  2002    Ohio  3.6  NaN\n3  2001  Nevada  2.4  NaN\n4  2002  Nevada  2.9  NaN\n5  2003  Nevada  3.2  NaN\n\nIn [56]: frame2.columns\nOut[56]: Index(['year', 'state', 'pop', 'debt'], dtype='object')\nDataFrame 中的列可以通过类似字典的表示法或使用点属性表示法作为 Series 进行检索：\nIn [57]: frame2[\"state\"]\nOut[57]: \n0      Ohio\n1      Ohio\n2      Ohio\n3    Nevada\n4    Nevada\n5    Nevada\nName: state, dtype: object\n\nIn [58]: frame2.year\nOut[58]: \n0    2000\n1    2001\n2    2002\n3    2001\n4    2002\n5    2003\nName: year, dtype: int64\n\n\n\n\n\n\nNote\n\n\n\n为了方便起见，IPython 中提供了类似属性的访问（例如，frame2.year）和制表符完成列名称。\nframe2[column] 适用于任何列名称，但 frame2.column 仅当列名称是有效的 Python 变量名称并且不与 DataFrame 中的任何方法名称冲突时才有效。例如，如果列的名称包含空格或下划线以外的符号，则无法使用点属性方法访问它。\n\n\n请注意，返回的 Series 与 DataFrame 具有相同的索引，并且它们的 name 属性已适当设置。\n还可以使用特殊的 iloc 和 loc 属性按位置或名称检索行（稍后将在 Selection on DataFrame with loc and iloc 中详细介绍）：\nIn [59]: frame2.loc[1]\nOut[59]: \nyear     2001\nstate    Ohio\npop       1.7\ndebt      NaN\nName: 1, dtype: object\n\nIn [60]: frame2.iloc[2]\nOut[60]: \nyear     2002\nstate    Ohio\npop       3.6\ndebt      NaN\nName: 2, dtype: object\n可以通过分配来修改列。例如，可以为空 debt 列分配标量值或值数组：\nIn [61]: frame2[\"debt\"] = 16.5\n\nIn [62]: frame2\nOut[62]: \n   year   state  pop  debt\n0  2000    Ohio  1.5  16.5\n1  2001    Ohio  1.7  16.5\n2  2002    Ohio  3.6  16.5\n3  2001  Nevada  2.4  16.5\n4  2002  Nevada  2.9  16.5\n5  2003  Nevada  3.2  16.5\n\nIn [63]: frame2[\"debt\"] = np.arange(6.)\n\nIn [64]: frame2\nOut[64]: \n   year   state  pop  debt\n0  2000    Ohio  1.5   0.0\n1  2001    Ohio  1.7   1.0\n2  2002    Ohio  3.6   2.0\n3  2001  Nevada  2.4   3.0\n4  2002  Nevada  2.9   4.0\n5  2003  Nevada  3.2   5.0\n将列表或数组分配给列时，值的长度必须与 DataFrame 的长度匹配。如果您分配一个 Series，它的标签将完全与 DataFrame 的索引重新对齐，在任何不存在的索引值中插入缺失值：\nIn [65]: val = pd.Series([-1.2, -1.5, -1.7], index=[2, 4, 5])\n\nIn [66]: frame2[\"debt\"] = val\n\nIn [67]: frame2\nOut[67]: \n   year   state  pop  debt\n0  2000    Ohio  1.5   NaN\n1  2001    Ohio  1.7   NaN\n2  2002    Ohio  3.6  -1.2\n3  2001  Nevada  2.4   NaN\n4  2002  Nevada  2.9  -1.5\n5  2003  Nevada  3.2  -1.7\n分配不存在的列将创建一个新列。\ndel 关键字将像字典一样删除列。作为示例，我首先添加一个新的布尔值列，其中 state 列等于 \"Ohio\"：\nIn [68]: frame2[\"eastern\"] = frame2[\"state\"] == \"Ohio\"\n\nIn [69]: frame2\nOut[69]: \n   year   state  pop  debt  eastern\n0  2000    Ohio  1.5   NaN     True\n1  2001    Ohio  1.7   NaN     True\n2  2002    Ohio  3.6  -1.2     True\n3  2001  Nevada  2.4   NaN    False\n4  2002  Nevada  2.9  -1.5    False\n5  2003  Nevada  3.2  -1.7    False\n\n\n\n\n\n\nCaution\n\n\n\n无法使用 frame2.eastern 点属性表示法创建新列。\n\n\n然后可以使用 del 方法删除该列：\nIn [70]: del frame2[\"eastern\"]\n\nIn [71]: frame2.columns\nOut[71]: Index(['year', 'state', 'pop', 'debt'], dtype='object')\n\n\n\n\n\n\nCaution\n\n\n\n对 DataFrame 进行索引返回的列是基础数据的视图，而不是副本。因此，对 Series 的任何就地修改都将反映在 DataFrame 中。可以使用 Series 的 copy 方法显式复制该列。\n\n\n另一种常见的数据形式是字典的嵌套字典：\nIn [72]: populations = {\"Ohio\": {2000: 1.5, 2001: 1.7, 2002: 3.6},\n   ....:                \"Nevada\": {2001: 2.4, 2002: 2.9}}\n如果嵌套字典传递给 DataFrame，pandas 会将外部字典键解释为列，将内部键解释为行索引：\nIn [73]: frame3 = pd.DataFrame(populations)\n\nIn [74]: frame3\nOut[74]: \n      Ohio  Nevada\n2000   1.5     NaN\n2001   1.7     2.4\n2002   3.6     2.9\n您可以使用与 NumPy 数组类似的语法转置 DataFrame（交换行和列）：\nIn [75]: frame3.T\nOut[75]: \n        2000  2001  2002\nOhio     1.5   1.7   3.6\nNevada   NaN   2.4   2.9\n\n\n\n\n\n\nWarning\n\n\n\n请注意，如果列不全部具有相同的数据类型，转置会丢弃列数据类型，因此转置然后转回可能会丢失以前的类型信息。在这种情况下，列变成纯 Python 对象的数组。\n\n\n内部字典中的键组合起来形成结果中的索引。如果指定了显式索引，则情况并非如此：\nIn [76]: pd.DataFrame(populations, index=[2001, 2002, 2003])\nOut[76]: \n      Ohio  Nevada\n2001   1.7     2.4\n2002   3.6     2.9\n2003   NaN     NaN\nSeries 字典的处理方式大致相同：\nIn [77]: pdata = {\"Ohio\": frame3[\"Ohio\"][:-1],\n   ....:          \"Nevada\": frame3[\"Nevada\"][:2]}\n\nIn [78]: pd.DataFrame(pdata)\nOut[78]: \n      Ohio  Nevada\n2000   1.5     NaN\n2001   1.7     2.4\n有关可以传递给 DataFrame 构造函数的许多内容的列表，请参阅 Table 5.1。\n\nTable 5.1: Possible data inputs to the DataFrame constructor\n\n\n\n\n\n\nType\nNotes\n\n\n\n\n2D ndarray\n数据矩阵，传递可选的行和列标签\n\n\nDictionary of arrays, lists, or tuples\n每个序列成为 DataFrame 中的一列；所有序列的长度必须相同\n\n\nNumPy structured/record array\n被视为 “dictionary of arrays” 的情况\n\n\nDictionary of Series\n每个值成为一列；如果没有传递显式索引，则每个 Series 的索引将联合在一起形成结果的行索引\n\n\nDictionary of dictionaries\n每个内部字典成为一列；键被联合起来形成行索引，如 “dictionary of Series” 的情况\n\n\nList of dictionaries or Series\n每个项目都成为 DataFrame 中的一行；字典键或 Series 索引的并集成为 DataFrame 的列标签\n\n\nList of lists or tuples\n被视为 “2D ndarray” 情况\n\n\nAnother DataFrame\n除非传递不同的索引，否则将使用 DataFrame 的索引\n\n\nNumPy MaskedArray\n与 “2D ndarray” 情况类似，只是 DataFrame 结果中缺少屏蔽值\n\n\n\n如果 DataFrame 的 index 和 columns 设置了 name 属性，这些属性也会显示：\nIn [79]: frame3.index.name = \"year\"\n\nIn [80]: frame3.columns.name = \"state\"\n\nIn [81]: frame3\nOut[81]: \nstate  Ohio  Nevada\nyear               \n2000    1.5     NaN\n2001    1.7     2.4\n2002    3.6     2.9\n与 Series 不同，DataFrame 没有 name 属性。DataFrame 的 to_numpy 方法将 DataFrame 中包含的数据作为二维 ndarray 返回：\nIn [82]: frame3.to_numpy()\nOut[82]: \narray([[1.5, nan],\n       [1.7, 2.4],\n       [3.6, 2.9]])\n如果 DataFrame 的列是不同的数据类型，则将选择返回数组的数据类型来容纳所有列：\nIn [83]: frame2.to_numpy()\nOut[83]: \narray([[2000, 'Ohio', 1.5, nan],\n       [2001, 'Ohio', 1.7, nan],\n       [2002, 'Ohio', 3.6, -1.2],\n       [2001, 'Nevada', 2.4, nan],\n       [2002, 'Nevada', 2.9, -1.5],\n       [2003, 'Nevada', 3.2, -1.7]], dtype=object)\n\n\n5.1.3 Index Objects\npandas 的 Index 对象负责保存轴标签（包括 DataFrame 的列名称）和其他元数据（如轴名称或名称）。构建 Series 或 DataFrame 时使用的任何数组或其他标签序列都会在内部转换为 Index：\nIn [84]: obj = pd.Series(np.arange(3), index=[\"a\", \"b\", \"c\"])\n\nIn [85]: index = obj.index\n\nIn [86]: index\nOut[86]: Index(['a', 'b', 'c'], dtype='object')\n\nIn [87]: index[1:]\nOut[87]: Index(['b', 'c'], dtype='object')\nIndex 对象是不可变的，因此用户不能修改：\nindex[1] = \"d\"  # TypeError\n不变性使得在数据结构之间共享 Index 对象更加安全：\nIn [88]: labels = pd.Index(np.arange(3))\n\nIn [89]: labels\nOut[89]: Index([0, 1, 2], dtype='int64')\n\nIn [90]: obj2 = pd.Series([1.5, -2.5, 0], index=labels)\n\nIn [91]: obj2\nOut[91]: \n0    1.5\n1   -2.5\n2    0.0\ndtype: float64\n\nIn [92]: obj2.index is labels\nOut[92]: True\n\n\n\n\n\n\nCaution\n\n\n\n有些用户不会经常利用 Index 提供的功能，但由于某些操作会产生包含索引数据的结果，因此了解它们的工作原理非常重要。\n\n\n除了类似于数组之外，索引的行为也类似于固定大小的集合：\nIn [93]: frame3\nOut[93]: \nstate  Ohio  Nevada\nyear               \n2000    1.5     NaN\n2001    1.7     2.4\n2002    3.6     2.9\n\nIn [94]: frame3.columns\nOut[94]: Index(['Ohio', 'Nevada'], dtype='object', name='state')\n\nIn [95]: \"Ohio\" in frame3.columns\nOut[95]: True\n\nIn [96]: 2003 in frame3.index\nOut[96]: False\n与 Python 集合不同，pandas 索引可以包含重复标签：\nIn [97]: pd.Index([\"foo\", \"foo\", \"bar\", \"bar\"])\nOut[97]: Index(['foo', 'foo', 'bar', 'bar'], dtype='object')\n具有重复标签的选择将选择该标签的所有出现位置。\n每个索引都有许多用于集合逻辑的方法和属性，它们回答了有关其包含的数据的其他常见问题。Table 5.2 总结了一些有用的内容。\n\nTable 5.2: Some Index methods and properties\n\n\nMethod/Property\nDescription\n\n\n\n\nappend()\n与其他 Index 对象连接，生成新的 Index\n\n\ndifference()\n将集合差异计算为 Index\n\n\nintersection()\n计算集合交集\n\n\nunion()\n计算集并集\n\n\nisin()\n计算布尔数组，指示每个值是否包含在传递的集合中\n\n\ndelete()\n删除索引 i 处的元素计算新索引\n\n\ndrop()\n通过删除传递的值来计算新索引\n\n\ninsert()\n通过在索引 i 处插入元素来计算新索引\n\n\nis_monotonic\n如果每个元素大于或等于前一个元素，则返回 True\n\n\nis_unique\n如果索引没有重复值，则返回 True\n\n\nunique()\n计算索引中唯一值的数组",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Getting Started with pandas</span>"
    ]
  },
  {
    "objectID": "05.pandas-basics.html#essential-functionality",
    "href": "05.pandas-basics.html#essential-functionality",
    "title": "5  Getting Started with pandas",
    "section": "5.2 Essential Functionality",
    "text": "5.2 Essential Functionality\n本节将引导您了解与 Series 或 DataFrame 中包含的数据进行交互的基本机制。在接下来的章节中，我们将更深入地研究使用 pandas 进行数据分析和操作的主题。本书无意作为 pandas 库的详尽文档；相反，我们将专注于让您熟悉常用的功能，而将不太常见（即更深奥）的内容留给您通过阅读在线 pandas 文档来了解更多信息。\n\n5.2.1 Reindexing\npandas 对象的一个​​重要方法是 reindex，这意味着创建一个新对象，并重新排列值以与新索引对齐。考虑一个例子：\nIn [98]: obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=[\"d\", \"b\", \"a\", \"c\"])\n\nIn [99]: obj\nOut[99]: \nd    4.5\nb    7.2\na   -5.3\nc    3.6\ndtype: float64\n在此 Series 上调用 reindex 会根据新索引重新排列数据，如果尚不存在任何索引值，则会引入缺失值：\nIn [100]: obj2 = obj.reindex([\"a\", \"b\", \"c\", \"d\", \"e\"])\n\nIn [101]: obj2\nOut[101]: \na   -5.3\nb    7.2\nc    3.6\nd    4.5\ne    NaN\ndtype: float64\n对于时间序列等有序数据，您可能需要在重新索引时进行一些插值或填充值。 method 选项允许我们使用诸如 ffill 之类的方法来执行此操作，该方法向前填充值：\nIn [102]: obj3 = pd.Series([\"blue\", \"purple\", \"yellow\"], index=[0, 2, 4])\n\nIn [103]: obj3\nOut[103]: \n0      blue\n2    purple\n4    yellow\ndtype: object\n\nIn [104]: obj3.reindex(np.arange(6), method=\"ffill\")\nOut[104]: \n0      blue\n1      blue\n2    purple\n3    purple\n4    yellow\n5    yellow\ndtype: object\n使用 DataFrame，reindex 可以更改（行）索引、列或两者。当仅传递一个序列时，它会重新索引结果中的行：\nIn [105]: frame = pd.DataFrame(np.arange(9).reshape((3, 3)),\n   .....:                      index=[\"a\", \"c\", \"d\"],\n   .....:                      columns=[\"Ohio\", \"Texas\", \"California\"])\n\nIn [106]: frame\nOut[106]: \n   Ohio  Texas  California\na     0      1           2\nc     3      4           5\nd     6      7           8\n\nIn [107]: frame2 = frame.reindex(index=[\"a\", \"b\", \"c\", \"d\"])\n\nIn [108]: frame2\nOut[108]: \n   Ohio  Texas  California\na   0.0    1.0         2.0\nb   NaN    NaN         NaN\nc   3.0    4.0         5.0\nd   6.0    7.0         8.0\n可以使用 columns 关键字对列重新索引：\nIn [109]: states = [\"Texas\", \"Utah\", \"California\"]\n\nIn [110]: frame.reindex(columns=states)\nOut[110]: \n   Texas  Utah  California\na      1   NaN           2\nc      4   NaN           5\nd      7   NaN           8\n由于 \"Ohio\" 不在 states 内，因此该列的数据将从结果中删除。\n重新索引特定轴的另一种方法是将新轴标签作为位置参数传递，然后使用 axis 关键字指定要重新索引的轴：\nIn [111]: frame.reindex(states, axis=\"columns\")\nOut[111]: \n   Texas  Utah  California\na      1   NaN           2\nc      4   NaN           5\nd      7   NaN           8\n有关 reindex 参数的更多信息，请参阅 Table 5.3。\n\nTable 5.3: reindex function arguments\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nlabels\n用作索引的新序列。可以是 Index 实例或任何其他类似序列的 Python 数据结构。索引将按原样使用，无需任何复制。\n\n\nindex\n使用传递的序列作为新的索引标签。\n\n\ncolumns\n使用传递的序列作为新的列标签。\n\n\naxis\n要重新索引的轴，无论是 \"index\"（行）还是 \"columns\"。默认值为 \"index\"。您可以选择执行 reindex(index=new_labels) 或 reindex(columns=new_labels)。\n\n\nmethod\n插值（填充）法；\"ffill\" 向前填充，而 \"bfill\" 向后填充。\n\n\nfill_value\n通过重新索引引入缺失数据时要使用的替代值。当您希望结果中缺少的标签具有空值时，请使用 fill_value=\"missing\" （默认行为）。\n\n\nlimit\n前向填充或回填时，要填充的最大间隙（以元素数量为单位）。\n\n\ntolerance\n向前填充或回填时，用于填充不精确匹配的最大尺寸间隙（以绝对数字距离表示）。\n\n\nlevel\n在 MultiIndex 级别上匹配简单索引；否则选择子集。\n\n\ncopy\n如果为 True，则始终复制基础数据，即使新索引与旧索引等效；如果为 False，则当索引相等时不复制数据。\n\n\n\n正如我们稍后将在 Selection on DataFrame with loc and iloc 中探讨的那样，您还可以使用 loc 运算符重新索引，并且许多用户更喜欢始终这样做。仅当所有新索引标签已存在于 DataFrame 中时，此方法才有效（而 reindex 将为新标签插入缺失的数据）：\nIn [112]: frame.loc[[\"a\", \"d\", \"c\"], [\"California\", \"Texas\"]]\nOut[112]: \n   California  Texas\na           2      1\nd           8      7\nc           5      4\n\n\n5.2.2 Dropping Entries from an Axis\n如果您已经有一个没有这些条目的索引数组或列表，则从轴中删除一个或多个条目很简单，因为您可以使用 reindex 方法或基于 .loc 的索引。由于这可能需要一些修改和设置逻辑，因此 drop 方法将返回一个新对象，其中包含从轴删除的一个或多个指示值：\nIn [113]: obj = pd.Series(np.arange(5.), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n\nIn [114]: obj\nOut[114]: \na    0.0\nb    1.0\nc    2.0\nd    3.0\ne    4.0\ndtype: float64\n\nIn [115]: new_obj = obj.drop(\"c\")\n\nIn [116]: new_obj\nOut[116]: \na    0.0\nb    1.0\nd    3.0\ne    4.0\ndtype: float64\n\nIn [117]: obj.drop([\"d\", \"c\"])\nOut[117]: \na    0.0\nb    1.0\ne    4.0\ndtype: float64\n使用 DataFrame，可以从任一轴删除索引值。为了说明这一点，我们首先创建一个示例 DataFrame：\nIn [118]: data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n   .....:                     index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n   .....:                     columns=[\"one\", \"two\", \"three\", \"four\"])\n\nIn [119]: data\nOut[119]: \n          one  two  three  four\nOhio        0    1      2     3\nColorado    4    5      6     7\nUtah        8    9     10    11\nNew York   12   13     14    15\n使用一系列标签调用 drop 将从行标签（axis 0）中删除值：\nIn [120]: data.drop(index=[\"Colorado\", \"Ohio\"])\nOut[120]: \n          one  two  three  four\nUtah        8    9     10    11\nNew York   12   13     14    15\n要从列中删除标签，请使用 columns 关键字：\nIn [121]: data.drop(columns=[\"two\"])\nOut[121]: \n          one  three  four\nOhio        0      2     3\nColorado    4      6     7\nUtah        8     10    11\nNew York   12     14    15\n您还可以通过传递 axis=1 （类似于 NumPy）或 axis=\"columns\" 来删除列中的值：\nIn [122]: data.drop(\"two\", axis=1)\nOut[122]: \n          one  three  four\nOhio        0      2     3\nColorado    4      6     7\nUtah        8     10    11\nNew York   12     14    15\n\nIn [123]: data.drop([\"two\", \"four\"], axis=\"columns\")\nOut[123]: \n          one  three\nOhio        0      2\nColorado    4      6\nUtah        8     10\nNew York   12     14\n\n\n5.2.3 Indexing, Selection, and Filtering\nSeries 索引 (obj[...]) 的工作方式与 NumPy 数组索引类似，只不过您可以使用 Series 的索引值而不仅仅是整数。以下是一些例子：\nIn [124]: obj = pd.Series(np.arange(4.), index=[\"a\", \"b\", \"c\", \"d\"])\n\nIn [125]: obj\nOut[125]: \na    0.0\nb    1.0\nc    2.0\nd    3.0\ndtype: float64\n\nIn [126]: obj[\"b\"]\nOut[126]: 1.0\n\nIn [127]: obj[1]\nOut[127]: 1.0\n\nIn [128]: obj[2:4]\nOut[128]: \nc    2.0\nd    3.0\ndtype: float64\n\nIn [129]: obj[[\"b\", \"a\", \"d\"]]\nOut[129]: \nb    1.0\na    0.0\nd    3.0\ndtype: float64\n\nIn [130]: obj[[1, 3]]\nOut[130]: \nb    1.0\nd    3.0\ndtype: float64\n\nIn [131]: obj[obj &lt; 2]\nOut[131]: \na    0.0\nb    1.0\ndtype: float64\n虽然您可以通过这种方式通过标签选择数据，但选择索引值的首选方法是使用特殊的 loc 运算符：\nIn [132]: obj.loc[[\"b\", \"a\", \"d\"]]\nOut[132]: \nb    1.0\na    0.0\nd    3.0\ndtype: float64\n更喜欢 loc 的原因是因为用 [] 索引时对整数的处理不同。如果索引包含整数，则基于常规 [] 的索引会将整数视为标签，因此行为会根据索引的数据类型而有所不同。例如：\nIn [133]: obj1 = pd.Series([1, 2, 3], index=[2, 0, 1])\n\nIn [134]: obj2 = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n\nIn [135]: obj1\nOut[135]: \n2    1\n0    2\n1    3\ndtype: int64\n\nIn [136]: obj2\nOut[136]: \na    1\nb    2\nc    3\ndtype: int64\n\nIn [137]: obj1[[0, 1, 2]]\nOut[137]: \n0    2\n1    3\n2    1\ndtype: int64\n\nIn [138]: obj2[[0, 1, 2]]\nOut[138]: \na    1\nb    2\nc    3\ndtype: int64\n使用 loc 时，当索引不包含整数时，表达式 obj.loc[[0, 1, 2]] 将失败：\nIn [134]: obj2.loc[[0, 1]]\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n/tmp/ipykernel_804589/4185657903.py in &lt;module&gt;\n----&gt; 1 obj2.loc[[0, 1]]\n\n^ LONG EXCEPTION ABBREVIATED ^\n\nKeyError: \"None of [Int64Index([0, 1], dtype=\"int64\")] are in the [index]\"\n由于 loc 运算符仅使用标签进行索引，因此还有一个 iloc 运算符仅使用整数进行索引，无论索引是否包含整数，都可以一致地工作：\nIn [139]: obj1.iloc[[0, 1, 2]]\nOut[139]: \n2    1\n0    2\n1    3\ndtype: int64\n\nIn [140]: obj2.iloc[[0, 1, 2]]\nOut[140]: \na    1\nb    2\nc    3\ndtype: int64\n\n\n\n\n\n\nCaution\n\n\n\n您还可以使用标签进行切片，但它的工作方式与普通 Python 切片不同，因为端点是包含的：\nIn [141]: obj2.loc[\"b\":\"c\"]\nOut[141]: \nb    2\nc    3\ndtype: int64\n\n\n使用这些方法赋值会修改 Series 的相应部分：\nIn [142]: obj2.loc[\"b\":\"c\"] = 5\n\nIn [143]: obj2\nOut[143]: \na    1\nb    5\nc    5\ndtype: int64\n\n\n\n\n\n\nNote\n\n\n\n尝试调用类似 loc 或 iloc 的函数而不是用方括号“索引”它们可能是一个常见的新手错误。方括号表示法用于启用切片操作并允许使用 DataFrame 对象在多个轴上进行索引。\n\n\n对 DataFrame 进行索引可检索具有单个值或序列的一列或多列：\nIn [144]: data = pd.DataFrame(np.arange(16).reshape((4, 4)),\n   .....:                     index=[\"Ohio\", \"Colorado\", \"Utah\", \"New York\"],\n   .....:                     columns=[\"one\", \"two\", \"three\", \"four\"])\n\nIn [145]: data\nOut[145]: \n          one  two  three  four\nOhio        0    1      2     3\nColorado    4    5      6     7\nUtah        8    9     10    11\nNew York   12   13     14    15\n\nIn [146]: data[\"two\"]\nOut[146]: \nOhio         1\nColorado     5\nUtah         9\nNew York    13\nName: two, dtype: int64\n\nIn [147]: data[[\"three\", \"one\"]]\nOut[147]: \n          three  one\nOhio          2    0\nColorado      6    4\nUtah         10    8\nNew York     14   12\n像这样的索引有一些特殊情况。第一个是使用布尔数组切片或选择数据：\nIn [148]: data[:2]\nOut[148]: \n          one  two  three  four\nOhio        0    1      2     3\nColorado    4    5      6     7\n\nIn [149]: data[data[\"three\"] &gt; 5]\nOut[149]: \n          one  two  three  four\nColorado    4    5      6     7\nUtah        8    9     10    11\nNew York   12   13     14    15\n提供行选择语法 data[:2] 是为了方便起见。将单个元素或列表传递给 [] 运算符会选择列。\n另一个用例是使用布尔 DataFrame 进行索引，例如通过标量比较生成的索引。考虑一个 DataFrame，其中所有布尔值都是通过与标量值进行比较而生成的：\nIn [150]: data &lt; 5\nOut[150]: \n            one    two  three   four\nOhio       True   True   True   True\nColorado   True  False  False  False\nUtah      False  False  False  False\nNew York  False  False  False  False\n我们可以使用此 DataFrame 将值 0 分配给值为 True 的每个位置，如下所示：\nIn [151]: data[data &lt; 5] = 0\n\nIn [152]: data\nOut[152]: \n          one  two  three  four\nOhio        0    0      0     0\nColorado    0    5      6     7\nUtah        8    9     10    11\nNew York   12   13     14    15\nSelection on DataFrame with loc and iloc\n与 Series 一样，DataFrame 具有特殊属性 loc 和 iloc，分别用于基于标签和基于整数的索引。由于 DataFrame 是二维的，因此您可以使用轴标签 (loc) 或整数 (iloc) 以类似 NumPy 的表示法选择行和列的子集。\n作为第一个示例，让我们按标签选择一行：\nIn [153]: data\nOut[153]: \n          one  two  three  four\nOhio        0    0      0     0\nColorado    0    5      6     7\nUtah        8    9     10    11\nNew York   12   13     14    15\n\nIn [154]: data.loc[\"Colorado\"]\nOut[154]: \none      0\ntwo      5\nthree    6\nfour     7\nName: Colorado, dtype: int64\n选择单行的结果是一个 Series，其索引包含 DataFrame 的列标签。要选择多个角色，创建一个新的 DataFrame，传递一系列标签：\nIn [155]: data.loc[[\"Colorado\", \"New York\"]]\nOut[155]: \n          one  two  three  four\nColorado    0    5      6     7\nNew York   12   13     14    15\n您可以通过用逗号分隔选择来组合 loc 中的行和列选择：\nIn [156]: data.loc[\"Colorado\", [\"two\", \"three\"]]\nOut[156]: \ntwo      5\nthree    6\nName: Colorado, dtype: int64\n然后，我们将使用 iloc 对整数执行一些类似的选择：\nIn [157]: data.iloc[2]\nOut[157]: \none       8\ntwo       9\nthree    10\nfour     11\nName: Utah, dtype: int64\n\nIn [158]: data.iloc[[2, 1]]\nOut[158]: \n          one  two  three  four\nUtah        8    9     10    11\nColorado    0    5      6     7\n\nIn [159]: data.iloc[2, [3, 0, 1]]\nOut[159]: \nfour    11\none      8\ntwo      9\nName: Utah, dtype: int64\n\nIn [160]: data.iloc[[1, 2], [3, 0, 1]]\nOut[160]: \n          four  one  two\nColorado     7    0    5\nUtah        11    8    9\n除了单个标签或标签列表之外，这两个索引函数还可以使用切片：\nIn [161]: data.loc[:\"Utah\", \"two\"]\nOut[161]: \nOhio        0\nColorado    5\nUtah        9\nName: two, dtype: int64\n\nIn [162]: data.iloc[:, :3][data.three &gt; 5]\nOut[162]: \n          one  two  three\nColorado    0    5      6\nUtah        8    9     10\nNew York   12   13     14\n布尔数组可以与 loc 一起使用，但不能与 iloc 一起使用：\nIn [163]: data.loc[data.three &gt;= 2]\nOut[163]: \n          one  two  three  four\nColorado    0    5      6     7\nUtah        8    9     10    11\nNew York   12   13     14    15\n有多种方法可以选择和重新排列 pandas 对象中包含的数据。对于 DataFrame，Table 5.4 提供了其中许多内容的简短摘要。正如您稍后将看到的，还有许多用于处理分层索引的附加选项。\n\nTable 5.4: Indexing options with DataFrame\n\n\n\n\n\n\nType\nNotes\n\n\n\n\ndf[column]\n从 DataFrame 中选择单列或列序列；特殊情况的便利：布尔数组（过滤行）、切片（切片行）或布尔 DataFrame（根据某些标准设置值）\n\n\ndf.loc[rows]\n按标签从 DataFrame 中选择单行或行子集\n\n\ndf.loc[:, cols]\n按标签选择单列或列的子集\n\n\ndf.loc[rows, cols]\n通过标签选择行和列\n\n\ndf.iloc[rows]\n按整数位置从 DataFrame 中选择单行或行子集\n\n\ndf.iloc[:, cols]\n按整数位置选择单列或列子集\n\n\ndf.iloc[rows, cols]\n按整数位置选择行和列\n\n\ndf.iat[row, col]\n按行和列位置（整数）选择单个标量值\n\n\nreindex\n通过标签选择行或列\n\n\n\nInteger indexing pitfalls\n使用由整数索引的 pandas 对象可能会成为新用户的绊脚石，因为它们的工作方式与内置的 Python 数据结构（如列表和元组）不同。例如，您可能不希望以下代码生成错误：\nIn [164]: ser = pd.Series(np.arange(3.))\n\nIn [165]: ser\nOut[165]: \n0    0.0\n1    1.0\n2    2.0\ndtype: float64\n\nIn [166]: ser[-1]\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n~/miniforge-x86/envs/book-env/lib/python3.10/site-packages/pandas/core/indexes/ra\nnge.py in get_loc(self, key)\n    344             try:\n--&gt; 345                 return self._range.index(new_key)\n    346             except ValueError as err:\nValueError: -1 is not in range\nThe above exception was the direct cause of the following exception:\nKeyError                                  Traceback (most recent call last)\n&lt;ipython-input-166-44969a759c20&gt; in &lt;module&gt;\n----&gt; 1 ser[-1]\n~/miniforge-x86/envs/book-env/lib/python3.10/site-packages/pandas/core/series.py \nin __getitem__(self, key)\n   1010 \n   1011         elif key_is_scalar:\n-&gt; 1012             return self._get_value(key)\n   1013 \n   1014         if is_hashable(key):\n~/miniforge-x86/envs/book-env/lib/python3.10/site-packages/pandas/core/series.py \nin _get_value(self, label, takeable)\n   1119 \n   1120         # Similar to Index.get_value, but we do not fall back to position\nal\n-&gt; 1121         loc = self.index.get_loc(label)\n   1122 \n   1123         if is_integer(loc):\n~/miniforge-x86/envs/book-env/lib/python3.10/site-packages/pandas/core/indexes/ra\nnge.py in get_loc(self, key)\n    345                 return self._range.index(new_key)\n    346             except ValueError as err:\n--&gt; 347                 raise KeyError(key) from err\n    348         self._check_indexing_error(key)\n    349         raise KeyError(key)\nKeyError: -1\n在这种情况下，pandas 可以“回退(fall back)”整数索引，但通常很难在不向用户代码中引入细微错误的情况下做到这一点。这里我们有一个包含 0、1 和 2 的索引，但 pandas 不想猜测用户想要什么（基于标签的索引或基于位置的索引）：\nIn [167]: ser\nOut[167]: \n0    0.0\n1    1.0\n2    2.0\ndtype: float64\n另一方面，对于非整数索引，就不存在这样的歧义：\nIn [168]: ser2 = pd.Series(np.arange(3.), index=[\"a\", \"b\", \"c\"])\n\nIn [169]: ser2[-1]\nOut[169]: 2.0\n如果您的轴索引包含整数，则数据选择将始终面向标签。正如我上面所说，如果您使用 loc （用于标签）或 iloc （用于整数），您将得到您想要的：\nIn [170]: ser.iloc[-1]\nOut[170]: 2.0\n另一方面，整数切片始终是面向整数的：\nIn [171]: ser[:2]\nOut[171]: \n0    0.0\n1    1.0\ndtype: float64\n由于这些陷阱，最好始终首选使用 loc 和 iloc 进行索引以避免歧义。\nPitfalls with chained indexing\n在上一节中，我们了解了如何使用 loc 和 iloc 在 DataFrame 上进行灵活的选择。这些索引属性也可用于就地修改 DataFrame 对象，但这样做需要小心。\n例如，在上面的示例 DataFrame 中，我们可以通过标签或整数位置分配给列或行：\nIn [172]: data.loc[:, \"one\"] = 1\n\nIn [173]: data\nOut[173]: \n          one  two  three  four\nOhio        1    0      0     0\nColorado    1    5      6     7\nUtah        1    9     10    11\nNew York    1   13     14    15\n\nIn [174]: data.iloc[2] = 5\n\nIn [175]: data\nOut[175]: \n          one  two  three  four\nOhio        1    0      0     0\nColorado    1    5      6     7\nUtah        5    5      5     5\nNew York    1   13     14    15\n\nIn [176]: data.loc[data[\"four\"] &gt; 5] = 3\n\nIn [177]: data\nOut[177]: \n          one  two  three  four\nOhio        1    0      0     0\nColorado    3    3      3     3\nUtah        5    5      5     5\nNew York    3    3      3     3\n对于新的 pandas 用户来说，一个常见的问题是在分配时链接选择，如下所示：\nIn [177]: data.loc[data.three == 5][\"three\"] = 6\n&lt;ipython-input-11-0ed1cf2155d5&gt;:1: SettingWithCopyWarning:\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n根据数据内容，这可能会打印一个特殊的 SettingWithCopyWarning，它警告您正在尝试修改临时值（data.loc[data. Three == 5]的非空结果）而不是原始 DataFrame 数据，这可能就是你想要的。这里，data 未修改：\nIn [179]: data\nOut[179]: \n          one  two  three  four\nOhio        1    0      0     0\nColorado    3    3      3     3\nUtah        5    5      5     5\nNew York    3    3      3     3\n在这些情况下，修复方法是重写链式赋值以使用单个 loc 操作：\nIn [180]: data.loc[data.three == 5, \"three\"] = 6\n\nIn [181]: data\nOut[181]: \n          one  two  three  four\nOhio        1    0      0     0\nColorado    3    3      3     3\nUtah        5    5      6     5\nNew York    3    3      3     3\n一个好的经验法则是在进行分配时避免链式索引。在其他情况下，pandas 会生成与链式索引有关的 SettingWithCopyWarning。我建议您参考在线 pandas 文档中的这个主题。\n\n\n5.2.4 Arithmetic and Data Alignment\npandas 可以使处理具有不同索引的对象变得更加简单。例如，当您添加对象时，如果任何索引对不相同，则结果中的相应索引将是索引对的并集。让我们看一个例子：\nIn [182]: s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=[\"a\", \"c\", \"d\", \"e\"])\n\nIn [183]: s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1],\n   .....:                index=[\"a\", \"c\", \"e\", \"f\", \"g\"])\n\nIn [184]: s1\nOut[184]: \na    7.3\nc   -2.5\nd    3.4\ne    1.5\ndtype: float64\n\nIn [185]: s2\nOut[185]: \na   -2.1\nc    3.6\ne   -1.5\nf    4.0\ng    3.1\ndtype: float64\n相加：\nIn [186]: s1 + s2\nOut[186]: \na    5.2\nc    1.1\nd    NaN\ne    0.0\nf    NaN\ng    NaN\ndtype: float64\n内部数据对齐在不重叠的标签位置引入了缺失值。缺失值将在进一步的算术计算中传播。\n对于 DataFrame，对齐是在行和列上执行的：\nIn [187]: df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list(\"bcd\"),\n   .....:                    index=[\"Ohio\", \"Texas\", \"Colorado\"])\n\nIn [188]: df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list(\"bde\"),\n   .....:                    index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n\nIn [189]: df1\nOut[189]: \n            b    c    d\nOhio      0.0  1.0  2.0\nTexas     3.0  4.0  5.0\nColorado  6.0  7.0  8.0\n\nIn [190]: df2\nOut[190]: \n          b     d     e\nUtah    0.0   1.0   2.0\nOhio    3.0   4.0   5.0\nTexas   6.0   7.0   8.0\nOregon  9.0  10.0  11.0\n添加这些会返回一个带有索引和列的 DataFrame，这些索引和列是每个 DataFrame 中的索引和列的并集：\nIn [191]: df1 + df2\nOut[191]: \n            b   c     d   e\nColorado  NaN NaN   NaN NaN\nOhio      3.0 NaN   6.0 NaN\nOregon    NaN NaN   NaN NaN\nTexas     9.0 NaN  12.0 NaN\nUtah      NaN NaN   NaN NaN\n由于在两个 DataFrame 对象中均未找到 \"c\" 和 \"e\" 列，因此它们在结果中显示为缺失。这同样适用于带有两个对象不常见的标签的行。\n如果添加没有共同列或行标签的 DataFrame 对象，结果将包含所有空值：\nIn [192]: df1 = pd.DataFrame({\"A\": [1, 2]})\n\nIn [193]: df2 = pd.DataFrame({\"B\": [3, 4]})\n\nIn [194]: df1\nOut[194]: \n   A\n0  1\n1  2\n\nIn [195]: df2\nOut[195]: \n   B\n0  3\n1  4\n\nIn [196]: df1 + df2\nOut[196]: \n    A   B\n0 NaN NaN\n1 NaN NaN\nArithmetic methods with fill values\n在不同索引对象之间的算术运算中，当在一个对象中找到轴标签但在另一个对象中未找到时，您可能需要填充特殊值，例如 0。下面是一个示例，我们通过将 np.nan 分配给它来将特定值设置为 NA (null)：\nIn [197]: df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)),\n   .....:                    columns=list(\"abcd\"))\n\nIn [198]: df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)),\n   .....:                    columns=list(\"abcde\"))\n\nIn [199]: df2.loc[1, \"b\"] = np.nan\n\nIn [200]: df1\nOut[200]: \n     a    b     c     d\n0  0.0  1.0   2.0   3.0\n1  4.0  5.0   6.0   7.0\n2  8.0  9.0  10.0  11.0\n\nIn [201]: df2\nOut[201]: \n      a     b     c     d     e\n0   0.0   1.0   2.0   3.0   4.0\n1   5.0   NaN   7.0   8.0   9.0\n2  10.0  11.0  12.0  13.0  14.0\n3  15.0  16.0  17.0  18.0  19.0\n相加导致不重叠位置的缺失值：\nIn [202]: df1 + df2\nOut[202]: \n      a     b     c     d   e\n0   0.0   2.0   4.0   6.0 NaN\n1   9.0   NaN  13.0  15.0 NaN\n2  18.0  20.0  22.0  24.0 NaN\n3   NaN   NaN   NaN   NaN NaN\n使用 df1 上的 add 方法，我将 df2 和一个参数传递给 fill_value，这将用传递的值替换操作中的任何缺失值：\nIn [203]: df1.add(df2, fill_value=0)\nOut[203]: \n      a     b     c     d     e\n0   0.0   2.0   4.0   6.0   4.0\n1   9.0   5.0  13.0  15.0   9.0\n2  18.0  20.0  22.0  24.0  14.0\n3  15.0  16.0  17.0  18.0  19.0\n请参阅 Table 5.5，了解用于算术的 Series 和 DataFrame 方法的列表。每个都有一个对应的，以字母 r 开头，其参数相反。所以这两个语句是等价的：\nIn [204]: 1 / df1\nOut[204]: \n       a         b         c         d\n0    inf  1.000000  0.500000  0.333333\n1  0.250  0.200000  0.166667  0.142857\n2  0.125  0.111111  0.100000  0.090909\n\nIn [205]: df1.rdiv(1)\nOut[205]: \n       a         b         c         d\n0    inf  1.000000  0.500000  0.333333\n1  0.250  0.200000  0.166667  0.142857\n2  0.125  0.111111  0.100000  0.090909\n相关地，在重新索引 Series 或 DataFrame 时，您还可以指定不同的填充值：\nIn [206]: df1.reindex(columns=df2.columns, fill_value=0)\nOut[206]: \n     a    b     c     d  e\n0  0.0  1.0   2.0   3.0  0\n1  4.0  5.0   6.0   7.0  0\n2  8.0  9.0  10.0  11.0  0\n\nTable 5.5: Flexible arithmetic methods\n\n\nMethod\nDescription\n\n\n\n\nadd, radd\nMethods for addition (+)\n\n\nsub, rsub\nMethods for subtraction (-)\n\n\ndiv, rdiv\nMethods for division (/)\n\n\nfloordiv, rfloordiv\nMethods for floor division (//)\n\n\nmul, rmul\nMethods for multiplication (*)\n\n\npow, rpow\nMethods for exponentiation (**)\n\n\n\nOperations between DataFrame and Series\n与不同维度的 NumPy 数组一样，DataFrame 和 Series 之间的算术也被定义。首先，作为一个激励示例，考虑二维数组与其行之一之间的差异：\nIn [207]: arr = np.arange(12.).reshape((3, 4))\n\nIn [208]: arr\nOut[208]: \narray([[ 0.,  1.,  2.,  3.],\n       [ 4.,  5.,  6.,  7.],\n       [ 8.,  9., 10., 11.]])\n\nIn [209]: arr[0]\nOut[209]: array([0., 1., 2., 3.])\n\nIn [210]: arr - arr[0]\nOut[210]: \narray([[0., 0., 0., 0.],\n       [4., 4., 4., 4.],\n       [8., 8., 8., 8.]])\n当我们从 arr 中减去 arr[0] 时，每行执行一次减法。这称为广播(broadcasting)，并在 Appendix A: Advanced NumPy 中更详细地解释了它与通用 NumPy 数组的关系。DataFrame 和 Series 之间的操作类似：\nIn [211]: frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),\n   .....:                      columns=list(\"bde\"),\n   .....:                      index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n\nIn [212]: series = frame.iloc[0]\n\nIn [213]: frame\nOut[213]: \n          b     d     e\nUtah    0.0   1.0   2.0\nOhio    3.0   4.0   5.0\nTexas   6.0   7.0   8.0\nOregon  9.0  10.0  11.0\n\nIn [214]: series\nOut[214]: \nb    0.0\nd    1.0\ne    2.0\nName: Utah, dtype: float64\n默认情况下，DataFrame 和 Series 之间的算术与 DataFrame 列上 Series 的索引相匹配，并向下广播行：\nIn [215]: frame - series\nOut[215]: \n          b    d    e\nUtah    0.0  0.0  0.0\nOhio    3.0  3.0  3.0\nTexas   6.0  6.0  6.0\nOregon  9.0  9.0  9.0\n如果在 DataFrame 的列或 Series 的索引中都找不到索引值，则对象将被重新索引以形成并集：\nIn [216]: series2 = pd.Series(np.arange(3), index=[\"b\", \"e\", \"f\"])\n\nIn [217]: series2\nOut[217]: \nb    0\ne    1\nf    2\ndtype: int64\n\nIn [218]: frame + series2\nOut[218]: \n          b   d     e   f\nUtah    0.0 NaN   3.0 NaN\nOhio    3.0 NaN   6.0 NaN\nTexas   6.0 NaN   9.0 NaN\nOregon  9.0 NaN  12.0 NaN\n如果您想在列上进行广播，在行上进行匹配，则必须使用其中一种算术方法并指定在索引上进行匹配。例如：\nIn [219]: series3 = frame[\"d\"]\n\nIn [220]: frame\nOut[220]: \n          b     d     e\nUtah    0.0   1.0   2.0\nOhio    3.0   4.0   5.0\nTexas   6.0   7.0   8.0\nOregon  9.0  10.0  11.0\n\nIn [221]: series3\nOut[221]: \nUtah       1.0\nOhio       4.0\nTexas      7.0\nOregon    10.0\nName: d, dtype: float64\n\nIn [222]: frame.sub(series3, axis=\"index\")\nOut[222]: \n          b    d    e\nUtah   -1.0  0.0  1.0\nOhio   -1.0  0.0  1.0\nTexas  -1.0  0.0  1.0\nOregon -1.0  0.0  1.0\n您传递的轴是要匹配的轴。在本例中，我们的意思是匹配 DataFrame 的行索引 (axis=\"index\") 并跨列广播。\n\n\n5.2.5 Function Application and Mapping\nNumPy ufuncs（逐元素数组方法）也适用于 pandas 对象：\nIn [223]: frame = pd.DataFrame(np.random.standard_normal((4, 3)),\n   .....:                      columns=list(\"bde\"),\n   .....:                      index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n\nIn [224]: frame\nOut[224]: \n               b         d         e\nUtah   -0.204708  0.478943 -0.519439\nOhio   -0.555730  1.965781  1.393406\nTexas   0.092908  0.281746  0.769023\nOregon  1.246435  1.007189 -1.296221\n\nIn [225]: np.abs(frame)\nOut[225]: \n               b         d         e\nUtah    0.204708  0.478943  0.519439\nOhio    0.555730  1.965781  1.393406\nTexas   0.092908  0.281746  0.769023\nOregon  1.246435  1.007189  1.296221\n另一种常见的操作是将一维数组上的函数应用于每一列或行。DataFrame 的 apply 方法正是这样做的：\nIn [226]: def f1(x):\n   .....:     return x.max() - x.min()\n\nIn [227]: frame.apply(f1)\nOut[227]: \nb    1.802165\nd    1.684034\ne    2.689627\ndtype: float64\n这里，函数 f 计算 Series 的最大值和最小值之间的差，在 frame 中的每一列上调用一次。结果是一个以 frame 列作为索引的系列。\n如果您传递 axis=\"columns\" 给 apply，则该函数将每行调用一次。思考这个问题的一个有用方法是“跨列应用”：\nIn [228]: frame.apply(f1, axis=\"columns\")\nOut[228]: \nUtah      0.998382\nOhio      2.521511\nTexas     0.676115\nOregon    2.542656\ndtype: float64\n许多最常见的数组统计数据（例如 sum 和 Mean）都是 DataFrame 方法，因此没有必要使用 apply。\n传递给 apply 的函数不需要返回标量值；它还可以返回具有多个值的 Series：\nIn [229]: def f2(x):\n   .....:     return pd.Series([x.min(), x.max()], index=[\"min\", \"max\"])\n\nIn [230]: frame.apply(f2)\nOut[230]: \n            b         d         e\nmin -0.555730  0.281746 -1.296221\nmax  1.246435  1.965781  1.393406\n也可以使用逐元素 Python 函数。假设您想根据 frame 中的每个浮点值计算格式化字符串。您可以使用 applymap 执行此操作：\nIn [231]: def my_format(x):\n   .....:     return f\"{x:.2f}\"\n\nIn [232]: frame.applymap(my_format)\nOut[232]: \n            b     d      e\nUtah    -0.20  0.48  -0.52\nOhio    -0.56  1.97   1.39\nTexas    0.09  0.28   0.77\nOregon   1.25  1.01  -1.30\n名称 applymap 的原因是 Series 有一个用于应用逐元素函数的 map 方法：\nIn [233]: frame[\"e\"].map(my_format)\nOut[233]: \nUtah      -0.52\nOhio       1.39\nTexas      0.77\nOregon    -1.30\nName: e, dtype: object\n\n\n5.2.6 Sorting and Ranking\n按某种标准对数据集进行排序是另一个重要的内置操作。要按行或列标签按字典顺序排序，请使用 sort_index 方法，该方法返回一个新的排序对象：\nIn [234]: obj = pd.Series(np.arange(4), index=[\"d\", \"a\", \"b\", \"c\"])\n\nIn [235]: obj\nOut[235]: \nd    0\na    1\nb    2\nc    3\ndtype: int64\n\nIn [236]: obj.sort_index()\nOut[236]: \na    1\nb    2\nc    3\nd    0\ndtype: int64\n使用 DataFrame，您可以按任一轴上的索引进行排序：\nIn [237]: frame = pd.DataFrame(np.arange(8).reshape((2, 4)),\n   .....:                      index=[\"three\", \"one\"],\n   .....:                      columns=[\"d\", \"a\", \"b\", \"c\"])\n\nIn [238]: frame\nOut[238]: \n       d  a  b  c\nthree  0  1  2  3\none    4  5  6  7\n\nIn [239]: frame.sort_index()\nOut[239]: \n       d  a  b  c\none    4  5  6  7\nthree  0  1  2  3\n\nIn [240]: frame.sort_index(axis=\"columns\")\nOut[240]: \n       a  b  c  d\nthree  1  2  3  0\none    5  6  7  4\n数据默认按升序排序，但也可以按降序排序：\nIn [241]: frame.sort_index(axis=\"columns\", ascending=False)\nOut[241]: \n       d  c  b  a\nthree  0  3  2  1\none    4  7  6  5\n要按值对 Series 进行排序，请使用其 sort_values 方法：\nIn [242]: obj = pd.Series([4, 7, -3, 2])\n\nIn [243]: obj.sort_values()\nOut[243]: \n2   -3\n3    2\n0    4\n1    7\ndtype: int64\n默认情况下，所有缺失值都会排序到 Series 末尾：\nIn [244]: obj = pd.Series([4, np.nan, 7, np.nan, -3, 2])\n\nIn [245]: obj.sort_values()\nOut[245]: \n4   -3.0\n5    2.0\n0    4.0\n2    7.0\n1    NaN\n3    NaN\ndtype: float64\n可以使用 na_position 选项将缺失值排序到开头：\nIn [246]: obj.sort_values(na_position=\"first\")\nOut[246]: \n1    NaN\n3    NaN\n4   -3.0\n5    2.0\n0    4.0\n2    7.0\ndtype: float64\n对 DataFrame 进行排序时，可以使用一列或多列中的数据作为排序键。为此，请将一个或多个列名称传递给 sort_values：\nIn [247]: frame = pd.DataFrame({\"b\": [4, 7, -3, 2], \"a\": [0, 1, 0, 1]})\n\nIn [248]: frame\nOut[248]: \n   b  a\n0  4  0\n1  7  1\n2 -3  0\n3  2  1\n\nIn [249]: frame.sort_values(\"b\")\nOut[249]: \n   b  a\n2 -3  0\n3  2  1\n0  4  0\n1  7  1\n要按多列排序，请传递名称列表：\nIn [250]: frame.sort_values([\"a\", \"b\"])\nOut[250]: \n   b  a\n2 -3  0\n0  4  0\n3  2  1\n1  7  1\n排名从最低值开始，从 1 到数组中有效数据点的数量分配排名。Series 和 DataFrame 的 rank 方法是值得关注的地方；默认情况下，rank 通过为每个组分配平均排名来打破平局：\nIn [251]: obj = pd.Series([7, -5, 7, 4, 2, 0, 4])\n\nIn [252]: obj.rank()\nOut[252]: \n0    6.5\n1    1.0\n2    6.5\n3    4.5\n4    3.0\n5    2.0\n6    4.5\ndtype: float64\n还可以根据数据中观察到的顺序来分配排名：\nIn [253]: obj.rank(method=\"first\")\nOut[253]: \n0    6.0\n1    1.0\n2    7.0\n3    4.0\n4    3.0\n5    2.0\n6    5.0\ndtype: float64\n此处，条目 0 和 2 没有使用平均排名 6.5，而是将它们设置为 6 和 7，因为数据中标签 0 位于标签 2 之前。\n您也可以按降序排列：\nIn [254]: obj.rank(ascending=False)\nOut[254]: \n0    1.5\n1    7.0\n2    1.5\n3    3.5\n4    5.0\n5    6.0\n6    3.5\ndtype: float64\n请参阅 Table 5.6，了解可用的打破平局方法的列表。\nDataFrame 可以计算行或列的排名：\nIn [255]: frame = pd.DataFrame({\"b\": [4.3, 7, -3, 2], \"a\": [0, 1, 0, 1],\n   .....:                       \"c\": [-2, 5, 8, -2.5]})\n\nIn [256]: frame\nOut[256]: \n     b  a    c\n0  4.3  0 -2.0\n1  7.0  1  5.0\n2 -3.0  0  8.0\n3  2.0  1 -2.5\n\nIn [257]: frame.rank(axis=\"columns\")\nOut[257]: \n     b    a    c\n0  3.0  2.0  1.0\n1  3.0  1.0  2.0\n2  1.0  2.0  3.0\n3  3.0  2.0  1.0\n\nTable 5.6: Tie-breaking methods with rank\n\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\n\n\n\"average\"\n默认值：为同等组中的每个条目分配平均排名\n\n\n\n\n\"min\"\n使用整个组的最低排名\n\n\n\n\n\"max\"\n使用整个组的最大排名\n\n\n\n\n\"first\"\n按照值在数据中出现的顺序分配排名\n\n\n\n\n\"dense\"\n与 method=\"min\" 类似，但组之间的排名总是增加 1，而不是组中相等元素的数量\n\n\n\n\n\n\n\n5.2.7 Axis Indexes with Duplicate Labels\n到目前为止，我们看过的几乎所有示例都有唯一的轴标签（索引值）。虽然许多 pandas 函数（如 reindex）要求标签是唯一的，但这不是强制性的。让我们考虑一个具有重复索引的小 Series：\nIn [258]: obj = pd.Series(np.arange(5), index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n\nIn [259]: obj\nOut[259]: \na    0\na    1\nb    2\nb    3\nc    4\ndtype: int64\n索引的 is_unique 属性可以告诉你它的标签是否唯一：\nIn [260]: obj.index.is_unique\nOut[260]: False\n数据选择是与重复项表现不同的主要因素之一。对具有多个条目的标签进行索引会返回一个 Series，而单个条目则返回一个标量值：\nIn [261]: obj[\"a\"]\nOut[261]: \na    0\na    1\ndtype: int64\n\nIn [262]: obj[\"c\"]\nOut[262]: 4\n这可能会使您的代码更加复杂，因为索引的输出类型可能会根据标签是否重复而有所不同。\n相同的逻辑扩展到 DataFrame 中的索引行（或列）：\nIn [263]: df = pd.DataFrame(np.random.standard_normal((5, 3)),\n   .....:                   index=[\"a\", \"a\", \"b\", \"b\", \"c\"])\n\nIn [264]: df\nOut[264]: \n          0         1         2\na  0.274992  0.228913  1.352917\na  0.886429 -2.001637 -0.371843\nb  1.669025 -0.438570 -0.539741\nb  0.476985  3.248944 -1.021228\nc -0.577087  0.124121  0.302614\n\nIn [265]: df.loc[\"b\"]\nOut[265]: \n          0         1         2\nb  1.669025 -0.438570 -0.539741\nb  0.476985  3.248944 -1.021228\n\nIn [266]: df.loc[\"c\"]\nOut[266]: \n0   -0.577087\n1    0.124121\n2    0.302614\nName: c, dtype: float64",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Getting Started with pandas</span>"
    ]
  },
  {
    "objectID": "05.pandas-basics.html#summarizing-and-computing-descriptive-statistics",
    "href": "05.pandas-basics.html#summarizing-and-computing-descriptive-statistics",
    "title": "5  Getting Started with pandas",
    "section": "5.3 Summarizing and Computing Descriptive Statistics",
    "text": "5.3 Summarizing and Computing Descriptive Statistics\npandas 对象配备了一套常见的数学和统计方法。其中大多数属于归约或汇总统计的类别，从 Series 中提取单个值（如总和或平均值）的方法，或从 DataFrame 的行或列中提取一系列值的方法。与 NumPy 数组上的类似方法相比，它们具有针对丢失数据的内置处理。考虑一个小的 DataFrame：\nIn [267]: df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n   .....:                    [np.nan, np.nan], [0.75, -1.3]],\n   .....:                   index=[\"a\", \"b\", \"c\", \"d\"],\n   .....:                   columns=[\"one\", \"two\"])\n\nIn [268]: df\nOut[268]: \n    one  two\na  1.40  NaN\nb  7.10 -4.5\nc   NaN  NaN\nd  0.75 -1.3\n调用 DataFrame 的 sum 方法会返回一个包含列总和的 Series：\nIn [269]: df.sum()\nOut[269]: \none    9.25\ntwo   -5.80\ndtype: float64\n而是传递 axis=\"columns\" 或 axis=1 跨列求和：\nIn [270]: df.sum(axis=\"columns\")\nOut[270]: \na    1.40\nb    2.60\nc    0.00\nd   -0.55\ndtype: float64\n当整行或整列包含所有 NA 值时，总和为 0，而如果任何值不为 NA，则结果为 NA。可以使用 skipna 选项禁用此功能，在这种情况下，行或列中的任何 NA 值都会命名相应的结果 NA：\nIn [271]: df.sum(axis=\"index\", skipna=False)\nOut[271]: \none   NaN\ntwo   NaN\ndtype: float64\n\nIn [272]: df.sum(axis=\"columns\", skipna=False)\nOut[272]: \na     NaN\nb    2.60\nc     NaN\nd   -0.55\ndtype: float64\n一些聚合（例如 mean）需要至少一个非 NA 值才能产生值结果，因此这里我们有：\nIn [273]: df.mean(axis=\"columns\")\nOut[273]: \na    1.400\nb    1.300\nc      NaN\nd   -0.275\ndtype: float64\n请参阅 Table 5.7，了解每种缩减方法的常用选项列表。\n\nTable 5.7: Options for reduction methods\n\n\nMethod\nDescription\n\n\n\n\naxis\n轴减少过度；DataFrame 的行的“index”和列的“columns”\n\n\nskipna\n排除缺失值；默认为 True\n\n\nlevel\n如果轴是分层索引的（MultiIndex），则减少按级别分组\n\n\n\n某些方法（例如 idxmin 和 idxmax）返回间接统计信息，例如达到最小值或最大值的索引值：\nIn [274]: df.idxmax()\nOut[274]: \none    b\ntwo    d\ndtype: object\n其他方法都是累加：\nIn [275]: df.cumsum()\nOut[275]: \n    one  two\na  1.40  NaN\nb  8.50 -4.5\nc   NaN  NaN\nd  9.25 -5.8\n有些方法既不是减法，也不是累加。describe 就是这样一个例子，一次性生成多个汇总统计信息：\nIn [276]: df.describe()\nOut[276]: \n            one       two\ncount  3.000000  2.000000\nmean   3.083333 -2.900000\nstd    3.493685  2.262742\nmin    0.750000 -4.500000\n25%    1.075000 -3.700000\n50%    1.400000 -2.900000\n75%    4.250000 -2.100000\nmax    7.100000 -1.300000\n对于非数字数据，describe 会生成替代的汇总统计数据：\nIn [277]: obj = pd.Series([\"a\", \"a\", \"b\", \"c\"] * 4)\n\nIn [278]: obj.describe()\nOut[278]: \ncount     16\nunique     3\ntop        a\nfreq       8\ndtype: object\n有关汇总统计数据和相关方法的完整列表，请参阅 Table 5.8。\n\nTable 5.8: Descriptive and summary statistics\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncount\nNumber of non-NA values\n\n\ndescribe\nCompute set of summary statistics\n\n\nmin, max\nCompute minimum and maximum values\n\n\nargmin, argmax\nCompute index locations (integers) at which minimum or maximum value is obtained, respectively; not available on DataFrame objects\n\n\nidxmin, idxmax\nCompute index labels at which minimum or maximum value is obtained, respectively\n\n\nquantile\nCompute sample quantile ranging from 0 to 1 (default: 0.5)\n\n\nsum\nSum of values\n\n\nmean\nMean of values\n\n\nmedian\nArithmetic median (50% quantile) of values\n\n\nmad\nMean absolute deviation from mean value\n\n\nprod\nProduct of all values\n\n\nvar\nSample variance of values\n\n\nstd\nSample standard deviation of values\n\n\nskew\nSample skewness (third moment) of values\n\n\nkurt\nSample kurtosis (fourth moment) of values\n\n\ncumsum\nCumulative sum of values\n\n\ncummin, cummax\nCumulative minimum or maximum of values, respectively\n\n\ncumprod\nCumulative product of values\n\n\ndiff\nCompute first arithmetic difference (useful for time series)\n\n\npct_change\nCompute percent changes\n\n\n\n\n5.3.1 Correlation and Covariance\n一些汇总统计数据（例如相关性和协方差）是根据参数对计算的。让我们考虑一些最初从 Yahoo! 获得的股票价格和交易量的 DataFrames。财务并以二进制 Python pickle 文件形式提供，您可以在本书随附的数据集中找到：\nIn [279]: price = pd.read_pickle(\"examples/yahoo_price.pkl\")\n\nIn [280]: volume = pd.read_pickle(\"examples/yahoo_volume.pkl\")\n我现在计算价格的百分比变化，这是一种时间序列运算，将在 Ch 11: Time Series 中进一步探讨：\nIn [281]: returns = price.pct_change()\n\nIn [282]: returns.tail()\nOut[282]: \n                AAPL      GOOG       IBM      MSFT\nDate                                              \n2016-10-17 -0.000680  0.001837  0.002072 -0.003483\n2016-10-18 -0.000681  0.019616 -0.026168  0.007690\n2016-10-19 -0.002979  0.007846  0.003583 -0.002255\n2016-10-20 -0.000512 -0.005652  0.001719 -0.004867\n2016-10-21 -0.003930  0.003011 -0.012474  0.042096\nSeries 的 corr 方法计算两个 Series 中重叠的、非 NA 的、按索引对齐的值的相关性。相关地，cov 计算协方差：\nIn [283]: returns[\"MSFT\"].corr(returns[\"IBM\"])\nOut[283]: 0.49976361144151166\n\nIn [284]: returns[\"MSFT\"].cov(returns[\"IBM\"])\nOut[284]: 8.870655479703549e-05\n另一方面，DataFrame 的 corr 和 cov 方法分别返回完整的相关或协方差矩阵作为 DataFrame：\nIn [285]: returns.corr()\nOut[285]: \n          AAPL      GOOG       IBM      MSFT\nAAPL  1.000000  0.407919  0.386817  0.389695\nGOOG  0.407919  1.000000  0.405099  0.465919\nIBM   0.386817  0.405099  1.000000  0.499764\nMSFT  0.389695  0.465919  0.499764  1.000000\n\nIn [286]: returns.cov()\nOut[286]: \n          AAPL      GOOG       IBM      MSFT\nAAPL  0.000277  0.000107  0.000078  0.000095\nGOOG  0.000107  0.000251  0.000078  0.000108\nIBM   0.000078  0.000078  0.000146  0.000089\nMSFT  0.000095  0.000108  0.000089  0.000215\n使用 DataFrame 的 corrwith 方法，您可以计算 DataFrame 的列或行与另一个 Series 或 DataFrame 之间的成对相关性。传递 Series 返回一个 Series，其中包含为每列计算的相关值：\nIn [287]: returns.corrwith(returns[\"IBM\"])\nOut[287]: \nAAPL    0.386817\nGOOG    0.405099\nIBM     1.000000\nMSFT    0.499764\ndtype: float64\n传递 DataFrame 会计算匹配列名称的相关性。在这里，我计算百分比变化与交易量的相关性：\nIn [288]: returns.corrwith(volume)\nOut[288]: \nAAPL   -0.075565\nGOOG   -0.007067\nIBM    -0.204849\nMSFT   -0.092950\ndtype: float64\n传递 axis=\"columns\" 会逐行执行操作。在所有情况下，在计算相关性之前，数据点都会按标签对齐。\n\n\n5.3.2 Unique Values, Value Counts, and Membership\n另一类相关方法提取有关一维 Series 中包含的值的信息。为了说明这些，请考虑以下示例：\nIn [289]: obj = pd.Series([\"c\", \"a\", \"d\", \"a\", \"a\", \"b\", \"b\", \"c\", \"c\"])\n第一个函数是 unique，它为您提供 Series 中唯一值的数组：\nIn [290]: uniques = obj.unique()\n\nIn [291]: uniques\nOut[291]: array(['c', 'a', 'd', 'b'], dtype=object)\n唯一值不一定按它们首次出现的顺序返回，也不是按排序顺序返回，但如果需要，可以在事后对它们进行排序 (uniques.sort())。相关地，value_counts 计算包含值频率的 Series：\nIn [292]: obj.value_counts()\nOut[292]: \nc    3\na    3\nb    2\nd    1\nName: count, dtype: int64\n为了方便起见，该 Series 按值降序排列。value_counts 也可用作顶级 pandas 方法，可与 NumPy 数组或其他 Python 序列一起使用：\nIn [293]: pd.value_counts(obj.to_numpy(), sort=False)\nOut[293]: \nc    3\na    3\nd    1\nb    2\nName: count, dtype: int64\nisin 执行矢量化集成员资格检查，可用于将数据集过滤为 DataFrame 中的 Series 或列中的值的子集：\nIn [294]: obj\nOut[294]: \n0    c\n1    a\n2    d\n3    a\n4    a\n5    b\n6    b\n7    c\n8    c\ndtype: object\n\nIn [295]: mask = obj.isin([\"b\", \"c\"])\n\nIn [296]: mask\nOut[296]: \n0     True\n1    False\n2    False\n3    False\n4    False\n5     True\n6     True\n7     True\n8     True\ndtype: bool\n\nIn [297]: obj[mask]\nOut[297]: \n0    c\n5    b\n6    b\n7    c\n8    c\ndtype: object\n与 isin 相关的是 Index.get_indexer 方法，它为您提供一个索引数组，从一个可能非不同值的数组到另一个不同值的数组：\nIn [298]: to_match = pd.Series([\"c\", \"a\", \"b\", \"b\", \"c\", \"a\"])\n\nIn [299]: unique_vals = pd.Series([\"c\", \"b\", \"a\"])\n\nIn [300]: indices = pd.Index(unique_vals).get_indexer(to_match)\n\nIn [301]: indices\nOut[301]: array([0, 2, 1, 1, 0, 2])\n有关这些方法的参考，请参阅 Table 5.9。\n\nTable 5.9: Unique, value counts, and set membership methods\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\nisin\n计算一个布尔数组，指示每个 Series 或 DataFrame 值是否包含在传递的值序列中\n\n\nget_indexer\n将数组中每个值的整数索引计算到另一个不同值的数组中；有助于数据对齐和连接类型操作\n\n\nunique\n计算 Series 中唯一值的数组，按观察到的顺序返回\n\n\nvalue_counts\n返回一个包含唯一值作为其索引和频率作为其值的 Series，按降序排列计数\n\n\n\n在某些情况下，您可能需要计算 DataFrame 中多个相关列的直方图。这是一个例子：\nIn [302]: data = pd.DataFrame({\"Qu1\": [1, 3, 4, 3, 4],\n   .....:                      \"Qu2\": [2, 3, 1, 2, 3],\n   .....:                      \"Qu3\": [1, 5, 2, 4, 4]})\n\nIn [303]: data\nOut[303]: \n   Qu1  Qu2  Qu3\n0    1    2    1\n1    3    3    5\n2    4    1    2\n3    3    2    4\n4    4    3    4\n我们可以计算单个列的值计数，如下所示：\nIn [304]: data[\"Qu1\"].value_counts().sort_index()\nOut[304]: \nQu1\n1    1\n3    2\n4    2\nName: count, dtype: int64\n要计算所有列的值，请将 pandas.value_counts 传递给 DataFrame 的 apply 方法：\nIn [305]: result = data.apply(pd.value_counts).fillna(0)\n\nIn [306]: result\nOut[306]: \n   Qu1  Qu2  Qu3\n1  1.0  1.0  1.0\n2  0.0  2.0  1.0\n3  2.0  2.0  0.0\n4  2.0  0.0  2.0\n5  0.0  0.0  1.0\n在这里，结果中的行标签是所有列中出现的不同值。这些值是每列中这些值的相应计数。\n还有一个 DataFrame.value_counts 方法，但它将 DataFrame 的每一行视为一个元组来计算计数，以确定每个不同行的出现次数：\nIn [307]: data = pd.DataFrame({\"a\": [1, 1, 1, 2, 2], \"b\": [0, 0, 1, 0, 0]})\n\nIn [308]: data\nOut[308]: \n   a  b\n0  1  0\n1  1  0\n2  1  1\n3  2  0\n4  2  0\n\nIn [309]: data.value_counts()\nOut[309]: \na  b\n1  0    2\n2  0    2\n1  1    1\nName: count, dtype: int64\n在这种情况下，结果有一个索引，将不同的行表示为分层索引，我们将在 Ch 8: Data Wrangling: Join, Combine, and Reshape 中更详细地探讨该主题。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Getting Started with pandas</span>"
    ]
  },
  {
    "objectID": "05.pandas-basics.html#conclusion",
    "href": "05.pandas-basics.html#conclusion",
    "title": "5  Getting Started with pandas",
    "section": "5.4 Conclusion",
    "text": "5.4 Conclusion\n在下一章中，我们将讨论使用 pandas 读取（或加载）和写入数据集的工具。之后，我们将更深入地研究使用 pandas 的数据清理、整理、分析和可视化工具。",
    "crumbs": [
      "Chapters",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Getting Started with pandas</span>"
    ]
  }
]